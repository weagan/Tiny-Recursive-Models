{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0owkUzeK0oTH6qliWl9Jy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/Full_TRM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1Hdjem5Kfqu",
        "outputId": "52d52525-c1c8-47d4-b50c-4576fc0df8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss = 0.4852\n",
            "Epoch 2, loss = 0.3465\n",
            "Epoch 3, loss = 0.2699\n",
            "Epoch 4, loss = 0.2417\n",
            "Epoch 5, loss = 0.2172\n",
            "Epoch 6, loss = 0.1990\n",
            "Epoch 7, loss = 0.1834\n",
            "Epoch 8, loss = 0.1746\n",
            "Epoch 9, loss = 0.1667\n",
            "Epoch 10, loss = 0.1575\n",
            "Input maze:\n",
            "[3. 2. 0. 0. 0.]\n",
            "\n",
            "Ground truth path:\n",
            "[[1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "\n",
            "Predicted path:\n",
            "[[1 1 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# Tiny Recursive Model (TRM) for 5×5 mazes\n",
        "# With:\n",
        "#   - Deep supervision (loss at every step)\n",
        "#   - Halting probability (optional)\n",
        "#   - Separate embeddings y (solution) and z (latent state)\n",
        "# ============================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# =====================================================\n",
        "# 1. MAZE GENERATION + SHORTEST PATH LABELS\n",
        "# =====================================================\n",
        "\n",
        "def generate_maze_5x5():\n",
        "    \"\"\"\n",
        "    Random 5×5 maze with walls, ensuring a valid path exists.\n",
        "    \"\"\"\n",
        "    maze = np.zeros((5,5), dtype=np.int32)\n",
        "\n",
        "    # randomly place walls\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            if random.random() < 0.25:\n",
        "                maze[i,j] = 1\n",
        "\n",
        "    # choose start/goal\n",
        "    sx, sy = random.randint(0,4), random.randint(0,4)\n",
        "    gx, gy = random.randint(0,4), random.randint(0,4)\n",
        "    maze[sx,sy] = 2\n",
        "    maze[gx,gy] = 3\n",
        "\n",
        "    # BFS shortest path\n",
        "    G = nx.grid_graph([5,5])\n",
        "    G.remove_edges_from([(u,v) for u,v in G.edges if maze[u] == 1 or maze[v] == 1])\n",
        "\n",
        "    try:\n",
        "        sp = nx.shortest_path(G, (sx,sy), (gx,gy))\n",
        "        label = np.zeros((5,5), dtype=np.float32)\n",
        "        for x,y in sp:\n",
        "            label[x,y] = 1.0\n",
        "        return maze.astype(np.float32), label\n",
        "    except:\n",
        "        return generate_maze_5x5()\n",
        "\n",
        "class MazeDataset(Dataset):\n",
        "    def __init__(self, n=2000):\n",
        "        self.mazes = []\n",
        "        self.labels = []\n",
        "        for _ in range(n):\n",
        "            maze, label = generate_maze_5x5()\n",
        "            self.mazes.append(maze)\n",
        "            self.labels.append(label)\n",
        "\n",
        "    def __len__(self): return len(self.mazes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        maze = self.mazes[idx][None,:,:]  # (1,5,5)\n",
        "        label = self.labels[idx][None,:,:] # (1,5,5)\n",
        "        return torch.tensor(maze), torch.tensor(label)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 2. TINY RECURSIVE MODEL (TRM)\n",
        "# =====================================================\n",
        "\n",
        "class TRM(nn.Module):\n",
        "    def __init__(self, hidden_dim=64, halting=True):\n",
        "        super().__init__()\n",
        "        self.halting = halting\n",
        "\n",
        "        # Core tiny network\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Conv2d(1+1+16, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # y-head (solution logits)\n",
        "        self.y_head = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
        "\n",
        "        # latent z update: map hidden → latent (16 channels)\n",
        "        self.z_head = nn.Conv2d(hidden_dim, 16, kernel_size=1)\n",
        "\n",
        "        # halting head\n",
        "        if halting:\n",
        "            self.halt_head = nn.Conv2d(hidden_dim, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, maze, y, z):\n",
        "        \"\"\"\n",
        "        maze: (B,1,5,5)\n",
        "        y:    (B,1,5,5)\n",
        "        z:    (B,16,5,5)\n",
        "        \"\"\"\n",
        "        inp = torch.cat([maze, y, z], dim=1)\n",
        "        h = self.f(inp)\n",
        "\n",
        "        logits_y = self.y_head(h)\n",
        "        new_y = torch.sigmoid(logits_y)\n",
        "\n",
        "        new_z = self.z_head(h)\n",
        "\n",
        "        if self.halting:\n",
        "            halt_logits = self.halt_head(h)\n",
        "            halt_p = torch.sigmoid(halt_logits)\n",
        "        else:\n",
        "            halt_p = torch.zeros_like(new_y)\n",
        "\n",
        "        return logits_y, new_y, new_z, halt_p\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 3. RECURSIVE LOOP WITH DEEP SUPERVISION\n",
        "# =====================================================\n",
        "\n",
        "def recursive_pass(model, maze, label, T=5, use_halting=False):\n",
        "    \"\"\"\n",
        "    Deep supervision: loss at each step t=1..T.\n",
        "    Optional halting mechanism.\n",
        "    \"\"\"\n",
        "    B = maze.size(0)\n",
        "    y = torch.zeros_like(maze)     # (B,1,5,5)\n",
        "    z = torch.zeros((B,16,5,5), device=maze.device)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    halting_mass = torch.zeros((B,1,5,5), device=maze.device)\n",
        "    final_output = None\n",
        "\n",
        "    for t in range(T):\n",
        "        logits_y, new_y, new_z, halt_p = model(maze, y, z)\n",
        "\n",
        "        # deep supervision loss\n",
        "        loss_t = criterion(logits_y, label)\n",
        "        total_loss += loss_t\n",
        "\n",
        "        # halting accumulation\n",
        "        if use_halting:\n",
        "            still_running = (halting_mass < 1.0).float()\n",
        "            halting_mass = halting_mass + halt_p * still_running\n",
        "            final_output = logits_y\n",
        "\n",
        "            # if all halted → early stop\n",
        "            if (halting_mass >= 1.0).all():\n",
        "                return total_loss / (t+1), final_output\n",
        "\n",
        "        # update y,z\n",
        "        y, z = new_y, new_z\n",
        "\n",
        "        final_output = logits_y\n",
        "\n",
        "    return total_loss / T, final_output\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 4. TRAINING\n",
        "# =====================================================\n",
        "\n",
        "train_ds = MazeDataset(2000)\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "\n",
        "model = TRM(hidden_dim=64, halting=True).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 10\n",
        "T = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for maze, label in train_loader:\n",
        "        maze = maze.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        loss, _ = recursive_pass(model, maze, label, T=T, use_halting=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += loss.item() * maze.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, loss = {total / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 5. INFERENCE\n",
        "# =====================================================\n",
        "\n",
        "def infer(model, maze, T=10, halting=True):\n",
        "    \"\"\"\n",
        "    maze: (1,1,5,5)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        B = maze.size(0)\n",
        "        y = torch.zeros_like(maze)\n",
        "        z = torch.zeros((B,16,5,5), device=maze.device)\n",
        "\n",
        "        halting_mass = torch.zeros_like(maze)\n",
        "        final_logits = None\n",
        "\n",
        "        for t in range(T):\n",
        "            logits_y, new_y, new_z, halt_p = model(maze, y, z)\n",
        "            y, z = new_y, new_z\n",
        "            final_logits = logits_y\n",
        "\n",
        "            if halting:\n",
        "                still_running = (halting_mass < 1).float()\n",
        "                halting_mass += halt_p * still_running\n",
        "                if (halting_mass >= 1).all():\n",
        "                    break\n",
        "\n",
        "        probs = torch.sigmoid(final_logits).cpu().numpy()[0,0]\n",
        "        return (probs > 0.5).astype(int), probs\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 6. DEMO ON UNSEEN MAZE\n",
        "# =====================================================\n",
        "\n",
        "maze, label = generate_maze_5x5()\n",
        "maze_t = torch.tensor(maze[None,None,:,:], device=device)\n",
        "\n",
        "pred_map, prob = infer(model, maze_t)\n",
        "\n",
        "print(\"Input maze:\")\n",
        "print(maze[0])\n",
        "\n",
        "print(\"\\nGround truth path:\")\n",
        "print(label)\n",
        "\n",
        "print(\"\\nPredicted path:\")\n",
        "print(pred_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "419be539",
        "outputId": "c9566ca1-ac2f-4a90-c8c9-1a40d0c6efc3"
      },
      "source": [
        "train_ds = MazeDataset(2000)\n",
        "print(\"Maze 1:\")\n",
        "print(train_ds[0][0].squeeze().numpy())\n",
        "\n",
        "print(\"\\nMaze 10:\")\n",
        "print(train_ds[9][0].squeeze().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maze 1:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 1.]\n",
            " [3. 1. 0. 1. 0.]\n",
            " [0. 0. 2. 1. 1.]]\n",
            "\n",
            "Maze 10:\n",
            "[[1. 0. 0. 2. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 3. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cac8615e",
        "outputId": "2b9686ba-0433-4f94-cb9a-9b4085a9c5c8"
      },
      "source": [
        "train_ds = MazeDataset(2000)\n",
        "\n",
        "# Display Maze 1 and its solution path\n",
        "maze1, label1 = train_ds[0]\n",
        "print(\"Maze 1:\")\n",
        "print(maze1.squeeze().numpy())\n",
        "print(\"Ground truth path for Maze 1:\")\n",
        "print(label1.squeeze().numpy())\n",
        "\n",
        "# Display Maze 10 and its solution path\n",
        "maze10, label10 = train_ds[9]\n",
        "print(\"\\nMaze 10:\")\n",
        "print(maze10.squeeze().numpy())\n",
        "print(\"Ground truth path for Maze 10:\")\n",
        "print(label10.squeeze().numpy())\n",
        "\n",
        "# Generate and display an unseen maze and its solution path\n",
        "unseen_maze, unseen_label = generate_maze_5x5()\n",
        "unseen_maze_t = torch.tensor(unseen_maze[None,None,:,:], device=device)\n",
        "\n",
        "pred_map, prob = infer(model, unseen_maze_t)\n",
        "\n",
        "print(\"\\nUnseen Maze:\")\n",
        "print(unseen_maze)\n",
        "\n",
        "print(\"\\nGround truth path for Unseen Maze:\")\n",
        "print(unseen_label)\n",
        "\n",
        "print(\"\\nPredicted path for Unseen Maze:\")\n",
        "print(pred_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maze 1:\n",
            "[[2. 0. 0. 0. 0.]\n",
            " [0. 3. 0. 0. 0.]\n",
            " [1. 1. 0. 1. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "Ground truth path for Maze 1:\n",
            "[[1. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "\n",
            "Maze 10:\n",
            "[[1. 1. 0. 0. 0.]\n",
            " [0. 3. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [2. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]]\n",
            "Ground truth path for Maze 10:\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "\n",
            "Unseen Maze:\n",
            "[[1. 1. 0. 0. 1.]\n",
            " [0. 0. 0. 3. 0.]\n",
            " [1. 0. 0. 0. 2.]\n",
            " [1. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 1. 0.]]\n",
            "\n",
            "Ground truth path for Unseen Maze:\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "\n",
            "Predicted path for Unseen Maze:\n",
            "[[0 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 1]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a5be2a9",
        "outputId": "75514407-3592-43d4-f5c1-658ca95c6a69"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "found_in_training = False\n",
        "for i in range(len(train_ds)):\n",
        "    # train_ds mazes are (1,5,5), unseen_maze is (5,5)\n",
        "    if np.array_equal(train_ds[i][0].squeeze().numpy(), unseen_maze):\n",
        "        found_in_training = True\n",
        "        break\n",
        "\n",
        "if found_in_training:\n",
        "    print(\"The unseen maze WAS found in the training dataset.\")\n",
        "else:\n",
        "    print(\"The unseen maze was NOT found in the training dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unseen maze was NOT found in the training dataset.\n"
          ]
        }
      ]
    }
  ]
}