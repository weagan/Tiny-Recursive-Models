{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/TRM_Demonstration_patched.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c24c60",
      "metadata": {
        "id": "45c24c60"
      },
      "source": [
        "# Understanding Tiny Recursive Models (TRM)\n",
        "\n",
        "This Colab notebook provides a hands-on implementation of a Tiny Recursive Model (TRM), based on the concepts outlined in the [learn-tiny-recursive-models GitHub repository](https://github.com/vukrosic/learn-tiny-recursive-models).\n",
        "\n",
        "We will:\n",
        "1.  Implement the core `RecursiveBlock`.\n",
        "2.  Build the full `TRM` model and enable it to run on a GPU.\n",
        "3.  Run a forward pass to see how it processes a sequence.\n",
        "4.  Set up a simple training loop to watch the model learn.\n",
        "5.  Train the model on a more complex task: solving a dataset of **100** 5x5 mazes.\n",
        "6.  Test the model's generalization on a new, unseen maze and **verify the solution path**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409cb425",
      "metadata": {
        "id": "409cb425"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install PyTorch and set up our device to use a GPU if one is available in the Colab environment. Using a GPU will significantly speed up training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efef132a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efef132a",
        "outputId": "6132da97-bfd3-46c2-af0f-7edd69ec35de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "# Set the device to a GPU if available, otherwise use the CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a822800",
      "metadata": {
        "id": "2a822800"
      },
      "source": [
        "## 1. The Core Component: `RecursiveBlock`\n",
        "\n",
        "The fundamental building block of a TRM is the `RecursiveBlock`. It takes an input tensor and a hidden state from the previous step, and produces an output and an updated hidden state. This recursive nature allows it to process sequences step-by-step.\n",
        "\n",
        "The block consists of:\n",
        "-   Two Layer Normalization layers for stability.\n",
        "-   Two Linear layers to transform the concatenated input and state.\n",
        "-   A GELU activation function for non-linearity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "210e6860",
      "metadata": {
        "id": "210e6860"
      },
      "outputs": [],
      "source": [
        "class RecursiveBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single recursive block for the TRM.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm_state = nn.LayerNorm(d_model)\n",
        "        self.norm_input = nn.LayerNorm(d_model)\n",
        "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
        "        self.activation = nn.GELU()\n",
        "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        \"\"\"\n",
        "        Forward pass for the recursive block.\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
        "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
        "        \"\"\"\n",
        "        normalized_state = self.norm_state(state)\n",
        "        normalized_input = self.norm_input(x)\n",
        "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
        "        hidden = self.linear1(combined_input)\n",
        "        hidden = self.activation(hidden)\n",
        "        processed_output = self.linear2(hidden)\n",
        "        new_state = state + processed_output[:, :self.d_model]\n",
        "        output = processed_output[:, self.d_model:]\n",
        "        return output, new_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec8cebbb",
      "metadata": {
        "id": "ec8cebbb"
      },
      "source": [
        "## 2. The TRM Model: Processing Sequences\n",
        "\n",
        "The full TRM model wraps the `RecursiveBlock`. It initializes the hidden state (usually with zeros) and then iterates through the input sequence, feeding each element into the recursive block one at a time. This step-by-step processing is the core of its operation.\n",
        "\n",
        "We also add input and output embedding layers to map our vocabulary to the model's dimension and back.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7975363",
      "metadata": {
        "id": "c7975363"
      },
      "outputs": [],
      "source": [
        "class TRM(nn.Module):\n",
        "    \"\"\"\n",
        "    The Tiny Recursive Model.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.recursive_block = RecursiveBlock(d_model)\n",
        "        self.norm_out = nn.LayerNorm(d_model)\n",
        "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        \"\"\"\n",
        "        Forward pass for the entire sequence.\n",
        "        Args:\n",
        "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
        "        Returns:\n",
        "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = input_sequence.shape\n",
        "        embedded_input = self.embedding(input_sequence)\n",
        "\n",
        "        # Initialize the hidden state on the same device as the input\n",
        "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
        "\n",
        "        outputs = []\n",
        "        for i in range(seq_len):\n",
        "            step_input = embedded_input[:, i, :]\n",
        "            output, state = self.recursive_block(step_input, state)\n",
        "            outputs.append(output)\n",
        "\n",
        "        outputs_tensor = torch.stack(outputs, dim=1)\n",
        "        normalized_outputs = self.norm_out(outputs_tensor)\n",
        "        logits = self.output_linear(normalized_outputs)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de31e0a8",
      "metadata": {
        "id": "de31e0a8"
      },
      "source": [
        "## 3. Forward Pass Demonstration\n",
        "\n",
        "Let's create a dummy input sequence and pass it through our model to see the shapes of the tensors at each step. We'll make sure to move both the model and the data to our selected device (GPU or CPU).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63394e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d63394e3",
        "outputId": "0a974d45-595e-4b62-c3b1-61c8db669345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "TRM(\n",
            "  (embedding): Embedding(20, 32)\n",
            "  (recursive_block): RecursiveBlock(\n",
            "    (norm_state): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm_input): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (activation): GELU(approximate='none')\n",
            "    (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  )\n",
            "  (norm_out): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "  (output_linear): Linear(in_features=32, out_features=20, bias=True)\n",
            ")\n",
            "\n",
            "Dummy Input Shape: torch.Size([1, 5])\n",
            "Dummy Input Tensor:\n",
            "tensor([[11,  5, 18, 12, 12]], device='cuda:0')\n",
            "\n",
            "Output Logits Shape: torch.Size([1, 5, 20])\n",
            "This shape (batch_size, seq_len, vocab_size) is what we expect!\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = 20\n",
        "D_MODEL = 32\n",
        "SEQ_LEN = 5\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# Instantiate the model and move it to the configured device\n",
        "model = TRM(vocab_size=VOCAB_SIZE, d_model=D_MODEL).to(device)\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "\n",
        "# Create a dummy input sequence and move it to the device\n",
        "dummy_input = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(device)\n",
        "print(f\"\\nDummy Input Shape: {dummy_input.shape}\")\n",
        "print(f\"Dummy Input Tensor:\\n{dummy_input}\")\n",
        "\n",
        "# Perform a forward pass\n",
        "output_logits = model(dummy_input)\n",
        "\n",
        "print(f\"\\nOutput Logits Shape: {output_logits.shape}\")\n",
        "print(\"This shape (batch_size, seq_len, vocab_size) is what we expect!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312ffe3d",
      "metadata": {
        "id": "312ffe3d"
      },
      "source": [
        "## 4. A Simple Training Example\n",
        "\n",
        "To show that the model can learn, let's create a simple \"next token prediction\" task. The goal is to train the model to predict the next number in a sequence.\n",
        "\n",
        "-   **Input:** `[1, 2, 3, 4]`\n",
        "-   **Target:** `[2, 3, 4, 5]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0e532b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0e532b",
        "outputId": "67765303-d245-4e66-ab15-c976cea0504e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  [1, 2, 3, 4]\n",
            "Target: [2, 3, 4, 5]\n",
            "Epoch [10/100], Loss: 0.3124\n",
            "Epoch [20/100], Loss: 0.0543\n",
            "Epoch [30/100], Loss: 0.0162\n",
            "Epoch [40/100], Loss: 0.0081\n",
            "Epoch [50/100], Loss: 0.0054\n",
            "Epoch [60/100], Loss: 0.0043\n",
            "Epoch [70/100], Loss: 0.0036\n",
            "Epoch [80/100], Loss: 0.0031\n",
            "Epoch [90/100], Loss: 0.0028\n",
            "Epoch [100/100], Loss: 0.0025\n",
            "\n",
            "--- Testing after training ---\n",
            "Input:              [1, 2, 3, 4]\n",
            "Predicted sequence: [2, 3, 4, 5]\n",
            "Target sequence:    [2, 3, 4, 5]\n",
            "\n",
            "The model has learned to predict the next number!\n"
          ]
        }
      ],
      "source": [
        "TRAINING_VOCAB_SIZE = 10\n",
        "TRAINING_D_MODEL = 16\n",
        "\n",
        "# Create a new model instance for training and move to device\n",
        "training_model = TRM(vocab_size=TRAINING_VOCAB_SIZE, d_model=TRAINING_D_MODEL).to(device)\n",
        "optimizer = optim.Adam(training_model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Data - move to device\n",
        "input_data = torch.tensor([[1, 2, 3, 4]]).to(device)\n",
        "target_data = torch.tensor([[2, 3, 4, 5]]).to(device)\n",
        "\n",
        "print(f\"Input:  {input_data[0].tolist()}\")\n",
        "print(f\"Target: {target_data[0].tolist()}\")\n",
        "\n",
        "# Training Loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    logits = training_model(input_data)\n",
        "    loss = criterion(logits.view(-1, TRAINING_VOCAB_SIZE), target_data.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Inference after training\n",
        "print(\"\\n--- Testing after training ---\")\n",
        "with torch.no_grad():\n",
        "    predictions = training_model(input_data)\n",
        "    predicted_ids = torch.argmax(predictions, dim=2)\n",
        "\n",
        "    print(f\"Input:              {input_data[0].tolist()}\")\n",
        "    print(f\"Predicted sequence: {predicted_ids[0].tolist()}\")\n",
        "    print(f\"Target sequence:    {target_data[0].tolist()}\")\n",
        "    print(\"\\nThe model has learned to predict the next number!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7ee555",
      "metadata": {
        "id": "6b7ee555"
      },
      "source": [
        "## 5. Advanced Example: Solving 5x5 Mazes\n",
        "\n",
        "Now for a more challenging task. Let's train the TRM to solve 5x5 mazes.\n",
        "\n",
        "**The Task:** We provide the model with a sequence representing the maze structure and the starting position. Its goal is to predict the sequence of coordinates that solves the maze.\n",
        "\n",
        "**Data:** We will programmatically generate a dataset of **100 random mazes** for training and test its generalization on one **unseen maze**.\n",
        "\n",
        "**Data Representation:**\n",
        "- **Vocabulary:**\n",
        "    - `0`: Wall (`#`), `1`: Path (`.`), `2`: Start (`S`), `3`: End (`E`)\n",
        "    - `4`: Separator (`|`)\n",
        "    - `5-29`: Path Coordinates, mapping each cell `(row, col)` to a unique token `5 + row * 5 + col`.\n",
        "- **Loss Mask:** We only care about predicting the path. We will use a **loss mask** to ignore the model's predictions for the maze layout part of the sequence during training. This focuses the model on the solving task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420433a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420433a4",
        "outputId": "ee54e6a6-e1a0-466c-e7de-d5e9fa93f5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset of 100 mazes... this may take a moment.\n",
            "Generated 100 training mazes.\n",
            "Generated unseen test maze.\n"
          ]
        }
      ],
      "source": [
        "from collections import deque\n",
        "\n",
        "# --- Maze Generation Helper ---\n",
        "def generate_random_maze(size=5):\n",
        "    # 0: Wall, 1: Path, 2: Start, 3: End\n",
        "    while True:\n",
        "        # Create a grid of all paths (1)\n",
        "        maze = [[1 for _ in range(size)] for _ in range(size)]\n",
        "\n",
        "        # Add random walls (0) with ~30% probability\n",
        "        # Keep (0,0) and (size-1, size-1) clear for Start/End\n",
        "        for r in range(size):\n",
        "            for c in range(size):\n",
        "                if (r == 0 and c == 0) or (r == size-1 and c == size-1):\n",
        "                    continue\n",
        "                if random.random() < 0.3:\n",
        "                    maze[r][c] = 0\n",
        "\n",
        "        maze[0][0] = 2\n",
        "        maze[size-1][size-1] = 3\n",
        "\n",
        "        # BFS to find shortest path\n",
        "        queue = deque([(0, 0, [])])\n",
        "        visited = set([(0,0)])\n",
        "        solution = None\n",
        "\n",
        "        while queue:\n",
        "            r, c, path = queue.popleft()\n",
        "            current_path = path + [(r, c)]\n",
        "\n",
        "            if r == size-1 and c == size-1:\n",
        "                solution = current_path\n",
        "                break\n",
        "\n",
        "            for dr, dc in [(0,1), (0,-1), (1,0), (-1,0)]:\n",
        "                nr, nc = r + dr, c + dc\n",
        "                if 0 <= nr < size and 0 <= nc < size and maze[nr][nc] != 0 and (nr, nc) not in visited:\n",
        "                    visited.add((nr, nc))\n",
        "                    queue.append((nr, nc, current_path))\n",
        "\n",
        "        if solution:\n",
        "            return {\"maze\": maze, \"path\": solution}\n",
        "\n",
        "# --- Generate Datasets ---\n",
        "print(\"Generating dataset of 100 mazes... this may take a moment.\")\n",
        "MAZE_DATASET = []\n",
        "hashes = set()\n",
        "\n",
        "# Generate 100 unique training mazes\n",
        "while len(MAZE_DATASET) < 100:\n",
        "    data = generate_random_maze()\n",
        "    # Create a hashable representation (tuple of tuples) to ensure uniqueness\n",
        "    maze_tuple = tuple(tuple(row) for row in data[\"maze\"])\n",
        "    if maze_tuple not in hashes:\n",
        "        hashes.add(maze_tuple)\n",
        "        MAZE_DATASET.append(data)\n",
        "\n",
        "print(f\"Generated {len(MAZE_DATASET)} training mazes.\")\n",
        "\n",
        "# Generate one unseen maze for testing that isn't in the training set\n",
        "while True:\n",
        "    UNSEEN_MAZE = generate_random_maze()\n",
        "    maze_tuple = tuple(tuple(row) for row in UNSEEN_MAZE[\"maze\"])\n",
        "    if maze_tuple not in hashes:\n",
        "        break\n",
        "\n",
        "print(\"Generated unseen test maze.\")\n",
        "\n",
        "# --- Vocabulary and Preprocessing ---\n",
        "WALL, PATH, START, END, SEP = 0, 1, 2, 3, 4\n",
        "PATH_TOKEN_OFFSET = 5\n",
        "MAZE_SIZE = 5\n",
        "MAZE_TOKENS = MAZE_SIZE * MAZE_SIZE\n",
        "\n",
        "def preprocess_maze_data(dataset):\n",
        "    sequences = []\n",
        "    for item in dataset:\n",
        "        maze_flat = [token for row in item[\"maze\"] for token in row]\n",
        "        path_tokens = [PATH_TOKEN_OFFSET + r * MAZE_SIZE + c for r, c in item[\"path\"]]\n",
        "        full_sequence = maze_flat + [SEP] + path_tokens\n",
        "        sequences.append(torch.tensor(full_sequence))\n",
        "    return sequences\n",
        "\n",
        "training_sequences = preprocess_maze_data(MAZE_DATASET)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fa8c5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "58fa8c5b",
        "outputId": "9910f929-69d3-4df0-e2fa-5e615a6aee8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting maze training with TRM-style deep supervision...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_trm_deepsup' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1590632526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Use train_trm_deepsup from appended utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m train_trm_deepsup(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmaze_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmaze_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_trm_deepsup' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Maze Model Training (TRM Deep Supervision) ---\n",
        "print(\"Starting maze training with TRM-style deep supervision...\")\n",
        "\n",
        "# Wrap training sequences into a simple DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class MazeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, seqs):\n",
        "        self.seqs = seqs\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx]\n",
        "        x = seq[:-1]\n",
        "        y = seq[1:]\n",
        "        return x, y\n",
        "\n",
        "maze_dataset = MazeDataset(training_sequences)\n",
        "maze_loader = DataLoader(maze_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Use train_trm_deepsup from appended utilities\n",
        "train_trm_deepsup(\n",
        "    maze_model,\n",
        "    maze_optimizer,\n",
        "    nn.CrossEntropyLoss(),\n",
        "    maze_loader,\n",
        "    device,\n",
        "    epochs=150,\n",
        "    Nsup=4,\n",
        "    n_inner=4\n",
        ")\n",
        "\n",
        "print(\"Maze training finished (TRM deep supervision).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fed656a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "8fed656a",
        "outputId": "63209c44-5ac7-4e18-81d8-5505208f96fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'maze_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2341952237.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Test with the unseen maze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0munseen_maze_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNSEEN_MAZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"maze\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mpredicted_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_maze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munseen_maze_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unseen Maze to solve:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'maze_model' is not defined"
          ]
        }
      ],
      "source": [
        "# --- Inference on an Unseen Maze ---\n",
        "def solve_maze(model, maze_grid, device, max_len=30):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "\n",
        "    maze_flat = [token for row in maze_grid for token in row]\n",
        "\n",
        "    # Find start position to begin generation\n",
        "    start_pos_flat = maze_flat.index(START)\n",
        "    start_r, start_c = divmod(start_pos_flat, MAZE_SIZE)\n",
        "    start_path_token = PATH_TOKEN_OFFSET + start_r * MAZE_SIZE + start_c\n",
        "\n",
        "    # Initial input: maze layout + separator + start token, moved to device\n",
        "    input_seq = torch.tensor(maze_flat + [SEP] + [start_path_token]).unsqueeze(0).to(device)\n",
        "\n",
        "    generated_path_tokens = [start_path_token]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len - 1):\n",
        "            logits = model(input_seq)\n",
        "\n",
        "            # Get the prediction for the very last token in the sequence\n",
        "            next_token_logits = logits[:, -1, :]\n",
        "            predicted_token = torch.argmax(next_token_logits, dim=1).item()\n",
        "\n",
        "            generated_path_tokens.append(predicted_token)\n",
        "            # Append the prediction and update the input for the next step\n",
        "            input_seq = torch.cat([input_seq, torch.tensor([[predicted_token]], device=device)], dim=1)\n",
        "\n",
        "            # Stop if we predict the end token\n",
        "            end_pos_flat = maze_flat.index(END)\n",
        "            end_r, end_c = divmod(end_pos_flat, MAZE_SIZE)\n",
        "            end_path_token = PATH_TOKEN_OFFSET + end_r * MAZE_SIZE + end_c\n",
        "            if predicted_token == end_path_token:\n",
        "                break\n",
        "\n",
        "    # Convert token IDs back to (row, col) coordinates\n",
        "    path_coords = []\n",
        "    for token in generated_path_tokens:\n",
        "        flat_pos = token - PATH_TOKEN_OFFSET\n",
        "        r, c = divmod(flat_pos, MAZE_SIZE)\n",
        "        path_coords.append((r, c))\n",
        "\n",
        "    return path_coords\n",
        "\n",
        "# --- Verification Logic ---\n",
        "def verify_path(maze_grid, path):\n",
        "    print(\"\\nVerifying solution...\")\n",
        "\n",
        "    if not path:\n",
        "        return False, \"Path is empty.\"\n",
        "\n",
        "    # Check Start\n",
        "    start_r, start_c = path[0]\n",
        "    if maze_grid[start_r][start_c] != START:\n",
        "        return False, f\"Path starts at ({start_r}, {start_c}) but maze start is not there.\"\n",
        "\n",
        "    # Check End\n",
        "    end_r, end_c = path[-1]\n",
        "    if maze_grid[end_r][end_c] != END:\n",
        "        return False, f\"Path ends at ({end_r}, {end_c}) but maze end is not there.\"\n",
        "\n",
        "    # Check Validity of steps\n",
        "    for i in range(len(path) - 1):\n",
        "        r1, c1 = path[i]\n",
        "        r2, c2 = path[i+1]\n",
        "\n",
        "        # Adjacency\n",
        "        if abs(r1 - r2) + abs(c1 - c2) != 1:\n",
        "            return False, f\"Invalid jump from ({r1},{c1}) to ({r2},{c2}).\"\n",
        "\n",
        "        # Wall collision\n",
        "        if maze_grid[r2][c2] == WALL:\n",
        "            return False, f\"Step ({r2},{c2}) hits a wall.\"\n",
        "\n",
        "    return True, \"Path is valid!\"\n",
        "\n",
        "# Test with the unseen maze\n",
        "unseen_maze_grid = UNSEEN_MAZE[\"maze\"]\n",
        "predicted_path = solve_maze(maze_model, unseen_maze_grid, device=device)\n",
        "\n",
        "print(\"Unseen Maze to solve:\")\n",
        "for row in unseen_maze_grid:\n",
        "     print(\"\".join([{0:'#', 1:'.', 2:'S', 3:'E'}[c] for c in row]))\n",
        "\n",
        "print(f\"\\nPredicted Path (coordinates):\\n{predicted_path}\")\n",
        "print(f\"\\nCorrect Path (coordinates):\\n{UNSEEN_MAZE['path']}\")\n",
        "\n",
        "# Run verification\n",
        "valid, msg = verify_path(unseen_maze_grid, predicted_path)\n",
        "print(f\"Verification Result: {msg}\")\n",
        "if valid:\n",
        "  print(\"SUCCESS: The model solved the unseen maze!\")\n",
        "else:\n",
        "  print(\"FAILURE: The model failed to solve the maze.\")\n",
        "\n",
        "# Visualize the path\n",
        "print(\"\\nVisualized solution (* = predicted path):\")\n",
        "for r in range(MAZE_SIZE):\n",
        "    line = \"\"\n",
        "    for c in range(MAZE_SIZE):\n",
        "        if unseen_maze_grid[r][c] == WALL:\n",
        "            line += '#'\n",
        "        elif (r,c) in predicted_path:\n",
        "            line += '*'\n",
        "        else:\n",
        "            line += '.'\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5874d52",
      "metadata": {
        "id": "f5874d52"
      },
      "source": [
        "The model learns a general strategy for solving mazes, which it can then apply to a new maze it has never encountered during training. This demonstrates the TRM's ability to handle structured sequence-to-sequence tasks that require understanding a context (the maze layout) to generate a relevant output (the path).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a62810f0",
      "metadata": {
        "id": "a62810f0"
      },
      "source": [
        "## 6. Conclusion\n",
        "\n",
        "This notebook provided a brief, practical introduction to Tiny Recursive Models. We implemented the core components in PyTorch, demonstrated its learning capability on a simple task, and then successfully trained it to solve a complex maze-solving problem, verifying its generalization on unseen data.\n",
        "\n",
        "TRMs offer an interesting alternative to Transformers, particularly for applications where computational efficiency and explicit state management are important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67953df7",
      "metadata": {
        "id": "67953df7"
      },
      "source": [
        "\n",
        "## Added: Deep-supervision training utilities (TRM-style)\n",
        "The following cells implement a training wrapper that performs `Nsup` supervised improvement steps, and an `inner_recursive_updates`\n",
        "function that runs several inner recursion steps with `torch.no_grad()` for all but the final step (the 1-step gradient approximation).\n",
        "Use these utilities instead of the notebook's original training loop to get behaviour closer to the TRM paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55503e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "d55503e9",
        "outputId": "0cfaac51-d333-489b-aadd-fd7d2dcf772c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (ipython-input-891387040.py, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-891387040.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    \\\"\\\"\\\"Run n_inner recursive updates on latent z using the model's forward-step function.\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Optional\n",
        "\n",
        "def inner_recursive_updates(model: nn.Module, z: torch.Tensor, x: Optional[torch.Tensor]=None,\n",
        "                            n_inner: int = 4, device: Optional[torch.device]=None, **forward_kwargs):\n",
        "    \"\"\"Run n_inner recursive updates on latent z using the model's forward-step function.\n",
        "    Behavior expected from `model`:\n",
        "      - model should implement a method `step(z, x, **kwargs)` or callable `model(z, x, **kwargs)` that returns new z.\n",
        "      - If the notebook's model exposes a different API, pass a wrapper into forward_kwargs like step_fn=...\n",
        "    Strategy:\n",
        "      - Run (n_inner - 1) steps in torch.no_grad() to avoid computing gradients for intermediate steps.\n",
        "      - Run the final step normally to allow gradients to flow into that last step (1-step gradient approx).\n",
        "    Returns final z (with gradients) and the intermediate ungrad z from previous steps (detached).\n",
        "    \"\"\"\n",
        "    step_fn = forward_kwargs.pop('step_fn', None)\n",
        "    if step_fn is None:\n",
        "        # try common names\n",
        "        if hasattr(model, 'step'):\n",
        "            step_fn = model.step\n",
        "        else:\n",
        "            # fallback to calling model as a function: model(z, x, **kwargs)\n",
        "            step_fn = lambda z_, x_, **kw: model(z_, x_, **kw)\n",
        "    # run intermediate steps without grad\n",
        "    z_cur = z\n",
        "    for _ in range(max(0, n_inner - 1)):\n",
        "        with torch.no_grad():\n",
        "            z_cur = step_fn(z_cur, x, **forward_kwargs)\n",
        "    # final step with grad\n",
        "    z_final = step_fn(z_cur, x, **forward_kwargs)\n",
        "    return z_final\n",
        "\n",
        "def default_answer_head(model: nn.Module, z: torch.Tensor, **kwargs):\n",
        "    \"\"\"Try to produce an answer/prediction y from z.\n",
        "    The notebook likely has a head named `head` or `output_layer`. We'll try to use them,\n",
        "    otherwise we fall back to a linear layer temporarily created (not trained).\n",
        "    \"\"\"\n",
        "    # Prefer user-provided heads if present\n",
        "    if hasattr(model, 'head'):\n",
        "        return model.head(z)\n",
        "    if hasattr(model, 'output_layer'):\n",
        "        return model.output_layer(z)\n",
        "    # fallback: if model has attribute `vocab_size` or `num_classes`, create a linear layer (on-the-fly)\n",
        "    if hasattr(model, 'vocab_size'):\n",
        "        out_dim = int(model.vocab_size)\n",
        "    elif hasattr(model, 'num_classes'):\n",
        "        out_dim = int(model.num_classes)\n",
        "    else:\n",
        "        # can't guess â€” return z directly\n",
        "        return z\n",
        "    temp_head = nn.Linear(z.size(-1), out_dim).to(z.device)\n",
        "    return temp_head(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cac2bf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4cac2bf1",
        "outputId": "3763985d-09de-4734-dec3-cd7327752855"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (ipython-input-2000704924.py, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2000704924.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \\\"\\\"\\\"Run a single training step with deep supervision.\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "# Deep-supervision training step.\n",
        "# This function accumulates the supervised loss across Nsup steps (as in the TRM paper).\n",
        "def train_step_deepsup(model: nn.Module, optimizer: torch.optim.Optimizer, criterion, batch, device: torch.device,\n",
        "                       Nsup: int = 4, n_inner: int = 4, detach_between_sup: bool = True, step_fn=None, answer_fn=None):\n",
        "    \"\"\"Run a single training step with deep supervision.\n",
        "    - model: your TRM model (must accept z updates via step_fn or model.step)\n",
        "    - optimizer, criterion: usual objects\n",
        "    - batch: training batch (caller must know structure: typically inputs, targets)\n",
        "    - device: torch device\n",
        "    - Nsup: number of supervised improvement steps (outer loop)\n",
        "    - n_inner: number of inner recursive updates per supervision step\n",
        "    - detach_between_sup: whether to .detach() the latent z between supervision steps (as paper suggests)\n",
        "    - step_fn: optional function(z, x, **kwargs)->z to perform one recursive update. If omitted, inferred.\n",
        "    - answer_fn: optional function(model, z)->y to produce predictions from z. If omitted, attempts common names.\n",
        "    Returns loss (scalar tensor).\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    # User must provide how to extract x and target from batch.\n",
        "    # We'll support common patterns: (x, target) or dict with keys 'x' and 'y' or 'input'/'target'.\n",
        "    if isinstance(batch, (list, tuple)) and len(batch) >= 2:\n",
        "        x, target = batch[0], batch[1]\n",
        "    elif isinstance(batch, dict):\n",
        "        x = batch.get('x', batch.get('input', None))\n",
        "        target = batch.get('y', batch.get('target', None))\n",
        "    else:\n",
        "        raise ValueError('Unrecognized batch format for train_step_deepsup. Provide (x, target) or dict.')\n",
        "    x = x.to(device) if isinstance(x, torch.Tensor) else x\n",
        "    target = target.to(device) if isinstance(target, torch.Tensor) else target\n",
        "\n",
        "    # initialize latent z; prefer a model-provided initializer\n",
        "    if hasattr(model, 'init_z'):\n",
        "        z = model.init_z(x).to(device)\n",
        "    elif hasattr(model, 'init_state'):\n",
        "        z = model.init_state(x).to(device)\n",
        "    else:\n",
        "        # fallback: use zeros with hidden size guess\n",
        "        hidden_size = getattr(model, 'hidden_size', getattr(model, 'd_model', None))\n",
        "        if hidden_size is None:\n",
        "            # try run a single forward to get a z (not ideal but robust)\n",
        "            with torch.no_grad():\n",
        "                try:\n",
        "                    trial = model(x)\n",
        "                    # attempt to treat trial as a dict or tuple\n",
        "                    if isinstance(trial, dict) and 'z' in trial:\n",
        "                        z = trial['z'].detach().clone().to(device)\n",
        "                    elif isinstance(trial, (list, tuple)) and len(trial) >= 1:\n",
        "                        z = trial[0].detach().clone().to(device)\n",
        "                    else:\n",
        "                        # as last resort, make zeros with batch dimension\n",
        "                        bsz = x.size(0) if hasattr(x, 'size') else 1\n",
        "                        hidden_size = trial.size(-1) if hasattr(trial, 'size') else 128\n",
        "                        z = torch.zeros(bsz, hidden_size, device=device)\n",
        "                except Exception as e:\n",
        "                    # cannot infer; create small zeros\n",
        "                    z = torch.zeros( (x.size(0) if hasattr(x, 'size') else 1, 128), device=device)\n",
        "\n",
        "    loss_total = 0.0\n",
        "    for s in range(Nsup):\n",
        "        # run inner recursion: many steps but only last contributes to gradient\n",
        "        z = inner_recursive_updates(model, z, x=x, n_inner=n_inner, device=device, step_fn=step_fn)\n",
        "        # produce answer y\n",
        "        if answer_fn is None:\n",
        "            y_pred = default_answer_head(model, z)\n",
        "        else:\n",
        "            y_pred = answer_fn(model, z)\n",
        "        # compute supervised loss (supporting classification or regression)\n",
        "        if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "            # expect target to be LongTensor of class indices\n",
        "            loss = criterion(y_pred, target.long())\n",
        "        else:\n",
        "            # generic loss: assume shapes align\n",
        "            loss = criterion(y_pred, target)\n",
        "        loss_total = loss_total + loss\n",
        "        # detach z between supervision steps to match paper's detach strategy (if requested)\n",
        "        if detach_between_sup and (s < Nsup - 1):\n",
        "            z = z.detach()\n",
        "    # average loss across supervision steps\n",
        "    loss_avg = loss_total / float(Nsup)\n",
        "    loss_avg.backward()\n",
        "    optimizer.step()\n",
        "    return loss_avg.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9a9b1c",
      "metadata": {
        "id": "bd9a9b1c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example training loop wrapper that uses train_step_deepsup.\n",
        "def train_trm_deepsup(model, optimizer, criterion, dataloader, device, epochs=3,\n",
        "                      Nsup=4, n_inner=4, detach_between_sup=True, step_fn=None, answer_fn=None, log_every=10):\n",
        "    for epoch in range(epochs):\n",
        "        running = 0.0\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            loss = train_step_deepsup(model, optimizer, criterion, batch, device,\n",
        "                                     Nsup=Nsup, n_inner=n_inner, detach_between_sup=detach_between_sup,\n",
        "                                     step_fn=step_fn, answer_fn=answer_fn)\n",
        "            running += loss\n",
        "            if (i + 1) % log_every == 0:\n",
        "                print(f\\\"Epoch {epoch+1} | batch {i+1} | avg loss {running/log_every:.4f}\\\")\n",
        "                running = 0.0\n",
        "    print('Finished training (deep-supervision wrapper).')\n",
        "\n",
        "\n",
        "# Usage notes (show to the user):\n",
        "print(\\\"\\\\n--- TRM deep-supervision utilities loaded. To use them:\\\\n\\\"\\\n",
        "      \\\"1) Call train_trm_deepsup(model, optimizer, criterion, train_loader, device, Nsup=..., n_inner=... )\\\\n\\\"\\\n",
        "      \\\"2) If your model uses a custom step API, pass step_fn=model.step or a wrapper step_fn.\\\\n\\\"\\\n",
        "      \\\"3) If your model provides an answer head, default_answer_head will use model.head or model.output_layer.\\\\n\\\" )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}