{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/Samsung_TRM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3j4YpJxbuO1"
      },
      "source": [
        "\n",
        "# Less is More: Recursive Reasoning with Tiny Networks (TRM)\n",
        "\n",
        "This notebook implements the Tiny Recursion Model (TRM) from the paper:\n",
        "\"Less is More: Recursive Reasoning with Tiny Networks\"\n",
        "\n",
        "**Key Features:**\n",
        "- 45% accuracy on ARC-AGI-1 with only 7M parameters\n",
        "- 8% accuracy on ARC-AGI-2\n",
        "- Recursive reasoning without massive models\n",
        "\n",
        "**Paper:** https://arxiv.org/abs/2510.04871\n",
        "\n",
        "**Original Code:** Based on Hierarchical Reasoning Model (HRM)\n",
        "\n",
        "**Runtime Requirements:**\n",
        "- ARC-AGI training: ~3 days on 4x H-100 GPUs\n",
        "- Sudoku-Extreme: <36 hours on 1x L40S GPU\n",
        "- Maze-Hard: <24 hours on 4x L40S GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Gd5biGbuO7"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7zRSLe6buO8",
        "outputId": "f2f8e45e-4d04-4366-9a24-ba3eef722e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU and System Info\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EXEFWxMbuO-",
        "outputId": "7ae9225f-061d-429a-92f1-77cca3512ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Samsung-TRM'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 58 (delta 16), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (58/58), 722.67 KiB | 1.17 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 606.62 KiB | 336.00 KiB/s, done.\n",
            "/content/Samsung-TRM\n"
          ]
        }
      ],
      "source": [
        "# Clone Repository\n",
        "!git clone https://huggingface.co/wtfmahe/Samsung-TRM\n",
        "%cd Samsung-TRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQbVxFpFbuO_",
        "outputId": "7118f346-9e74-4165-cfe2-65d13277f992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.6/1.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for adam-atan2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Dependencies\n",
        "# Note: Adjust PyTorch installation based on your CUDA version\n",
        "\n",
        "# Upgrade pip and core tools\n",
        "!pip install --upgrade pip wheel setuptools -q\n",
        "\n",
        "# Install PyTorch (adjust for your CUDA version)\n",
        "# For Colab with CUDA 12.x:\n",
        "!pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121 -q\n",
        "\n",
        "# Install other requirements\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Install adam-atan2 optimizer\n",
        "!pip install --no-cache-dir --no-build-isolation adam-atan2 -q\n",
        "\n",
        "print(\"✓ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctTOsLVJbuPA",
        "outputId": "c1f05294-fc51-4044-d703-ee2b1e461013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mweagan\u001b[0m (\u001b[33mweagan-abc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "# Option 1: Login interactively\n",
        "#wandb.login()\n",
        "\n",
        "# Option 2: Login with API key from Colab secrets\n",
        "wandb.login(key=userdata.get('W&B_Key'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV6xkMv_buPA"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "kaggle_json_content = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Create .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle/\n",
        "\n",
        "# Write the Kaggle API key to kaggle.json\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
        "    f.write(kaggle_json_content)\n",
        "\n",
        "# Set permissions for kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API configured successfully!\")"
      ],
      "metadata": {
        "id": "58a18109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b00069-c582-4867-b902-d93df566d5ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AV6wgFC3buPB"
      },
      "outputs": [],
      "source": [
        "# Download ARC-AGI Dataset\n",
        "# You'll need Kaggle API credentials configured\n",
        "\n",
        "# Create kaggle directory\n",
        "!mkdir -p kaggle/combined\n",
        "\n",
        "# Download ARC-AGI dataset\n",
        "# Note: You need to accept competition rules and have kaggle.json configured\n",
        "# !kaggle competitions download -c arc-prize-2024\n",
        "# !unzip -q arc-prize-2024.zip -d kaggle/combined/\n",
        "\n",
        "# print(\"✓ ARC-AGI dataset downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Th5ZKiR4mqNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#!git clone https://github.com/fchollet/ARC\n"
      ],
      "metadata": {
        "id": "V3xIYWlikPt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d namank24/arc-prize-2024-dataset\n",
        "!unzip -q arc-prize-2024-dataset.zip -d kaggle/combined/\n",
        "#!unzip arc-prize-2024-dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xIbYCXRkwWc",
        "outputId": "619e4def-52a8-4fc8-c320-3bf739c6ca94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/namank24/arc-prize-2024-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading arc-prize-2024-dataset.zip to /content/Samsung-TRM\n",
            "  0% 0.00/150k [00:00<?, ?B/s]\n",
            "100% 150k/150k [00:00<00:00, 373MB/s]\n",
            "replace kaggle/combined/arc-agi_evaluation_challenges.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLPwD9M6buPB",
        "outputId": "2a0ce71c-6ce6-44b8-cece-d0afbc70598b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Puzzle 8be77c9e] augmentation not full, only 72\n",
            "[Puzzle 4258a5f9] augmentation not full, only 576\n",
            "[Puzzle 3618c87e] augmentation not full, only 575\n",
            "[Puzzle 2281f1f4] augmentation not full, only 576\n",
            "[Puzzle 3906de3d] augmentation not full, only 576\n",
            "[Puzzle aedd82e4] augmentation not full, only 576\n",
            "[Puzzle 4612dd53] augmentation not full, only 575\n",
            "[Puzzle 28e73c20] augmentation not full, only 72\n",
            "[Puzzle f15e1fac] augmentation not full, only 576\n",
            "[Puzzle 44d8ac46] augmentation not full, only 576\n",
            "[Puzzle dc433765] augmentation not full, only 575\n",
            "[Puzzle a5313dff] augmentation not full, only 576\n",
            "[Puzzle 3f7978a0] augmentation not full, only 576\n",
            "[Puzzle d4f3cd78] augmentation not full, only 576\n",
            "[Puzzle 760b3cac] augmentation not full, only 576\n",
            "[Puzzle cce03e0d] augmentation not full, only 576\n",
            "[Puzzle ef135b50] augmentation not full, only 576\n",
            "[Puzzle a3df8b1e] augmentation not full, only 72\n",
            "[Puzzle 6855a6e4] augmentation not full, only 576\n",
            "[Puzzle 05f2a901] augmentation not full, only 575\n",
            "[Puzzle ded97339] augmentation not full, only 72\n",
            "[Puzzle dbc1a6ce] augmentation not full, only 575\n",
            "[Puzzle b60334d2] augmentation not full, only 576\n",
            "[Puzzle db3e9e38] augmentation not full, only 576\n",
            "[Puzzle 7447852a] augmentation not full, only 576\n",
            "[Puzzle 80af3007] augmentation not full, only 72\n",
            "[Puzzle 90f3ed37] augmentation not full, only 576\n",
            "[Puzzle ba26e723] augmentation not full, only 576\n",
            "[Puzzle 4938f0c2] augmentation not full, only 576\n",
            "[Puzzle 6d75e8bb] augmentation not full, only 576\n",
            "[Puzzle 4522001f] augmentation not full, only 288\n",
            "[Puzzle ce22a75a] augmentation not full, only 576\n",
            "[Puzzle ff28f65a] augmentation not full, only 576\n",
            "[Puzzle 1fad071e] augmentation not full, only 576\n",
            "[Puzzle d0f5fe59] augmentation not full, only 72\n",
            "[Puzzle 810b9b61] augmentation not full, only 576\n",
            "[Puzzle 67385a82] augmentation not full, only 575\n",
            "[Puzzle d5d6de2d] augmentation not full, only 576\n",
            "[Puzzle 794b24be] augmentation not full, only 576\n",
            "[Puzzle b27ca6d3] augmentation not full, only 576\n",
            "[Puzzle e5062a87] augmentation not full, only 576\n",
            "[Puzzle 017c7c7b] augmentation not full, only 575\n",
            "[Puzzle 1b60fb0c] augmentation not full, only 575\n",
            "[Puzzle ecdecbb3] augmentation not full, only 576\n",
            "[Puzzle d06dbe63] augmentation not full, only 576\n",
            "[Puzzle f8a8fe49] augmentation not full, only 576\n",
            "[Puzzle a48eeaf7] augmentation not full, only 576\n",
            "[Puzzle a1570a43] augmentation not full, only 576\n",
            "[Puzzle 6c434453] augmentation not full, only 576\n",
            "[Puzzle 6f8cd79b] augmentation not full, only 18\n",
            "[Puzzle af902bf9] augmentation not full, only 576\n",
            "[Puzzle 22233c11] augmentation not full, only 576\n",
            "[Puzzle c9e6f938] augmentation not full, only 72\n",
            "[Puzzle d406998b] augmentation not full, only 576\n",
            "[Puzzle 447fd412] augmentation not full, only 576\n",
            "[Puzzle 8efcae92] augmentation not full, only 576\n",
            "[Puzzle 239be575] augmentation not full, only 576\n",
            "[Puzzle e179c5f4] augmentation not full, only 576\n",
            "[Puzzle a79310a0] augmentation not full, only 576\n",
            "[Puzzle e9614598] augmentation not full, only 576\n",
            "[Puzzle 60b61512] augmentation not full, only 576\n",
            "[Puzzle 5c0a986e] augmentation not full, only 576\n",
            "[Puzzle e73095fd] augmentation not full, only 576\n",
            "[Puzzle b527c5c6] augmentation not full, only 576\n",
            "[Puzzle 7df24a62] augmentation not full, only 576\n",
            "[Puzzle 00d62c1b] augmentation not full, only 576\n",
            "[Puzzle 253bf280] augmentation not full, only 576\n",
            "[Puzzle 3aa6fb7a] augmentation not full, only 576\n",
            "[Puzzle 25ff71a9] augmentation not full, only 576\n",
            "[Puzzle a8d7556c] augmentation not full, only 576\n",
            "[Puzzle b0c4d837] augmentation not full, only 576\n",
            "[Puzzle f25fbde4] augmentation not full, only 72\n",
            "[Puzzle ce9e57f2] augmentation not full, only 576\n",
            "[Puzzle d9f24cd1] augmentation not full, only 576\n",
            "[Puzzle bb43febb] augmentation not full, only 576\n",
            "[Puzzle a699fb00] augmentation not full, only 576\n",
            "[Puzzle 5168d44c] augmentation not full, only 576\n",
            "[Puzzle ae4f1146] augmentation not full, only 576\n",
            "[Puzzle 4e469f39] augmentation not full, only 576\n",
            "[Puzzle 8719f442] augmentation not full, only 72\n",
            "[Puzzle 712bf12e] augmentation not full, only 576\n",
            "[Puzzle be03b35f] augmentation not full, only 576\n",
            "[Puzzle 0b17323b] augmentation not full, only 288\n",
            "[Puzzle b9630600] augmentation not full, only 72\n",
            "[Puzzle 817e6c09] augmentation not full, only 576\n",
            "[Puzzle 6f473927] augmentation not full, only 576\n",
            "[Puzzle 2697da3f] augmentation not full, only 72\n",
            "[Puzzle 7e02026e] augmentation not full, only 576\n",
            "[Puzzle ac0c5833] augmentation not full, only 576\n",
            "[Puzzle 73c3b0d8] augmentation not full, only 576\n",
            "[Puzzle 9bebae7a] augmentation not full, only 576\n",
            "[Puzzle 332efdb3] augmentation not full, only 9\n",
            "[Puzzle 9c56f360] augmentation not full, only 575\n",
            "[Puzzle 64a7c07e] augmentation not full, only 72\n",
            "[Puzzle 31adaf00] augmentation not full, only 576\n",
            "[Puzzle bf89d739] augmentation not full, only 575\n",
            "[Puzzle e6de6e8f] augmentation not full, only 576\n",
            "[Puzzle e7639916] augmentation not full, only 576\n",
            "[Puzzle dc2aa30b] augmentation not full, only 576\n",
            "[Puzzle c87289bb] augmentation not full, only 576\n",
            "[Puzzle ce039d91] augmentation not full, only 576\n",
            "[Puzzle baf41dbf] augmentation not full, only 576\n",
            "[Puzzle e1d2900e] augmentation not full, only 576\n",
            "[Puzzle fd4b2b02] augmentation not full, only 576\n",
            "[Puzzle f9a67cb5] augmentation not full, only 576\n",
            "[Puzzle e619ca6e] augmentation not full, only 72\n",
            "[Puzzle 759f3fd3] augmentation not full, only 576\n",
            "[Puzzle da515329] augmentation not full, only 72\n",
            "[Puzzle 0d87d2a6] augmentation not full, only 576\n",
            "[Puzzle 21f83797] augmentation not full, only 576\n",
            "[Puzzle ae58858e] augmentation not full, only 576\n",
            "[Puzzle 54db823b] augmentation not full, only 576\n",
            "[Puzzle 2c0b0aff] augmentation not full, only 576\n",
            "[Puzzle aa300dc3] augmentation not full, only 576\n",
            "[Puzzle 551d5bf1] augmentation not full, only 576\n",
            "[Puzzle 5b526a93] augmentation not full, only 576\n",
            "[Puzzle cb227835] augmentation not full, only 576\n",
            "[Puzzle d304284e] augmentation not full, only 576\n",
            "[Puzzle e0fb7511] augmentation not full, only 576\n",
            "[Puzzle 1c0d0a4b] augmentation not full, only 576\n",
            "[Puzzle e7dd8335] augmentation not full, only 576\n",
            "[Puzzle 20981f0e] augmentation not full, only 576\n",
            "[Puzzle 42a15761] augmentation not full, only 72\n",
            "[Puzzle 60a26a3e] augmentation not full, only 576\n",
            "[Puzzle d37a1ef5] augmentation not full, only 576\n",
            "[Puzzle c1990cce] augmentation not full, only 576\n",
            "[Puzzle 18419cfa] augmentation not full, only 576\n",
            "[Puzzle 8fbca751] augmentation not full, only 575\n",
            "[Puzzle e5c44e8f] augmentation not full, only 576\n",
            "[Puzzle a3f84088] augmentation not full, only 576\n",
            "[Puzzle c97c0139] augmentation not full, only 576\n",
            "[Puzzle 69889d6e] augmentation not full, only 576\n",
            "[Puzzle b1fc8b8e] augmentation not full, only 72\n",
            "[Puzzle 55059096] augmentation not full, only 576\n",
            "[Puzzle 1990f7a8] augmentation not full, only 72\n",
            "[Puzzle 4852f2fa] augmentation not full, only 576\n",
            "[Puzzle 9772c176] augmentation not full, only 576\n",
            "[Puzzle e872b94a] augmentation not full, only 72\n",
            "[Puzzle a934301b] augmentation not full, only 574\n",
            "[Puzzle bd14c3bf] augmentation not full, only 576\n",
            "[Puzzle CleanUp10] augmentation not full, only 72\n",
            "[Puzzle HorizontalVertical5] augmentation not full, only 575\n",
            "[Puzzle ExtendToBoundary6] augmentation not full, only 576\n",
            "[Puzzle InsideOutside3] augmentation not full, only 576\n",
            "[Puzzle CompleteShape5] augmentation not full, only 576\n",
            "[Puzzle Order5] augmentation not full, only 576\n",
            "[Puzzle Order9] augmentation not full, only 36\n",
            "[Puzzle FilledNotFilled4] augmentation not full, only 72\n",
            "[Puzzle ExtendToBoundary5] augmentation not full, only 72\n",
            "[Puzzle Count2] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary1] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary2] augmentation not full, only 72\n",
            "[Puzzle HorizontalVertical6] augmentation not full, only 576\n",
            "[Puzzle Order7] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary10] augmentation not full, only 576\n",
            "[Puzzle Center10] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled10] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary3] augmentation not full, only 72\n",
            "[Puzzle FilledNotFilled9] augmentation not full, only 576\n",
            "[Puzzle Count5] augmentation not full, only 72\n",
            "[Puzzle MoveToBoundary4] augmentation not full, only 72\n",
            "[Puzzle InsideOutside2] augmentation not full, only 576\n",
            "[Puzzle TopBottom2D1] augmentation not full, only 576\n",
            "[Puzzle InsideOutside9] augmentation not full, only 576\n",
            "Total puzzles: 960\n",
            "Total puzzle IDs (including <blank>): 876406\n",
            "^C\n",
            "✓ ARC-AGI-1 dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build ARC-AGI-1 Dataset\n",
        "# This creates augmented versions of the data\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc1concept-aug-1000 \\\n",
        "  --subsets training evaluation concept \\\n",
        "  --test-set-name evaluation\n",
        "\n",
        "print(\"✓ ARC-AGI-1 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3t1avJbuPC",
        "outputId": "69bddcf0-2898-4524-8217-c984dbd2cee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Puzzle bd14c3bf] augmentation not full, only 574\n",
            "[Puzzle 8dab14c2] augmentation not full, only 575\n",
            "[Puzzle 3aa6fb7a] augmentation not full, only 576\n",
            "[Puzzle e6de6e8f] augmentation not full, only 576\n",
            "[Puzzle 5c0a986e] augmentation not full, only 576\n",
            "[Puzzle 2697da3f] augmentation not full, only 72\n",
            "[Puzzle 3618c87e] augmentation not full, only 576\n",
            "[Puzzle 5168d44c] augmentation not full, only 576\n",
            "[Puzzle 9bebae7a] augmentation not full, only 575\n",
            "[Puzzle 90f3ed37] augmentation not full, only 576\n",
            "[Puzzle 1990f7a8] augmentation not full, only 72\n",
            "[Puzzle 20981f0e] augmentation not full, only 576\n",
            "[Puzzle a934301b] augmentation not full, only 576\n",
            "[Puzzle 18419cfa] augmentation not full, only 576\n",
            "[Puzzle cce03e0d] augmentation not full, only 576\n",
            "[Puzzle 4612dd53] augmentation not full, only 576\n",
            "[Puzzle d37a1ef5] augmentation not full, only 576\n",
            "[Puzzle f9a67cb5] augmentation not full, only 576\n",
            "[Puzzle 4258a5f9] augmentation not full, only 576\n",
            "[Puzzle 0b17323b] augmentation not full, only 288\n",
            "[Puzzle b9630600] augmentation not full, only 72\n",
            "[Puzzle d255d7a7] augmentation not full, only 576\n",
            "[Puzzle ded97339] augmentation not full, only 72\n",
            "[Puzzle 80af3007] augmentation not full, only 72\n",
            "[Puzzle 21f83797] augmentation not full, only 576\n",
            "[Puzzle d06dbe63] augmentation not full, only 576\n",
            "[Puzzle aedd82e4] augmentation not full, only 576\n",
            "[Puzzle 60b61512] augmentation not full, only 576\n",
            "[Puzzle ef135b50] augmentation not full, only 575\n",
            "[Puzzle f15e1fac] augmentation not full, only 576\n",
            "[Puzzle d5d6de2d] augmentation not full, only 576\n",
            "[Puzzle 8efcae92] augmentation not full, only 576\n",
            "[Puzzle aa300dc3] augmentation not full, only 576\n",
            "[Puzzle 44d8ac46] augmentation not full, only 575\n",
            "[Puzzle e5c44e8f] augmentation not full, only 576\n",
            "[Puzzle e73095fd] augmentation not full, only 576\n",
            "[Puzzle 817e6c09] augmentation not full, only 576\n",
            "[Puzzle 00d62c1b] augmentation not full, only 576\n",
            "[Puzzle 3906de3d] augmentation not full, only 576\n",
            "[Puzzle 1c0d0a4b] augmentation not full, only 576\n",
            "[Puzzle fd4b2b02] augmentation not full, only 576\n",
            "[Puzzle e872b94a] augmentation not full, only 72\n",
            "[Puzzle 017c7c7b] augmentation not full, only 576\n",
            "[Puzzle 4852f2fa] augmentation not full, only 576\n",
            "[Puzzle 8be77c9e] augmentation not full, only 72\n",
            "[Puzzle 9c56f360] augmentation not full, only 576\n",
            "[Puzzle cb227835] augmentation not full, only 575\n",
            "[Puzzle 7df24a62] augmentation not full, only 576\n",
            "[Puzzle 758abdf0] augmentation not full, only 576\n",
            "[Puzzle 6f8cd79b] augmentation not full, only 18\n",
            "[Puzzle c9e6f938] augmentation not full, only 72\n",
            "[Puzzle 794b24be] augmentation not full, only 576\n",
            "[Puzzle baf41dbf] augmentation not full, only 576\n",
            "[Puzzle 1b60fb0c] augmentation not full, only 576\n",
            "[Puzzle 28e73c20] augmentation not full, only 72\n",
            "[Puzzle c97c0139] augmentation not full, only 576\n",
            "[Puzzle 5b526a93] augmentation not full, only 576\n",
            "[Puzzle a48eeaf7] augmentation not full, only 576\n",
            "[Puzzle 551d5bf1] augmentation not full, only 576\n",
            "[Puzzle e179c5f4] augmentation not full, only 576\n",
            "[Puzzle 25ff71a9] augmentation not full, only 576\n",
            "[Puzzle 6855a6e4] augmentation not full, only 576\n",
            "[Puzzle db7260a4] augmentation not full, only 576\n",
            "[Puzzle 332efdb3] augmentation not full, only 9\n",
            "[Puzzle 6c434453] augmentation not full, only 576\n",
            "[Puzzle ff28f65a] augmentation not full, only 576\n",
            "[Puzzle b27ca6d3] augmentation not full, only 576\n",
            "[Puzzle 5ad8a7c0] augmentation not full, only 36\n",
            "[Puzzle d406998b] augmentation not full, only 576\n",
            "[Puzzle 73c3b0d8] augmentation not full, only 576\n",
            "[Puzzle 60a26a3e] augmentation not full, only 576\n",
            "[Puzzle 05f2a901] augmentation not full, only 576\n",
            "[Puzzle f8a8fe49] augmentation not full, only 576\n",
            "[Puzzle ac0c5833] augmentation not full, only 576\n",
            "[Puzzle 447fd412] augmentation not full, only 576\n",
            "[Puzzle 22233c11] augmentation not full, only 576\n",
            "[Puzzle e0fb7511] augmentation not full, only 576\n",
            "[Puzzle 31adaf00] augmentation not full, only 576\n",
            "[Puzzle b0c4d837] augmentation not full, only 576\n",
            "[Puzzle c1990cce] augmentation not full, only 576\n",
            "[Puzzle a5313dff] augmentation not full, only 576\n",
            "[Puzzle 4e469f39] augmentation not full, only 576\n",
            "[Puzzle d9f24cd1] augmentation not full, only 576\n",
            "[Puzzle 2281f1f4] augmentation not full, only 576\n",
            "[Puzzle d4f3cd78] augmentation not full, only 576\n",
            "[Puzzle b25e450b] augmentation not full, only 576\n",
            "[Puzzle 760b3cac] augmentation not full, only 576\n",
            "[Puzzle ae4f1146] augmentation not full, only 576\n",
            "[Puzzle 239be575] augmentation not full, only 576\n",
            "[Puzzle a3f84088] augmentation not full, only 576\n",
            "[Puzzle ce039d91] augmentation not full, only 576\n",
            "[Puzzle 8fbca751] augmentation not full, only 576\n",
            "[Puzzle a1570a43] augmentation not full, only 576\n",
            "[Puzzle dc433765] augmentation not full, only 575\n",
            "[Puzzle be03b35f] augmentation not full, only 576\n",
            "[Puzzle 810b9b61] augmentation not full, only 576\n",
            "[Puzzle 3f7978a0] augmentation not full, only 576\n",
            "[Puzzle 7e02026e] augmentation not full, only 576\n",
            "[Puzzle db3e9e38] augmentation not full, only 576\n",
            "[Puzzle dbc1a6ce] augmentation not full, only 575\n",
            "[Puzzle e7639916] augmentation not full, only 576\n",
            "[Puzzle 6f473927] augmentation not full, only 576\n",
            "[Puzzle c61be7dc] augmentation not full, only 576\n",
            "[Puzzle a8d7556c] augmentation not full, only 576\n",
            "[Puzzle e5062a87] augmentation not full, only 576\n",
            "[Puzzle 6d75e8bb] augmentation not full, only 576\n",
            "[Puzzle e7dd8335] augmentation not full, only 576\n",
            "[Puzzle e9614598] augmentation not full, only 576\n",
            "[Puzzle e1d2900e] augmentation not full, only 576\n",
            "[Puzzle 759f3fd3] augmentation not full, only 576\n",
            "[Puzzle ae58858e] augmentation not full, only 576\n",
            "[Puzzle f25fbde4] augmentation not full, only 72\n",
            "[Puzzle d304284e] augmentation not full, only 576\n",
            "[Puzzle 8719f442] augmentation not full, only 72\n",
            "[Puzzle a79310a0] augmentation not full, only 576\n",
            "[Puzzle 97c75046] augmentation not full, only 575\n",
            "[Puzzle ce9e57f2] augmentation not full, only 576\n",
            "[Puzzle 2c0b0aff] augmentation not full, only 576\n",
            "[Puzzle 2faf500b] augmentation not full, only 576\n",
            "[Puzzle 42a15761] augmentation not full, only 72\n",
            "[Puzzle 9772c176] augmentation not full, only 576\n",
            "[Puzzle b1fc8b8e] augmentation not full, only 72\n",
            "[Puzzle 69889d6e] augmentation not full, only 576\n",
            "[Puzzle a699fb00] augmentation not full, only 576\n",
            "[Puzzle d0f5fe59] augmentation not full, only 72\n",
            "[Puzzle 0d87d2a6] augmentation not full, only 576\n",
            "[Puzzle 253bf280] augmentation not full, only 576\n",
            "[Puzzle 84551f4c] augmentation not full, only 576\n",
            "[Puzzle 67385a82] augmentation not full, only 576\n",
            "[Puzzle ce22a75a] augmentation not full, only 576\n",
            "[Puzzle bf89d739] augmentation not full, only 576\n",
            "[Puzzle ba26e723] augmentation not full, only 576\n",
            "[Puzzle 50c07299] augmentation not full, only 288\n",
            "[Puzzle 4522001f] augmentation not full, only 288\n",
            "[Puzzle bb43febb] augmentation not full, only 576\n",
            "[Puzzle b60334d2] augmentation not full, only 576\n",
            "[Puzzle ecdecbb3] augmentation not full, only 576\n",
            "[Puzzle 712bf12e] augmentation not full, only 576\n",
            "[Puzzle e619ca6e] augmentation not full, only 72\n",
            "[Puzzle 55059096] augmentation not full, only 576\n",
            "[Puzzle b527c5c6] augmentation not full, only 576\n",
            "[Puzzle af902bf9] augmentation not full, only 576\n",
            "[Puzzle dc2aa30b] augmentation not full, only 576\n",
            "[Puzzle 54db823b] augmentation not full, only 576\n",
            "[Puzzle c87289bb] augmentation not full, only 576\n",
            "[Puzzle 64a7c07e] augmentation not full, only 72\n",
            "[Puzzle 4938f0c2] augmentation not full, only 576\n",
            "[Puzzle 7447852a] augmentation not full, only 576\n",
            "[Puzzle 1fad071e] augmentation not full, only 576\n",
            "[Puzzle 71e489b6] augmentation not full, only 576\n",
            "[Puzzle da515329] augmentation not full, only 72\n",
            "[Puzzle Count2] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled9] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary2] augmentation not full, only 72\n",
            "[Puzzle Center10] augmentation not full, only 576\n",
            "[Puzzle InsideOutside9] augmentation not full, only 576\n",
            "[Puzzle Order7] augmentation not full, only 576\n",
            "[Puzzle CompleteShape5] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled10] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary10] augmentation not full, only 575\n",
            "[Puzzle HorizontalVertical5] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary5] augmentation not full, only 72\n",
            "[Puzzle FilledNotFilled4] augmentation not full, only 72\n",
            "[Puzzle MoveToBoundary1] augmentation not full, only 576\n",
            "[Puzzle InsideOutside2] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary4] augmentation not full, only 72\n",
            "[Puzzle TopBottom2D1] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary6] augmentation not full, only 576\n",
            "[Puzzle InsideOutside3] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary3] augmentation not full, only 72\n",
            "[Puzzle Count5] augmentation not full, only 72\n",
            "[Puzzle Order9] augmentation not full, only 36\n",
            "[Puzzle Order5] augmentation not full, only 576\n",
            "[Puzzle HorizontalVertical6] augmentation not full, only 576\n",
            "[Puzzle CleanUp10] augmentation not full, only 72\n",
            "Total puzzles: 1280\n",
            "Total puzzle IDs (including <blank>): 1191730\n",
            "^C\n",
            "✓ ARC-AGI-2 dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build ARC-AGI-2 Dataset\n",
        "# Note: Cannot train on both ARC-AGI-1 and ARC-AGI-2 together\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc2concept-aug-1000 \\\n",
        "  --subsets training2 evaluation2 concept \\\n",
        "  --test-set-name evaluation2\n",
        "\n",
        "print(\"✓ ARC-AGI-2 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdrj3kXAbuPC"
      },
      "outputs": [],
      "source": [
        "# Build Sudoku-Extreme Dataset\n",
        "# Generate with 1000 examples and 1000 augmentations\n",
        "\n",
        "!python dataset/build_sudoku_dataset.py \\\n",
        "  --output-dir data/sudoku-extreme-1k-aug-1000 \\\n",
        "  --subsample-size 1000 \\\n",
        "  --num-aug 1000\n",
        "\n",
        "print(\"✓ Sudoku-Extreme dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WHt18ZSbuPD",
        "outputId": "6ec0b122-400e-43ab-8fc5-b31f2c5d3910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rtrain.csv: 0.00B [00:00, ?B/s]\rtrain.csv: 1.81MB [00:00, 31.7MB/s]\n",
            "100% 1000/1000 [00:00<00:00, 972028.74it/s]\n",
            "test.csv: 1.81MB [00:00, 114MB/s]\n",
            "100% 1000/1000 [00:00<00:00, 629397.36it/s]\n",
            "✓ Maze-Hard dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build Maze-Hard Dataset\n",
        "# Generate 1000 examples with 8 augmentations\n",
        "\n",
        "!python dataset/build_maze_dataset.py\n",
        "\n",
        "print(\"✓ Maze-Hard dataset prepared!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDnpn0zObuPD"
      },
      "source": [
        "## Training Experiments\n",
        "\n",
        "### ARC-AGI Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb8wFv9fbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp9rRwYPbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Single GPU - for Colab)\n",
        "# Modified for Colab constraints\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_1gpu\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sjOJIRabuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-2 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc2concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc2concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8kysWsbuPE"
      },
      "source": [
        "### Sudoku-Extreme Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4TfPozabuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (MLP version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_mlp_t_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.mlp_t=True \\\n",
        "  arch.pos_encodings=none \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkFGZc8UbuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (Attention version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_att_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrooQqMlbuPF"
      },
      "source": [
        "### Maze-Hard Task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on Maze-Hard\n",
        "# Runtime: <24 hours on 4 L40S GPUs\n",
        "!pip install adam-atan2 --force-reinstall --no-binary :all: --verbose\n",
        "\n",
        "run_name = \"pretrain_att_maze30x30\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain_patched.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/maze-30x30-hard-1k]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ],
      "metadata": {
        "id": "FHFcUjKHmXLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWrDU0lbuPF",
        "outputId": "e86454db-0515-4a27-fe4c-f2267f13e6a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 25.3 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)\n",
            "Collecting adam-atan2\n",
            "  Using cached adam_atan2-0.0.3-py3-none-any.whl\n",
            "Installing collected packages: adam-atan2\n",
            "  Attempting uninstall: adam-atan2\n",
            "    Found existing installation: adam_atan2 0.0.3\n",
            "    Uninstalling adam_atan2-0.0.3:\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2-0.0.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2/\n",
            "      Successfully uninstalled adam_atan2-0.0.3\n",
            "Successfully installed adam-atan2-0.0.3\n",
            "W1120 18:32:35.957000 3812 torch/distributed/run.py:774] \n",
            "W1120 18:32:35.957000 3812 torch/distributed/run.py:774] *****************************************\n",
            "W1120 18:32:35.957000 3812 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W1120 18:32:35.957000 3812 torch/distributed/run.py:774] *****************************************\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "W1120 18:33:17.020000 3812 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3833 closing signal SIGTERM\n",
            "W1120 18:33:17.021000 3812 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3834 closing signal SIGTERM\n",
            "W1120 18:33:17.024000 3812 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3835 closing signal SIGTERM\n",
            "E1120 18:33:17.091000 3812 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 3 (pid: 3836) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 901, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 892, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 143, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 277, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "pretrain.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-11-20_18:33:17\n",
            "  host      : 6265ce2272ad\n",
            "  rank      : 3 (local_rank: 3)\n",
            "  exitcode  : 1 (pid: 3836)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Train on Maze-Hard\n",
        "# Runtime: <24 hours on 4 L40S GPUs\n",
        "!pip install adam-atan2 --force-reinstall --no-binary :all: --verbose\n",
        "\n",
        "run_name = \"pretrain_att_maze30x30\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/maze-30x30-hard-1k]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQbVxFpFbu_",
        "outputId": "7af328d8-38df-46e4-e0be-c412edc50e96"
      },
      "source": [
        "# Install Dependencies\n",
        "# Note: Adjust PyTorch installation based on your CUDA version\n",
        "\n",
        "# Upgrade pip and core tools\n",
        "!pip install --upgrade pip wheel setuptools -q\n",
        "\n",
        "# Install PyTorch (adjust for your CUDA version)\n",
        "# For Colab with CUDA 12.x:\n",
        "!pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121 -q\n",
        "\n",
        "# Install other requirements\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Install adam-atan2 optimizer\n",
        "# Force pip to build from source to ensure adam_atan2_backend is compiled.\n",
        "!pip install adam-atan2 --force-reinstall --no-binary :all: --verbose\n",
        "\n",
        "print(\"✓ All dependencies installed!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 25.3 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)\n",
            "Collecting adam-atan2\n",
            "  Using cached adam_atan2-0.0.3-py3-none-any.whl\n",
            "Installing collected packages: adam-atan2\n",
            "  Attempting uninstall: adam-atan2\n",
            "    Found existing installation: adam_atan2 0.0.3\n",
            "    Uninstalling adam_atan2-0.0.3:\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2-0.0.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2/\n",
            "      Successfully uninstalled adam_atan2-0.0.3\n",
            "Successfully installed adam-atan2-0.0.3\n",
            "✓ All dependencies installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro7RuKv1buPF"
      },
      "source": [
        "## Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz3GCdhAbuPG"
      },
      "outputs": [],
      "source": [
        "# Monitor Training Progress\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# List all run directories\n",
        "runs = glob.glob(\"outputs/*/\")\n",
        "print(\"Available training runs:\")\n",
        "for run in sorted(runs):\n",
        "    print(f\"  {run}\")\n",
        "\n",
        "# Check latest checkpoint\n",
        "latest_run = max(runs, key=os.path.getmtime) if runs else None\n",
        "if latest_run:\n",
        "    print(f\"\\nLatest run: {latest_run}\")\n",
        "    checkpoints = glob.glob(os.path.join(latest_run, \"*.pt\"))\n",
        "    print(f\"Checkpoints: {len(checkpoints)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y7_PPCLbuPG"
      },
      "outputs": [],
      "source": [
        "# Load and Evaluate Model\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Specify checkpoint path\n",
        "checkpoint_path = \"outputs/YOUR_RUN_NAME/checkpoint_best.pt\"\n",
        "\n",
        "if Path(checkpoint_path).exists():\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "    print(f\"Best validation accuracy: {checkpoint.get('best_val_acc', 'unknown')}\")\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZPXuK-ObuPG"
      },
      "outputs": [],
      "source": [
        "# Visualize Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_arc_prediction(input_grid, true_output, predicted_output):\n",
        "    \"\"\"Visualize ARC-AGI predictions\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(input_grid, cmap='tab10', interpolation='nearest')\n",
        "    axes[0].set_title('Input')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(true_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[1].set_title('True Output')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(predicted_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[2].set_title('Predicted Output')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (with dummy data)\n",
        "# input_grid = np.random.randint(0, 10, (10, 10))\n",
        "# true_output = np.random.randint(0, 10, (10, 10))\n",
        "# predicted_output = np.random.randint(0, 10, (10, 10))\n",
        "# visualize_arc_prediction(input_grid, true_output, predicted_output)\n",
        "\n",
        "print(\"Visualization functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszXJRwebuPG"
      },
      "source": [
        "## Citation\n",
        "\n",
        "If you use this code, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{jolicoeurmartineau2025morerecursivereasoningtiny,\n",
        "      title={Less is More: Recursive Reasoning with Tiny Networks},\n",
        "      author={Alexia Jolicoeur-Martineau},\n",
        "      year={2025},\n",
        "      eprint={2510.04871},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.LG},\n",
        "      url={https://arxiv.org/abs/2510.04871},\n",
        "}\n",
        "```\n",
        "\n",
        "And the Hierarchical Reasoning Model (HRM):\n",
        "\n",
        "```bibtex\n",
        "@misc{wang2025hierarchicalreasoningmodel,\n",
        "      title={Hierarchical Reasoning Model},\n",
        "      author={Guan Wang and Jin Li and Yuhao Sun and Xing Chen and Changling Liu and Yue Wu and Meng Lu and Sen Song and Yasin Abbasi Yadkori},\n",
        "      year={2025},\n",
        "      eprint={2506.21734},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.AI},\n",
        "      url={https://arxiv.org/abs/2506.21734},\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}