<!doctype html><html lang="en"><head><title data-rh="true">Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants at Their Own Game | by azhar | Oct, 2025 | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" name="apple-itunes-app" content="app-id=828256236, app-argument=/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb, affiliate-data=pt=698524&amp;ct=smart_app_banner&amp;mt=8"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2025-10-13T08:43:27.083Z"/><meta data-rh="true" name="title" content="Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants at Their Own Game | by azhar | Oct, 2025 | Medium"/><meta data-rh="true" property="og:title" content="Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶"/><meta data-rh="true" property="al:android:url" content="medium://p/68d9df9e1fdb"/><meta data-rh="true" property="al:ios:url" content="medium://p/68d9df9e1fdb"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="‚Äú‚Äù is published by azhar."/><meta data-rh="true" property="og:description" content="How a 7 million parameter model outperforms 671 billion parameter models on reasoning tasks and why this changes everything"/><meta data-rh="true" property="og:url" content="https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb"/><meta data-rh="true" property="al:web:url" content="https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:848/1*RE5SGAeCzfzpA7dl_PUBpQ.png"/><meta data-rh="true" property="article:author" content="https://moazharu.medium.com"/><meta data-rh="true" name="author" content="azhar"/><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶"/><meta data-rh="true" name="twitter:site" content="@Medium"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/68d9df9e1fdb"/><meta data-rh="true" property="twitter:description" content="How a 7 million parameter model outperforms 671 billion parameter models on reasoning tasks and why this changes everything"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:848/1*RE5SGAeCzfzpA7dl_PUBpQ.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:creator" content="@Azhar41429690"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="21 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/5d8de952517e8160e40ef9841c781cdc14a5db313057fa3c3de41c6f5b494b19"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" rel="manifest" href="/manifest.json"/><link data-rh="true" rel="preconnect" href="https://www.google.com"/><link data-rh="true" rel="preconnect" href="https://www.gstatic.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://moazharu.medium.com"/><link data-rh="true" rel="canonical" href="https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/68d9df9e1fdb"/><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@id":"https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","@type":"SocialMediaPosting","image":["https://miro.medium.com/"],"url":"https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","dateCreated":"2025-10-12T02:16:50Z","datePublished":"2025-10-12T02:16:50Z","dateModified":"2025-10-13T08:43:27Z","headline":"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶","name":"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶","description":"‚Äú‚Äù is published by azhar.","identifier":"68d9df9e1fdb","author":{"@context":"https://schema.org","@id":"https://medium.com/@moazharu","@type":"Person","identifier":"moazharu","name":"azhar","url":"https://medium.com/@moazharu"},"creator":{"@context":"https://schema.org","@id":"https://medium.com/@moazharu","@type":"Person","identifier":"moazharu","name":"azhar","url":"https://medium.com/@moazharu"},"publisher":{"@context":"https://schema.org","@type":"Organization","@id":"https://medium.com","name":"Medium","url":"https://medium.com","logo":{"@type":"ImageObject","width":500,"height":110,"url":"https://miro.medium.com/v2/resize:fit:500/7%2AV1_7XP4snlmqrc_0Njontw.png"}},"mainEntityOfPage":"https://moazharu.medium.com/building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","isAccessibleForFree":true}</script><script data-rh="true" src="https://www.google.com/recaptcha/enterprise.js?render=6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp" async="true"></script><style type="text/css" data-fela-rehydration="592" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="592" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.d{display:none}.m{display:block}.n{position:sticky}.o{top:0}.p{z-index:500}.q{padding:0 24px}.r{align-items:center}.s{border-bottom:solid 1px #F2F2F2}.z{height:41px}.ab{line-height:20px}.ac{display:flex}.ae{gap:32px}.af{height:57px}.ag{flex:1 0 auto}.ah{color:inherit}.ai{fill:inherit}.aj{font-size:inherit}.ak{border:none}.al{font-family:inherit}.am{letter-spacing:inherit}.an{font-weight:inherit}.ao{padding:0}.ap{margin:0}.aq{cursor:pointer}.ar:disabled{cursor:not-allowed}.as:disabled{color:#6B6B6B}.at:disabled{fill:#6B6B6B}.aw{width:auto}.ax path{fill:#242424}.ay{height:25px}.az{margin-left:24px}.ba{border-radius:20px}.bb{width:240px}.bc{background:#F9F9F9}.bd path{fill:#6B6B6B}.bf{outline:none}.bg{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bh{font-size:14px}.bi{width:100%}.bj{padding:10px 20px 10px 0}.bk{background-color:transparent}.bl{color:#242424}.bm::placeholder{color:#6B6B6B}.bn{display:inline-block}.bo{margin-left:12px}.bp{margin-right:12px}.bq{border-radius:4px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{flex:0 0 auto}.cd{flex:1 1 auto}.ci{justify-content:center}.co{max-width:680px}.cp{min-width:0}.cq{animation:k1 1.2s ease-in-out infinite}.cr{height:100vh}.cs{margin-bottom:16px}.ct{margin-top:48px}.cu{align-items:flex-start}.cv{flex-direction:column}.cw{justify-content:space-between}.cx{margin-bottom:24px}.dd{width:80%}.de{background-color:#F2F2F2}.dk{height:44px}.dl{width:44px}.dm{margin:auto 0}.dn{margin-bottom:4px}.do{height:16px}.dp{width:120px}.dq{width:80px}.dw{margin-bottom:8px}.dx{width:96%}.dy{width:98%}.dz{width:81%}.ea{margin-left:8px}.eb{color:#6B6B6B}.ec{font-size:13px}.ed{height:100%}.ew{color:#FFFFFF}.ex{fill:#FFFFFF}.ey{background:#1A8917}.ez{border-color:#1A8917}.fd:disabled{cursor:inherit !important}.fe:disabled{opacity:0.3}.ff:disabled:hover{background:#1A8917}.fg:disabled:hover{border-color:#1A8917}.fh{border-radius:99em}.fi{border-width:1px}.fj{border-style:solid}.fk{box-sizing:border-box}.fl{text-decoration:none}.fm{text-align:center}.fn{margin-left:16px}.fo{border:inherit}.fr{position:relative}.fs{fill:#6B6B6B}.ft{gap:8px}.fw{position:absolute}.fx{width:1px}.fy{height:1px}.fz{margin:-1px}.ga{overflow:hidden}.gb{clip:rect(0, 0, 0, 0)}.gc{white-space:nowrap}.gd{border-width:0}.ge{margin-right:32px}.gf{background:transparent}.gg svg{margin-left:4px}.gh svg{fill:#6B6B6B}.gj{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.gq{margin:0 24px}.gu{background:rgba(255, 255, 255, 1)}.gv{border:1px solid #F2F2F2}.gw{box-shadow:0 1px 4px #F2F2F2}.gx{max-height:100vh}.gy{overflow-y:auto}.gz{left:0}.ha{top:calc(100vh + 100px)}.hb{bottom:calc(100vh + 100px)}.hc{width:10px}.hd{pointer-events:none}.he{word-break:break-word}.hf{word-wrap:break-word}.hg:after{display:block}.hh:after{content:""}.hi:after{clear:both}.hj{line-height:1.23}.hk{letter-spacing:0}.hl{font-style:normal}.hm{font-weight:700}.iw{gap:12px}.ix{align-items:baseline}.iy{width:36px}.iz{height:36px}.ja{border:2px solid rgba(255, 255, 255, 1)}.jb{z-index:0}.jc{box-shadow:none}.jd{border:1px solid rgba(0, 0, 0, 0.05)}.je{margin-bottom:2px}.jf{flex-wrap:nowrap}.jh{width:12px}.ji{flex-wrap:wrap}.jj{padding-left:8px}.jk{padding-right:8px}.kl> *{flex-shrink:0}.km{overflow-x:scroll}.kn::-webkit-scrollbar{display:none}.ko{scrollbar-width:none}.kp{-ms-overflow-style:none}.kq{width:74px}.kr{flex-direction:row}.ks{z-index:2}.kt{margin-right:4px}.kw{-webkit-user-select:none}.kx{border:0}.ky{fill:rgba(117, 117, 117, 1)}.lb{outline:0}.lc{user-select:none}.ld> svg{pointer-events:none}.lm{cursor:progress}.ln{margin-left:4px}.lo{margin-top:0px}.lp{opacity:1}.lq{padding:4px 0}.lt{width:16px}.lv{display:inline-flex}.mb{max-width:100%}.mc{padding:8px 2px}.md svg{color:#6B6B6B}.mu{line-height:1.58}.mv{letter-spacing:-0.004em}.mw{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.nr{margin-bottom:-0.46em}.ns{font-style:italic}.nt{line-height:1.12}.nu{letter-spacing:-0.022em}.nv{font-weight:600}.oq{margin-bottom:-0.28em}.ow{text-decoration:underline}.ox{padding-left:30px}.oy{line-height:40px}.oz{letter-spacing:-0.009em}.pa{font-weight:300}.pb{font-size:28px}.ph{font-style:inherit}.pi{line-height:1.18}.pw{margin-bottom:-0.31em}.qc{list-style-type:disc}.qd{margin-left:30px}.qe{padding-left:0px}.qp{overflow-x:auto}.qq{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.qr{padding:32px}.qs{border:1px solid #E5E5E5}.qt{line-height:1.4}.qu{margin-top:-0.2em}.qv{margin-bottom:-0.2em}.qw{white-space:pre}.qx{min-width:fit-content}.qy{margin-left:auto}.qz{margin-right:auto}.ra{max-width:848px}.rb{clear:both}.rd{cursor:zoom-in}.re{z-index:auto}.rg{height:auto}.rh{padding:2px 4px}.ri{font-size:75%}.rj> strong{font-family:inherit}.rk{list-style-type:decimal}.rq{box-shadow:inset 0 0 0 1px #F2F2F2}.rr{padding:0px}.rs{padding:16px 20px}.ru{font-size:16px}.rv{max-height:40px}.rw{text-overflow:ellipsis}.rx{display:-webkit-box}.ry{-webkit-line-clamp:2}.rz{-webkit-box-orient:vertical}.sb{margin-top:8px}.sc{margin-top:12px}.sd{margin-bottom:26px}.se{margin-top:6px}.sf{margin-right:8px}.sg{padding:8px 16px}.sh{border-radius:100px}.si{transition:background 300ms ease}.sk{border-top:none}.sl{margin-bottom:50px}.sm{height:52px}.sn{max-height:52px}.so{box-sizing:content-box}.sp{position:static}.sq{z-index:1}.ss{max-width:155px}.sy{margin-right:20px}.sz{margin-bottom:64px}.tm{height:48px}.tn{width:48px}.tp{height:64px}.tq{width:64px}.tr{align-self:flex-end}.tx{padding-right:4px}.ty{font-weight:500}.uf{white-space:pre-wrap}.ug{margin:0 8px}.uh{margin-top:16px}.un{height:0px}.uo{gap:18px}.up{fill:rgba(61, 61, 61, 1)}.ur{padding-bottom:20px}.us{border-bottom:1px solid #F2F2F2}.uy{margin-top:32px}.uz{fill:#242424}.va{background:0}.vb{border-color:#242424}.vd:disabled:hover{color:#242424}.ve:disabled:hover{fill:#242424}.vf:disabled:hover{border-color:#242424}.vq{border-bottom:solid 1px #E5E5E5}.vr{margin-top:72px}.vs{padding:24px 0}.vt{margin-bottom:0px}.vu{margin-right:16px}.au:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.av:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.fa:hover{background:#156D12}.fb:hover{border-color:#156D12}.fc:hover{cursor:pointer}.fu:hover{color:#242424}.fv:hover{fill:#242424}.gi:hover svg{fill:#242424}.gk:hover{background-color:rgba(0, 0, 0, 0.1)}.jg:hover{text-decoration:underline}.la:hover{fill:rgba(8, 8, 8, 1)}.lr:hover{fill:#000000}.ls:hover p{color:#000000}.lu:hover{color:#000000}.me:hover svg{color:#000000}.sj:hover{background-color:#F2F2F2}.to:hover{background-color:none}.uq:hover{fill:rgba(25, 25, 25, 1)}.vc:hover{border-color:#242424}.be:focus-within path{fill:#242424}.kz:focus{fill:rgba(8, 8, 8, 1)}.mf:focus svg{color:#000000}.rf:focus{transform:scale(1.01)}.le:active{border-style:none}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (min-width: 1080px)">.e{display:none}.bw{width:64px}.cc{display:block}.cn{margin:0 64px}.dc{height:48px}.dj{margin-bottom:52px}.dv{margin-bottom:48px}.em{font-size:14px}.eo{line-height:20px}.eu{font-size:13px}.ev{padding:5px 12px}.fq{display:flex}.gp{margin-bottom:50px}.gt{max-width:680px}.ih{font-size:42px}.ii{margin-top:1.19em}.ij{margin-bottom:32px}.ik{line-height:52px}.il{letter-spacing:-0.011em}.iu{align-items:center}.iv{flex-direction:row}.jx{border-top:solid 1px #F2F2F2}.jy{border-bottom:solid 1px #F2F2F2}.jz{margin:32px 0 0}.ka{padding:3px 8px}.kj> *{margin-right:24px}.kk> :last-child{margin-right:0}.ll{margin-top:0px}.ma{margin:0}.nn{font-size:20px}.no{margin-top:2.14em}.np{line-height:32px}.nq{letter-spacing:-0.003em}.om{font-size:24px}.on{margin-top:1.95em}.oo{line-height:30px}.op{letter-spacing:-0.016em}.ov{margin-top:0.94em}.pg{margin-top:1.75em}.pt{margin-top:2.11em}.pu{line-height:24px}.pv{letter-spacing:0}.qb{margin-top:1.72em}.qj{margin-top:1.14em}.qo{margin-top:56px}.rp{margin-top:32px}.sx{display:inline-block}.tc{margin-bottom:0}.td{margin-right:20px}.ts{max-width:500px}.um{margin-bottom:88px}.ux{margin:40px 0 16px}.vk{width:min-width}.vp{padding-top:72px}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.f{display:none}.lk{margin-top:0px}.sw{display:inline-block}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (max-width: 903.98px)">.g{display:none}.lj{margin-top:0px}.sv{display:inline-block}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (max-width: 727.98px)">.h{display:none}.lh{margin-top:0px}.li{margin-right:0px}.rt{padding:10px 12px 10px}.su{display:inline-block}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (max-width: 551.98px)">.i{display:none}.t{display:flex}.u{justify-content:space-between}.bs{width:24px}.ce{min-width:100%}.cj{margin:0 24px}.cy{height:40px}.df{margin-bottom:44px}.dr{margin-bottom:32px}.ee{font-size:13px}.ef{line-height:20px}.ep{padding:0px 8px 1px}.gl{margin-bottom:2px}.hn{font-size:32px}.ho{margin-top:1.01em}.hp{margin-bottom:24px}.hq{line-height:38px}.hr{letter-spacing:-0.014em}.im{align-items:flex-start}.in{flex-direction:column-reverse}.jl{margin:24px -24px 0}.jm{padding:0}.kb> *{margin-right:8px}.kc> :last-child{margin-right:24px}.ku{margin-left:0px}.lf{margin-top:0px}.lg{margin-right:0px}.lw{margin:0}.mg{border:1px solid #F2F2F2}.mh{border-radius:99em}.mi{padding:0px 16px 0px 12px}.mj{height:38px}.mk{align-items:center}.mm svg{margin-right:8px}.mx{font-size:18px}.my{margin-top:1.56em}.mz{line-height:28px}.na{letter-spacing:-0.003em}.nw{font-size:20px}.nx{margin-top:1.2em}.ny{line-height:24px}.nz{letter-spacing:0}.or{margin-top:0.67em}.pc{margin-top:1.08em}.pj{font-size:16px}.pk{margin-top:1.57em}.px{margin-top:1.23em}.qf{margin-top:1.34em}.qk{margin-top:40px}.rl{margin-top:24px}.st{display:inline-block}.tb{flex-direction:column}.tk{margin-bottom:20px}.tl{margin-right:0}.tw{max-width:100%}.tz{font-size:24px}.ua{line-height:30px}.ub{letter-spacing:-0.016em}.ui{margin-bottom:64px}.ut{margin:32px 0 16px}.vg{width:100%}.vl{padding-top:48px}.ml:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.j{display:none}.bv{width:64px}.ch{min-width:100%}.cm{margin:0 64px}.db{height:48px}.di{margin-bottom:52px}.du{margin-bottom:48px}.ek{font-size:14px}.el{line-height:20px}.es{font-size:13px}.et{padding:5px 12px}.fp{display:flex}.go{margin-bottom:50px}.gs{max-width:680px}.ic{font-size:42px}.id{margin-top:1.19em}.ie{margin-bottom:32px}.if{line-height:52px}.ig{letter-spacing:-0.011em}.is{align-items:center}.it{flex-direction:row}.jt{border-top:solid 1px #F2F2F2}.ju{border-bottom:solid 1px #F2F2F2}.jv{margin:32px 0 0}.jw{padding:3px 8px}.kh> *{margin-right:24px}.ki> :last-child{margin-right:0}.lz{margin:0}.nj{font-size:20px}.nk{margin-top:2.14em}.nl{line-height:32px}.nm{letter-spacing:-0.003em}.oi{font-size:24px}.oj{margin-top:1.95em}.ok{line-height:30px}.ol{letter-spacing:-0.016em}.ou{margin-top:0.94em}.pf{margin-top:1.75em}.pq{margin-top:2.11em}.pr{line-height:24px}.ps{letter-spacing:0}.qa{margin-top:1.72em}.qi{margin-top:1.14em}.qn{margin-top:56px}.ro{margin-top:32px}.te{margin-bottom:0}.tf{margin-right:20px}.tt{max-width:500px}.ul{margin-bottom:88px}.uw{margin:40px 0 16px}.vj{width:min-width}.vo{padding-top:72px}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.k{display:none}.x{display:flex}.y{justify-content:space-between}.bu{width:64px}.cg{min-width:100%}.cl{margin:0 48px}.da{height:48px}.dh{margin-bottom:52px}.dt{margin-bottom:48px}.ei{font-size:13px}.ej{line-height:20px}.er{padding:0px 8px 1px}.gn{margin-bottom:50px}.gr{max-width:680px}.hx{font-size:42px}.hy{margin-top:1.19em}.hz{margin-bottom:32px}.ia{line-height:52px}.ib{letter-spacing:-0.011em}.iq{align-items:center}.ir{flex-direction:row}.jp{border-top:solid 1px #F2F2F2}.jq{border-bottom:solid 1px #F2F2F2}.jr{margin:32px 0 0}.js{padding:3px 8px}.kf> *{margin-right:24px}.kg> :last-child{margin-right:0}.ly{margin:0}.nf{font-size:20px}.ng{margin-top:2.14em}.nh{line-height:32px}.ni{letter-spacing:-0.003em}.oe{font-size:24px}.of{margin-top:1.95em}.og{line-height:30px}.oh{letter-spacing:-0.016em}.ot{margin-top:0.94em}.pe{margin-top:1.75em}.pn{margin-top:2.11em}.po{line-height:24px}.pp{letter-spacing:0}.pz{margin-top:1.72em}.qh{margin-top:1.14em}.qm{margin-top:56px}.rn{margin-top:32px}.tg{margin-bottom:0}.th{margin-right:20px}.tu{max-width:500px}.uk{margin-bottom:88px}.uv{margin:40px 0 16px}.vi{width:min-width}.vn{padding-top:72px}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.l{display:none}.v{display:flex}.w{justify-content:space-between}.bt{width:24px}.cf{min-width:100%}.ck{margin:0 24px}.cz{height:40px}.dg{margin-bottom:44px}.ds{margin-bottom:32px}.eg{font-size:13px}.eh{line-height:20px}.eq{padding:0px 8px 1px}.gm{margin-bottom:2px}.hs{font-size:32px}.ht{margin-top:1.01em}.hu{margin-bottom:24px}.hv{line-height:38px}.hw{letter-spacing:-0.014em}.io{align-items:flex-start}.ip{flex-direction:column-reverse}.jn{margin:24px 0 0}.jo{padding:0}.kd> *{margin-right:8px}.ke> :last-child{margin-right:8px}.kv{margin-left:0px}.lx{margin:0}.mn{border:1px solid #F2F2F2}.mo{border-radius:99em}.mp{padding:0px 16px 0px 12px}.mq{height:38px}.mr{align-items:center}.mt svg{margin-right:8px}.nb{font-size:18px}.nc{margin-top:1.56em}.nd{line-height:28px}.ne{letter-spacing:-0.003em}.oa{font-size:20px}.ob{margin-top:1.2em}.oc{line-height:24px}.od{letter-spacing:0}.os{margin-top:0.67em}.pd{margin-top:1.08em}.pl{font-size:16px}.pm{margin-top:1.57em}.py{margin-top:1.23em}.qg{margin-top:1.34em}.ql{margin-top:40px}.rm{margin-top:24px}.ta{flex-direction:column}.ti{margin-bottom:20px}.tj{margin-right:0}.tv{max-width:100%}.uc{font-size:24px}.ud{line-height:30px}.ue{letter-spacing:-0.016em}.uj{margin-bottom:64px}.uu{margin:32px 0 16px}.vh{width:100%}.vm{padding-top:48px}.ms:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="print">.sr{display:none}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.rc{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><style type="text/css" data-fela-rehydration="592" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.sa{max-height:none}</style></head><body><div id="root"><div class="a b c"><a href="/sitemap/sitemap.xml" class="d">Sitemap</a><div class="e f g h i j k l"></div><script>document.domain = document.domain;</script><div class="m c"><div class="m n o p c"><div class="q r s t u v w x y j e z ab"><a class="eb ai ec bg am b ao ap aq ar as at au av t v x j e r ed ab" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68d9df9e1fdb&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;%7Estage=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="ea"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ac r"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><button class="bg b ee ef ep eg eh eq ei ej er es el et eu eo ev ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk bn fl fm" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fn m"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="q r s ac ae af"><div class="ac r ag"><a class="ah ai aj ak al am an ao ap aq ar as at au av ac" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" aria-labelledby="wordmark-medium-desc" viewBox="0 0 719 160" class="aw ax ay"><desc id="wordmark-medium-desc">Medium Logo</desc><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="az i"><div class="ac ak ba bb bc r bd be"><div class="bn" aria-describedby="searchResults" aria-labelledby="searchResults" aria-haspopup="listbox" role="listbox"></div><div class="bo bp ac"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ak bf bg bh ab bi bj bk bl bm" placeholder="Search" value=""/></div></div></div><div class="i l x fp fq"><span data-dd-action-name="Susi presentation tracker new_post_topnav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------" rel="noopener follow"><div class="bg b bh ab eb fr fs ac r ft fu fv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg>Write</div></a></span></div><div class="l k j e"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSearchButton" href="https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------" rel="noopener follow"><div class="bg b bh ab eb fr fs ac r ft fu fv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Search</span></div></a></div><div class="ge i l k"><div class="ac r"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><button class="bg b ee ef ep eg eh eq ei ej er es el et eu eo ev ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk bn fl fm" data-testid="headerSignUpButton">Sign up</button></span></p><div class="fn m"><p class="bg b ee ef eg eh ei ej ek el em eo eb"><span data-dd-action-name="Susi presentation tracker global_nav"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="m"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button class="ak gf ao ac r aq fr gg gh gi" aria-label="user options menu" data-testid="headerUserIcon"><div class="m fr"><img alt="" class="m fk by bz ca de" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="gj by m bz ca fw o ak gk"></div></div></button></div></div></div></div></div></div><div class="ac"><div class="cb i l k j cc" style="width:0px"></div><div class="cd bi ce cf cg ch" style="width:calc(100% - 0px)"><div class="m"><div class="gl gm gn go gp m"><div class="ac ci"><div class="cp bi gq gr gs gt"></div></div><article><div class="m"><div class="m"><span class="m"></span><section><div><div class="fw gz ha hb hc hd"></div><div class="he hf hg hh hi"><div class="ac ci"><div class="cp bi gq gr gs gt"><div><h1 id="a81b" class="pw-post-title hj hk hl bg hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie if ig ih ii ij ik il bl" data-testid="storyTitle">Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants at Their Own Game</h1><div><div class="speechify-ignore ac cw"><div class="speechify-ignore bi m"><div class="ac im in io ip iq ir is it iu iv iw"><div class="ac r iw"><div class="ac ix"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><a rel="noopener follow" href="/?source=post_page---byline--68d9df9e1fdb---------------------------------------" data-discover="true"><div class="m iy iz by ja jb"><div class="m fr"><img alt="azhar" class="m fk by bz ca de" src="https://miro.medium.com/v2/resize:fill:64:64/1*OlAeNq-E9M64u96VI8Bv-Q@2x.jpeg" width="32" height="32" loading="lazy" data-testid="authorPhoto"/><div class="jc by m bz ca fw o jd gk"></div></div></div></a></div></div></div></div><span class="bg b bh ab bl"><div class="je ac r"><div class="ac r jf"><div class="ac r"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><span class="bg b bh ab bl"><a class="ah ai aj fo al am an ao ap aq ar as at jg" data-testid="authorName" rel="noopener follow" href="/?source=post_page---byline--68d9df9e1fdb---------------------------------------" data-discover="true">azhar</a></span></div></div></div></div><div class="jh bn"></div></div></div></span></div><div class="ac r ji"><span class="bg b bh ab eb"><div class="ac ag"><span data-testid="storyReadTime">21 min read</span><div class="jj jk m" aria-hidden="true"><span class="m" aria-hidden="true"><span class="bg b bh ab eb">¬∑</span></span></div><span data-testid="storyPublishDate">Oct 12, 2025</span></div></span></div></div><div class="ac cw jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka"><div class="i l x fp fq r"><div class="kq m"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F68d9df9e1fdb&amp;operation=register&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;user=azhar&amp;userId=685a4c0e34a2&amp;source=---header_actions--68d9df9e1fdb---------------------clap_footer------------------" rel="noopener follow"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><p class="bg b ec ab eb"><span class="lm">--</span></p></div></div></div><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button class="aq kx lp lq ac r fs lr ls" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lo"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bg b ec ab eb"><span class="pw-responses-count ln lo">2</span></p></button></div></div></div></div><div class="ac r kb kc kd ke kf kg kh ki kj kk kl km kn ko kp"><div class="lt l k j e"></div><div class="i l"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68d9df9e1fdb&amp;operation=register&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;source=---header_actions--68d9df9e1fdb---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lu" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="fk lv cu"><div class="m ag"><div class="ac ci"><div class="lw lx ly lz ma mb cp bi"><div class="ac"><div class="bn" role="tooltip"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button aria-label="Listen" data-testid="audioPlayButton" class="ah fs aj fo al am an mc ap aq ar fe md me ls mf mg mh mi mj t mk ml mm mn mo mp mq v mr ms mt"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bg b bh ab eb">Listen</p></div></button></div></div></div></div></div></div></div></div></div><div class="bn" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="ah fs aj fo al am an mc ap aq ar fe md me ls mf mg mh mi mj t mk ml mm mn mo mp mq v mr ms mt"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="k j e"><p class="bg b bh ab eb">Share</p></div></button></div></div></div></div></div></div></div></div></div></div><p id="afa3" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><em class="ns">How a 7 million parameter model outperforms 671 billion parameter models on reasoning tasks and why this changes everything</em></p><h2 id="00c7" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Moment Everything Changed</h2><p id="2005" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Picture this: You‚Äôre working on a Sudoku puzzle. You read the clues once, think hard, and try to write down the complete solution in one shot. Sounds impossible, right?</p><p id="d390" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">That‚Äôs exactly how traditional large language models work. They read the problem once and generate an answer in a single forward pass. No wonder GPT-4, Claude, and even the massive 671 billion parameter DeepSeek R1 score <strong class="mw hm">0% on hard Sudoku puzzles</strong>.</p><p id="191c" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Now imagine a different approach. You read the puzzle, think about it, maybe even think about your thinking, and then start filling in numbers. You check your work, reconsider, make corrections, and iterate until you‚Äôve got it.</p><p id="3dd2" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">This is how humans solve problems. And this is exactly what TRM (Transformer Reasoning Model) does with just 7 million parameters.</p><p id="d255" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">The results? 87.4% accuracy on Sudoku puzzles that stumped models 100,000x larger.</strong></p><p id="bda7" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Before we proceed, let‚Äôs stay connected! Please consider following me on <strong class="mw hm">Medium</strong>, and don‚Äôt forget to connect with me on <a class="ah ow" href="https://www.linkedin.com/in/mohamed-azharudeen/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> for a regular dose of data science and deep learning insights.‚Äù üöÄüìäü§ñ</p><blockquote class="ox"><p id="9b63" class="oy oz hl bg pa pb pc pd pe pf pg nr eb"><em class="ph">üì© Note: I‚Äôm not actively checking Medium messages if you have any doubts or concerns about the article, please feel free to reach out to me on LinkedIn.</em></p></blockquote><h3 id="3d32" class="pi nu hl bg nv pj pk ef nz pl pm eh od nf pn po pp nj pq pr ps nn pt pu pv pw bl">Why Should You Care?</h3><p id="cc8f" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Before we dive into code, let‚Äôs talk about why this is revolutionary:</p><h3 id="213a" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">The Old Paradigm: Bigger is Better</h3><p id="d3ab" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">For years, AI progress looked like this:</p><ul class=""><li id="8aa6" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qc qd qe bl">2018: BERT (110M parameters)</li><li id="8a0d" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">2019: GPT-2 (1.5B parameters)</li><li id="95bc" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">2020: GPT-3 (175B parameters)</li><li id="6778" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">2023: GPT-4 (rumored 1.7T parameters)</li></ul><p id="27d1" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">The assumption</strong>: More parameters = Better reasoning</p><h2 id="b7e3" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The New Reality: Architecture Matters More</h2><p id="c423" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">TRM flips this on its head. The paper ‚ÄúLess is More: Recursive Reasoning with Tiny Networks‚Äù shows that a 7M parameter model can beat a 671B parameter model on systematic reasoning tasks.</p><p id="6d51" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">The insight</strong>: It‚Äôs not about how big your brain is; it‚Äôs about how you use it.</p><p id="091c" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">This has massive implications:</p><ul class=""><li id="4460" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qc qd qe bl">‚úÖ Run powerful AI on your laptop (no cloud needed)</li><li id="f6d4" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">‚úÖ Deploy reasoning models on mobile devices</li><li id="65ca" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">‚úÖ Train models in hours instead of weeks</li><li id="6d2c" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">‚úÖ Democratize AI (you don‚Äôt need millions of dollars)</li></ul><p id="3574" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Okay, enough philosophy. Let‚Äôs build this thing.</p><h2 id="ccd1" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Big Idea: Three Streams and Recursive Thinking</h2><p id="7182" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Here‚Äôs the core innovation in one sentence:</p><p id="ed0f" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Instead of processing a problem once with a huge network, TRM processes it many times with a tiny network and keeps three separate ‚Äúthoughts‚Äù running in parallel.</strong></p><h2 id="2bf4" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Three Streams</h2><p id="a387" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Think of it like three Post-it notes on your desk:</p><p id="d309" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">1. The Question (x-stream)</strong> This is your problem statement. It never changes. You keep referring back to it as you work.</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="7c14" class="qt nu hl qq b bh qu qv m qw qx">&quot;Solve: 2x + 3 = 7&quot;</span></pre><p id="a221" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">2. Your Current Answer (y-stream)</strong> This is your working solution. It starts rough and gets refined through iteration.</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="dc34" class="qt nu hl qq b bh qu qv m qw qx">Iteration 1: &quot;x = ?&quot;<br/>Iteration 5: &quot;x = maybe 2 or 3&quot;<br/>Iteration 16: &quot;x = 2&quot;</span></pre><p id="af96" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">3. Your Reasoning Notes (z-stream)</strong> This is your scratch work. The intermediate thoughts that help you get to the answer.</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="66f6" class="qt nu hl qq b bh qu qv m qw qx">&quot;Need to isolate x... subtract 3 from both sides... <br/>then divide by 2... checking: 2*2 + 3 = 7 ‚úì&quot;</span></pre><p id="eb9e" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">The magic happens when these three streams talk to each other through transformer layers.</p><h2 id="8f39" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Architecture Overview: The 10,000 Foot View</h2><p id="b4f5" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Before we write code, let‚Äôs visualize the flow:</p><figure class="qk ql qm qn qo rb qy qz paragraph-image"><div role="button" tabindex="0" class="rc rd fr re bi rf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="qy qz ra"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RE5SGAeCzfzpA7dl_PUBpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*RE5SGAeCzfzpA7dl_PUBpQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*RE5SGAeCzfzpA7dl_PUBpQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*RE5SGAeCzfzpA7dl_PUBpQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*RE5SGAeCzfzpA7dl_PUBpQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*RE5SGAeCzfzpA7dl_PUBpQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*RE5SGAeCzfzpA7dl_PUBpQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*RE5SGAeCzfzpA7dl_PUBpQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bi mb rg c" width="700" height="1098" loading="eager" role="presentation"/></picture></div></div></figure><p id="7517" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Simple, right? Now let‚Äôs implement it piece by piece.</p><h2 id="a545" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 1: Building Blocks ‚Äî The Attention Mechanism</h2><p id="c97f" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Let me start with a confession: I‚Äôve implemented attention dozens of times, and it still feels like magic every time it works.</p><p id="b3f2" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Here‚Äôs the intuition: <strong class="mw hm">Attention lets each word ask every other word ‚ÄúHey, how relevant are you to me right now?‚Äù</strong></p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="814d" class="qt nu hl qq b bh qu qv m qw qx">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>import math<br/><br/>class MultiHeadAttention(nn.Module):<br/>    &quot;&quot;&quot;<br/>    Multi-head attention: The secret sauce of transformers.<br/>    <br/>    Intuition: Instead of one attention mechanism, we have multiple <br/>    &quot;attention heads&quot; that each focus on different aspects of the input.<br/>    <br/>    Head 1 might focus on: &quot;What words are nouns?&quot;<br/>    Head 2 might focus on: &quot;What words are related to time?&quot;<br/>    Head 3 might focus on: &quot;What words are negations?&quot;<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(self, d_model, n_heads, dropout=0.1):<br/>        super().__init__()<br/>        assert d_model % n_heads == 0, &quot;d_model must be divisible by n_heads&quot;<br/>        <br/>        self.d_model = d_model      # Total embedding dimension (e.g., 256)<br/>        self.n_heads = n_heads      # Number of attention heads (e.g., 4)<br/>        self.d_k = d_model // n_heads  # Dimension per head (256/4 = 64)<br/>        <br/>        # These projections create our Queries, Keys, and Values<br/>        self.q_proj = nn.Linear(d_model, d_model)<br/>        self.k_proj = nn.Linear(d_model, d_model)<br/>        self.v_proj = nn.Linear(d_model, d_model)<br/>        <br/>        # Final output projection<br/>        self.out_proj = nn.Linear(d_model, d_model)<br/>        self.dropout = nn.Dropout(dropout)<br/>        <br/>    def forward(self, x, mask=None):<br/>        batch_size, seq_len, d_model = x.shape<br/>        <br/>        # Step 1: Project to Q, K, V<br/>        # Think of this as creating three different &quot;views&quot; of the input<br/>        q = self.q_proj(x)  # Queries: &quot;What am I looking for?&quot;<br/>        k = self.k_proj(x)  # Keys: &quot;What information do I have?&quot;<br/>        v = self.v_proj(x)  # Values: &quot;What should I output?&quot;<br/>        <br/>        # Step 2: Split into multiple heads<br/>        # Shape: [batch, seq_len, d_model] -&gt; [batch, n_heads, seq_len, d_k]<br/>        q = q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)<br/>        k = k.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)<br/>        v = v.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)<br/>        <br/>        # Step 3: Compute attention scores<br/>        # This is the &quot;How much should I pay attention to each word?&quot; step<br/>        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)<br/>        <br/>        # Why divide by sqrt(d_k)? <br/>        # Without it, dot products get very large -&gt; softmax becomes peaked<br/>        # -&gt; gradients vanish -&gt; training fails<br/>        # With it, we keep values in a nice range for softmax<br/>        <br/>        if mask is not None:<br/>            scores = scores.masked_fill(mask == 0, -1e9)<br/>        <br/>        # Step 4: Apply softmax to get attention weights<br/>        # Now scores are probabilities (sum to 1)<br/>        attn_weights = F.softmax(scores, dim=-1)<br/>        attn_weights = self.dropout(attn_weights)<br/>        <br/>        # Step 5: Apply attention to values<br/>        # This is the actual &quot;paying attention&quot; step<br/>        attn_output = torch.matmul(attn_weights, v)<br/>        <br/>        # Step 6: Reshape and project back<br/>        attn_output = attn_output.transpose(1, 2).contiguous()<br/>        attn_output = attn_output.view(batch_size, seq_len, d_model)<br/>        output = self.out_proj(attn_output)<br/>        <br/>        return output</span></pre><p id="a1fd" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Real Talk</strong>: When I first learned attention, the sqrt(d_k) scaling confused me. Here‚Äôs why it matters:</p><p id="3289" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Imagine you‚Äôre at a party trying to have a conversation. If everyone whispers (small dot products), you can hear multiple people. If everyone shouts (large dot products), you can only focus on the loudest person. The scaling keeps everyone at ‚Äúnormal speaking volume.‚Äù</p><h2 id="e031" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 2: The Feed-Forward Network (The Thinking Layer)</h2><p id="aef9" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">After attention figures out what‚Äôs relevant, the feed-forward network does the actual ‚Äúthinking‚Äù:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="081a" class="qt nu hl qq b bh qu qv m qw qx">class FeedForward(nn.Module):<br/>    &quot;&quot;&quot;<br/>    Feed-forward network (also called MLP - Multi-Layer Perceptron).<br/>    <br/>    This is where the actual transformation happens. Think of it as:<br/>    - Layer 1: Expand your thoughts (d_model -&gt; d_ff)<br/>    - Activation: Non-linear thinking (GELU)<br/>    - Layer 2: Compress back to useful format (d_ff -&gt; d_model)<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(self, d_model, d_ff, dropout=0.1):<br/>        super().__init__()<br/>        # Typical: d_ff = 4 * d_model (e.g., 256 -&gt; 1024)<br/>        self.linear1 = nn.Linear(d_model, d_ff)<br/>        self.linear2 = nn.Linear(d_ff, d_model)<br/>        self.dropout = nn.Dropout(dropout)<br/>        <br/>    def forward(self, x):<br/>        # Expand -&gt; Activate -&gt; Compress<br/>        return self.linear2(self.dropout(F.gelu(self.linear1(x))))</span></pre><p id="74cc" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Why GELU instead of ReLU?</strong></p><p id="ce6d" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">I used to always use ReLU (the classic activation function). But GELU (Gaussian Error Linear Unit) is smoother.</p><p id="8ea4" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Think of it this way:</p><ul class=""><li id="46c9" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qc qd qe bl"><strong class="mw hm">ReLU</strong>: ‚ÄúIs this positive? YES ‚Üí keep it. NO ‚Üí kill it.‚Äù</li><li id="8d81" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl"><strong class="mw hm">GELU</strong>: ‚ÄúIs this positive? Probably ‚Üí keep most of it. Probably not ‚Üí keep a little bit.‚Äù</li></ul><p id="d868" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">GELU‚Äôs smoothness helps gradients flow better during training. It‚Äôs like the difference between binary decisions and nuanced thinking.</p><h2 id="26dc" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 3: The Transformer Block (Putting It Together)</h2><p id="0fa4" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Now we combine attention and feed-forward into a transformer block:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="c61f" class="qt nu hl qq b bh qu qv m qw qx">class TransformerBlock(nn.Module):<br/>    &quot;&quot;&quot;<br/>    A single transformer block. The paper uses 4 of these in sequence.<br/>    <br/>    Structure:<br/>    1. Multi-head attention (tokens talk to each other)<br/>    2. Add &amp; Normalize (residual connection)<br/>    3. Feed-forward (actually process the information)<br/>    4. Add &amp; Normalize (another residual connection)<br/>    <br/>    The &quot;Add&quot; parts are crucial - they let information flow directly<br/>    through the network without going through all the transformations.<br/>    This prevents vanishing gradients.<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(self, d_model, n_heads, d_ff, dropout=0.1, use_attention=True):<br/>        super().__init__()<br/>        self.use_attention = use_attention  # False for TRM-MLP variant<br/>        <br/>        if use_attention:<br/>            self.attention = MultiHeadAttention(d_model, n_heads, dropout)<br/>            self.norm1 = nn.LayerNorm(d_model)<br/>        <br/>        self.ffn = FeedForward(d_model, d_ff, dropout)<br/>        self.norm2 = nn.LayerNorm(d_model)<br/>        self.dropout = nn.Dropout(dropout)<br/>        <br/>    def forward(self, x, mask=None):<br/>        # Block 1: Self-attention (if enabled)<br/>        if self.use_attention:<br/>            # Save input for residual connection<br/>            residual = x<br/>            # Apply attention<br/>            x = self.attention(x, mask)<br/>            # Add residual and normalize<br/>            x = self.norm1(residual + self.dropout(x))<br/>        <br/>        # Block 2: Feed-forward<br/>        residual = x<br/>        x = self.ffn(x)<br/>        x = self.norm2(residual + self.dropout(x))<br/>        <br/>        return x</span></pre><p id="259b" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">A Cool Finding from the Paper</strong>:</p><p id="80ee" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">The TRM-MLP variant (where <code class="de rh ri rj qq b">use_attention=False</code>) actually works better on some tasks!</p><p id="d04b" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">For Sudoku: TRM-MLP gets 87.4% accuracy vs TRM-Att‚Äôs 74.7%.</p><p id="2330" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">This blew my mind. Attention is supposed to be the key to transformers, right? But sometimes, simpler is better. The MLP-only version is faster, uses less memory, and learns better for certain structured problems.</p><h2 id="07b4" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 4: The Complete TRM Model (Here‚Äôs Where Magic Happens)</h2><p id="20e8" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Now for the main event. This is where we implement the three-stream architecture and recursive reasoning:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="efaa" class="qt nu hl qq b bh qu qv m qw qx">class TRM(nn.Module):<br/>    &quot;&quot;&quot;<br/>    Transformer Reasoning Model - The Full Implementation<br/>    <br/>    This is where TRM&#x27;s innovation shines:<br/>    - Three separate streams: question (x), answer (y), reasoning (z)<br/>    - Recursive updates: process multiple times instead of once<br/>    - Selective updates: only change what needs changing at each step<br/>    <br/>    Result: Tiny network (7M params) beats huge networks (671B params)<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(<br/>        self,<br/>        vocab_size,           # Size of your vocabulary<br/>        d_model=256,          # Embedding dimension<br/>        n_heads=4,            # Number of attention heads<br/>        d_ff=1024,            # Feed-forward dimension (4x d_model)<br/>        n_layers=4,           # Number of transformer blocks<br/>        max_seq_len=512,      # Maximum sequence length<br/>        dropout=0.1,          # Dropout probability<br/>        n_reasoning_steps=8,  # How many times to update z<br/>        n_refinement_steps=16,# How many times to update y<br/>        use_attention=True,   # False for TRM-MLP variant<br/>        tie_embeddings=True   # Share input/output embeddings (saves params)<br/>    ):<br/>        super().__init__()<br/>        <br/>        self.d_model = d_model<br/>        self.n_reasoning_steps = n_reasoning_steps<br/>        self.n_refinement_steps = n_refinement_steps<br/>        self.use_attention = use_attention<br/>        <br/>        # Token embeddings: converts token IDs to vectors<br/>        # Example: token &quot;hello&quot; (ID: 42) -&gt; 256-dim vector<br/>        self.token_embedding = nn.Embedding(vocab_size, d_model)<br/>        <br/>        # Positional embeddings: adds position information<br/>        # Transformers have no inherent notion of order!<br/>        self.position_embedding = nn.Embedding(max_seq_len, d_model)<br/>        <br/>        self.embedding_dropout = nn.Dropout(dropout)<br/>        <br/>        # Stack of transformer blocks (4x in the paper)<br/>        self.transformer_blocks = nn.ModuleList([<br/>            TransformerBlock(d_model, n_heads, d_ff, dropout, use_attention)<br/>            for _ in range(n_layers)<br/>        ])<br/>        <br/>        # Reverse embedding: converts vectors back to token probabilities<br/>        # This is how we go from hidden states to actual words<br/>        self.reverse_embedding = nn.Linear(d_model, vocab_size, bias=False)<br/>        <br/>        # Weight tying: a clever trick to reduce parameters<br/>        # Use the same weights for embedding and un-embedding<br/>        if tie_embeddings:<br/>            self.reverse_embedding.weight = self.token_embedding.weight<br/>        <br/>        self._init_weights()<br/>        <br/>    def _init_weights(self):<br/>        &quot;&quot;&quot;<br/>        Initialize weights properly. This matters more than you&#x27;d think!<br/>        <br/>        Too large: training explodes<br/>        Too small: training is too slow<br/>        Just right: Goldilocks initialization<br/>        &quot;&quot;&quot;<br/>        for module in self.modules():<br/>            if isinstance(module, nn.Linear):<br/>                # Initialize with small random values<br/>                nn.init.normal_(module.weight, mean=0.0, std=0.02)<br/>                if module.bias is not None:<br/>                    nn.init.zeros_(module.bias)<br/>            elif isinstance(module, nn.Embedding):<br/>                nn.init.normal_(module.weight, mean=0.0, std=0.02)<br/>            elif isinstance(module, nn.LayerNorm):<br/>                nn.init.ones_(module.weight)<br/>                nn.init.zeros_(module.bias)<br/>    <br/>    def embed_tokens(self, token_ids):<br/>        &quot;&quot;&quot;<br/>        Convert token IDs to embeddings with positional information.<br/>        <br/>        Example:<br/>        Input:  [1, 42, 7, 13]  (token IDs)<br/>        Output: [[0.23, -0.45, ...],  (256-dim vectors)<br/>                 [0.12, 0.89, ...],<br/>                 [-0.34, 0.67, ...],<br/>                 [0.56, -0.12, ...]]<br/>        &quot;&quot;&quot;<br/>        batch_size, seq_len = token_ids.shape<br/>        <br/>        # Get token embeddings<br/>        token_emb = self.token_embedding(token_ids)<br/>        <br/>        # Get positional embeddings<br/>        # Position 0, 1, 2, 3, ... for each sequence<br/>        positions = torch.arange(seq_len, device=token_ids.device)<br/>        positions = positions.unsqueeze(0).expand(batch_size, -1)<br/>        pos_emb = self.position_embedding(positions)<br/>        <br/>        # Combine token + position information<br/>        embeddings = self.embedding_dropout(token_emb + pos_emb)<br/>        <br/>        return embeddings<br/>    <br/>    def apply_transformer_blocks(self, x, mask=None):<br/>        &quot;&quot;&quot;Apply all transformer blocks sequentially.&quot;&quot;&quot;<br/>        for block in self.transformer_blocks:<br/>            x = block(x, mask)<br/>        return x<br/>    <br/>    def forward_pass(self, x, y, z, mask=None):<br/>        &quot;&quot;&quot;<br/>        THIS IS THE KEY INNOVATION!<br/>        <br/>        Single forward pass through the model. We:<br/>        1. Concatenate x, y, z (all three streams)<br/>        2. Process through transformers (they all talk to each other)<br/>        3. Split back into x, y, z (separate the streams again)<br/>        <br/>        This allows cross-stream attention:<br/>        - y can look at x to remember the question<br/>        - y can look at z to use the reasoning<br/>        - z can look at x to understand the problem<br/>        - z can look at y to see current progress<br/>        &quot;&quot;&quot;<br/>        # Remember the lengths (we need to split back later)<br/>        len_x = x.size(1)<br/>        len_y = y.size(1)<br/>        len_z = z.size(1)<br/>        <br/>        # Concatenate along sequence dimension<br/>        # If x is length 10, y is length 5, z is length 32<br/>        # combined is length 10+5+32 = 47<br/>        combined = torch.cat([x, y, z], dim=1)<br/>        <br/>        # Pass through all transformer blocks<br/>        # Each position can now attend to all other positions<br/>        # across all three streams!<br/>        combined = self.apply_transformer_blocks(combined, mask)<br/>        <br/>        # Split back into three streams<br/>        x_new = combined[:, :len_x, :]<br/>        y_new = combined[:, len_x:len_x + len_y, :]<br/>        z_new = combined[:, len_x + len_y:, :]<br/>        <br/>        return x_new, y_new, z_new<br/>    <br/>    def recursive_reasoning(self, x, y, z, mask=None, return_trajectory=False):<br/>        &quot;&quot;&quot;<br/>        The heart of TRM: recursive reasoning.<br/>        <br/>        Phase 1 (8 steps): Build up reasoning in z<br/>        Phase 2 (16 steps): Refine answer in y<br/>        <br/>        This is like:<br/>        Phase 1: Reading and understanding the problem deeply<br/>        Phase 2: Working through the solution step by step<br/>        &quot;&quot;&quot;<br/>        trajectory = {&#x27;z_states&#x27;: [], &#x27;y_states&#x27;: []} if return_trajectory else None<br/>        <br/>        # ===== PHASE 1: BUILD REASONING =====<br/>        print(f&quot;Phase 1: Building reasoning ({self.n_reasoning_steps} steps)...&quot;)<br/>        for step in range(self.n_reasoning_steps):<br/>            # Process all three streams<br/>            x_new, y_new, z_new = self.forward_pass(x, y, z, mask)<br/>            <br/>            # ONLY UPDATE Z<br/>            # x stays fixed (question doesn&#x27;t change)<br/>            # y stays fixed (not ready to answer yet)<br/>            # z gets updated (building understanding)<br/>            z = z_new<br/>            <br/>            if return_trajectory:<br/>                trajectory[&#x27;z_states&#x27;].append(z.detach().clone())<br/>        <br/>        print(f&quot;Phase 2: Refining answer ({self.n_refinement_steps} steps)...&quot;)<br/>        # ===== PHASE 2: REFINE ANSWER =====<br/>        for step in range(self.n_refinement_steps):<br/>            x_new, y_new, z_new = self.forward_pass(x, y, z, mask)<br/>            <br/>            # ONLY UPDATE Y<br/>            # x stays fixed (question doesn&#x27;t change)<br/>            # z stays fixed (we&#x27;ve built our reasoning)<br/>            # y gets updated (refining our answer)<br/>            y = y_new<br/>            <br/>            if return_trajectory:<br/>                trajectory[&#x27;y_states&#x27;].append(y.detach().clone())<br/>        <br/>        return (y, trajectory) if return_trajectory else y<br/>    <br/>    def forward(self, question_ids, answer_ids=None, latent_len=32, mask=None):<br/>        &quot;&quot;&quot;<br/>        Complete forward pass.<br/>        <br/>        Args:<br/>            question_ids: Input question as token IDs [batch, len_q]<br/>            answer_ids: Target answer as token IDs [batch, len_a]<br/>            latent_len: Length of reasoning sequence (typically 32)<br/>        <br/>        Returns:<br/>            logits: Predicted tokens [batch, len_a, vocab_size]<br/>        &quot;&quot;&quot;<br/>        batch_size = question_ids.size(0)<br/>        device = question_ids.device<br/>        <br/>        # Step 1: Embed the question (x stream)<br/>        x = self.embed_tokens(question_ids)<br/>        <br/>        # Step 2: Initialize or embed the answer (y stream)<br/>        if answer_ids is not None:<br/>            # Training: start with target answer embeddings<br/>            y = self.embed_tokens(answer_ids)<br/>        else:<br/>            # Inference: start with random embeddings<br/>            len_a = 32  # default answer length<br/>            y = torch.randn(batch_size, len_a, self.d_model, device=device) * 0.02<br/>        <br/>        # Step 3: Initialize reasoning (z stream) with random noise<br/>        # The model will learn what to put here!<br/>        z = torch.randn(batch_size, latent_len, self.d_model, device=device) * 0.02<br/>        <br/>        # Step 4: Do the recursive reasoning magic!<br/>        y_final = self.recursive_reasoning(x, y, z, mask)<br/>        <br/>        # Step 5: Convert final answer embeddings to token probabilities<br/>        logits = self.reverse_embedding(y_final)<br/>        <br/>        return logits<br/>    <br/>    def generate(self, question_ids, max_length=50, latent_len=32, temperature=1.0):<br/>        &quot;&quot;&quot;<br/>        Generate an answer autoregressively.<br/>        <br/>        This is how you&#x27;d use the model in production:<br/>        1. Give it a question<br/>        2. It thinks recursively<br/>        3. It generates an answer token by token<br/>        &quot;&quot;&quot;<br/>        batch_size = question_ids.size(0)<br/>        device = question_ids.device<br/>        <br/>        # Start with a beginning-of-sequence token (or zeros)<br/>        generated = torch.zeros(batch_size, 1, dtype=torch.long, device=device)<br/>        <br/>        for i in range(max_length):<br/>            # Get predictions for current sequence<br/>            logits = self.forward(question_ids, generated, latent_len)<br/>            <br/>            # Sample next token (with temperature for randomness)<br/>            next_token_logits = logits[:, -1, :] / temperature<br/>            probs = F.softmax(next_token_logits, dim=-1)<br/>            next_token = torch.multinomial(probs, num_samples=1)<br/>            <br/>            # Add to sequence<br/>            generated = torch.cat([generated, next_token], dim=1)<br/>            <br/>            # Optional: stop if end-of-sequence token<br/>            # if (next_token == eos_token_id).all():<br/>            #     break<br/>        <br/>        return generated<br/>    <br/>    def count_parameters(self):<br/>        &quot;&quot;&quot;Count total trainable parameters.&quot;&quot;&quot;<br/>        return sum(p.numel() for p in self.parameters() if p.requires_grad)</span></pre><p id="b9d8" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Let me explain what just happened:</strong></p><p id="4d33" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">The <code class="de rh ri rj qq b">recursive_reasoning</code> method is where TRM&#x27;s magic lives. Instead of processing the problem once, it processes it 24 times (8 + 16).</p><p id="cde6" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Phase 1 (Update z)</strong>: ‚ÄúLet me really understand this problem‚Ä¶‚Äù</p><ul class=""><li id="5ad1" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qc qd qe bl">Step 1: ‚ÄúOkay, I see the question‚Äù</li><li id="a85e" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 2: ‚ÄúThese seem to be the constraints‚Äù</li><li id="c630" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 3‚Äì6: ‚ÄúI‚Äôm building a mental model of the solution space‚Äù</li><li id="a450" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 7‚Äì8: ‚ÄúGot it, I know how to approach this‚Äù</li></ul><p id="e3bd" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Phase 2 (Update y)</strong>: ‚ÄúNow let me work through the solution‚Ä¶‚Äù</p><ul class=""><li id="bceb" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qc qd qe bl">Step 1‚Äì4: ‚ÄúHere‚Äôs my first attempt‚Äù</li><li id="ead6" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 5‚Äì8: ‚ÄúWait, that doesn‚Äôt work, let me revise‚Äù</li><li id="3c4e" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 9‚Äì12: ‚ÄúGetting closer‚Ä¶‚Äù</li><li id="aadc" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr qc qd qe bl">Step 13‚Äì16: ‚ÄúFinal answer!‚Äù</li></ul><p id="8364" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">This is exactly how you‚Äôd solve a hard problem yourself.</p><h2 id="5797" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 5: Model Variants (The Plot Twist)</h2><p id="5e77" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Remember how I said attention was optional? Here are helper functions to create both variants:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="d57d" class="qt nu hl qq b bh qu qv m qw qx">def create_trm_att(vocab_size, d_model=256, n_layers=4):<br/>    &quot;&quot;&quot;<br/>    Create TRM-Att variant (with attention).<br/>    <br/>    This is the &quot;standard&quot; transformer approach.<br/>    Parameters: ~7M<br/>    Best for: General reasoning tasks<br/>    &quot;&quot;&quot;<br/>    return TRM(<br/>        vocab_size=vocab_size,<br/>        d_model=d_model,<br/>        n_heads=4,<br/>        d_ff=d_model * 4,  # 256 * 4 = 1024<br/>        n_layers=n_layers,<br/>        n_reasoning_steps=8,<br/>        n_refinement_steps=16,<br/>        use_attention=True  # Key difference!<br/>    )<br/><br/><br/>def create_trm_mlp(vocab_size, d_model=256, n_layers=4):<br/>    &quot;&quot;&quot;<br/>    Create TRM-MLP variant (MLP-only, no attention).<br/>    <br/>    Simpler, faster, sometimes better!<br/>    Parameters: ~5M (30% fewer than TRM-Att)<br/>    Best for: Structured problems like Sudoku<br/>    <br/>    Fun fact: This variant scored 87.4% on Sudoku vs 74.7% for TRM-Att.<br/>    Sometimes less really is more!<br/>    &quot;&quot;&quot;<br/>    return TRM(<br/>        vocab_size=vocab_size,<br/>        d_model=d_model,<br/>        n_heads=4,  # Not used, but kept for compatibility<br/>        d_ff=d_model * 4,<br/>        n_layers=n_layers,<br/>        n_reasoning_steps=8,<br/>        n_refinement_steps=16,<br/>        use_attention=False  # This is the magic!<br/>    )</span></pre><h2 id="86af" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 6: Training the Model (Making It Smart)</h2><p id="c7e8" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Now let‚Äôs write the training code. This is where the model actually learns:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="ffc9" class="qt nu hl qq b bh qu qv m qw qx">def train_step(model, question_ids, answer_ids, optimizer, criterion):<br/>    &quot;&quot;&quot;<br/>    Single training step. This runs thousands of times during training.<br/>    <br/>    The beauty of TRM is that we only need to supervise the final output.<br/>    The model figures out how to use the z-stream on its own!<br/>    &quot;&quot;&quot;<br/>    model.train()  # Enable dropout, etc.<br/>    optimizer.zero_grad()  # Reset gradients<br/>    <br/>    # Forward pass with all that recursive reasoning<br/>    logits = model(question_ids, answer_ids, latent_len=32)<br/>    <br/>    # Compute loss<br/>    # We&#x27;re doing cross-entropy: &quot;How well did you predict the right token?&quot;<br/>    vocab_size = logits.size(-1)<br/>    loss = criterion(<br/>        logits.reshape(-1, vocab_size),  # Flatten to [batch*seq_len, vocab]<br/>        answer_ids.reshape(-1)            # Flatten to [batch*seq_len]<br/>    )<br/>    <br/>    # Backward pass (compute gradients)<br/>    loss.backward()<br/>    <br/>    # Update weights<br/>    optimizer.step()<br/>    <br/>    return loss.item()<br/><br/><br/>def evaluate(model, question_ids, answer_ids, criterion):<br/>    &quot;&quot;&quot;Evaluation without updating weights.&quot;&quot;&quot;<br/>    model.eval()  # Disable dropout<br/>    with torch.no_grad():  # Don&#x27;t compute gradients (faster, less memory)<br/>        logits = model(question_ids, answer_ids, latent_len=32)<br/>        vocab_size = logits.size(-1)<br/>        loss = criterion(logits.reshape(-1, vocab_size), answer_ids.reshape(-1))<br/>    return loss.item()</span></pre><h2 id="4641" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Complete Training Loop</h2><p id="dc6e" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Here‚Äôs a full training script you can actually run:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="4e9a" class="qt nu hl qq b bh qu qv m qw qx">from torch.utils.data import DataLoader, Dataset<br/><br/>class ReasoningDataset(Dataset):<br/>    &quot;&quot;&quot;<br/>    Custom dataset for reasoning tasks.<br/>    <br/>    You&#x27;d replace this with your actual data:<br/>    - Sudoku puzzles and solutions<br/>    - Math problems and answers<br/>    - Logic puzzles and solutions<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(self, questions, answers, tokenizer):<br/>        self.questions = questions<br/>        self.answers = answers<br/>        self.tokenizer = tokenizer<br/>    <br/>    def __len__(self):<br/>        return len(self.questions)<br/>    <br/>    def __getitem__(self, idx):<br/>        # Tokenize question and answer<br/>        q_tokens = self.tokenizer.encode(self.questions[idx])<br/>        a_tokens = self.tokenizer.encode(self.answers[idx])<br/>        return torch.tensor(q_tokens), torch.tensor(a_tokens)<br/><br/><br/>def collate_fn(batch):<br/>    &quot;&quot;&quot;<br/>    Pad sequences to same length within a batch.<br/>    <br/>    Why? Transformers need fixed-size inputs within a batch.<br/>    Different batches can have different sizes though.<br/>    &quot;&quot;&quot;<br/>    questions, answers = zip(*batch)<br/>    <br/>    # Pad questions<br/>    q_padded = torch.nn.utils.rnn.pad_sequence(<br/>        questions, <br/>        batch_first=True, <br/>        padding_value=0  # 0 is typically the padding token<br/>    )<br/>    <br/>    # Pad answers<br/>    a_padded = torch.nn.utils.rnn.pad_sequence(<br/>        answers, <br/>        batch_first=True, <br/>        padding_value=0<br/>    )<br/>    <br/>    return q_padded, a_padded<br/><br/><br/># ===== MAIN TRAINING SCRIPT =====<br/><br/># Setup<br/>device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)<br/>print(f&quot;Using device: {device}&quot;)<br/><br/># Create model<br/>vocab_size = 10000  # Adjust based on your tokenizer<br/>model = create_trm_att(vocab_size=vocab_size, d_model=256, n_layers=4)<br/>model = model.to(device)<br/><br/># Count parameters<br/>n_params = model.count_parameters()<br/>print(f&quot;Model has {n_params / 1e6:.2f}M parameters&quot;)<br/><br/># Optimizer and loss<br/>optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)<br/>criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens<br/><br/># Data loading (replace with your actual data)<br/># train_questions = [&quot;Question 1&quot;, &quot;Question 2&quot;, ...]<br/># train_answers = [&quot;Answer 1&quot;, &quot;Answer 2&quot;, ...]<br/># tokenizer = YourTokenizer()<br/><br/># train_dataset = ReasoningDataset(train_questions, train_answers, tokenizer)<br/># train_loader = DataLoader(<br/>#     train_dataset,<br/>#     batch_size=32,<br/>#     shuffle=True,<br/>#     collate_fn=collate_fn<br/># )<br/><br/># Training loop<br/>num_epochs = 50<br/>best_loss = float(&#x27;inf&#x27;)<br/><br/>print(&quot;\n&quot; + &quot;=&quot;*50)<br/>print(&quot;Starting training...&quot;)<br/>print(&quot;=&quot;*50)<br/><br/>for epoch in range(num_epochs):<br/>    model.train()<br/>    epoch_loss = 0<br/>    num_batches = 0<br/>    <br/>    # for questions, answers in train_loader:<br/>    #     questions = questions.to(device)<br/>    #     answers = answers.to(device)<br/>    #     <br/>    #     loss = train_step(model, questions, answers, optimizer, criterion)<br/>    #     epoch_loss += loss<br/>    #     num_batches += 1<br/>    <br/>    # avg_loss = epoch_loss / num_batches<br/>    # print(f&quot;Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}&quot;)<br/>    <br/>    # Save best model<br/>    # if avg_loss &lt; best_loss:<br/>    #     best_loss = avg_loss<br/>    #     torch.save({<br/>    #         &#x27;epoch&#x27;: epoch,<br/>    #         &#x27;model_state_dict&#x27;: model.state_dict(),<br/>    #         &#x27;optimizer_state_dict&#x27;: optimizer.state_dict(),<br/>    #         &#x27;loss&#x27;: avg_loss,<br/>    #     }, &#x27;best_model.pt&#x27;)<br/>    #     print(f&quot;  Saved new best model!&quot;)<br/>    <br/>    # Save checkpoint every 10 epochs<br/>    # if (epoch + 1) % 10 == 0:<br/>    #     torch.save({<br/>    #         &#x27;epoch&#x27;: epoch,<br/>    #         &#x27;model_state_dict&#x27;: model.state_dict(),<br/>    #         &#x27;optimizer_state_dict&#x27;: optimizer.state_dict(),<br/>    #     }, f&#x27;checkpoint_epoch_{epoch+1}.pt&#x27;)<br/><br/>print(&quot;\n Training complete!&quot;)</span></pre><p id="de76" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Personal Note on Training:</strong></p><p id="ae2e" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">The first time I trained TRM, I made every beginner mistake:</p><ol class=""><li id="6787" class="mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr rk qd qe bl">Forgot to clip gradients ‚Üí training exploded at epoch 5</li><li id="8472" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr rk qd qe bl">Learning rate too high ‚Üí loss oscillated wildly</li><li id="f42f" class="mu mv hl mw b mx qf mz na nb qg nd ne nf qh nh ni nj qi nl nm nn qj np nq nr rk qd qe bl">No warmup ‚Üí got stuck in a bad local minimum</li></ol><p id="8416" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">After fixing these (code below), training became smooth. Learn from my mistakes!</p><h2 id="d99d" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 7: Essential Training Tricks (The Stuff They Don‚Äôt Tell You)</h2><p id="a969" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">These techniques make the difference between ‚Äúdoesn‚Äôt work‚Äù and ‚Äúworks amazingly‚Äù:</p><h3 id="567e" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">1. Gradient Clipping (Prevents Explosions)</h3><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="f65f" class="qt nu hl qq b bh qu qv m qw qx">def train_step_with_clipping(model, question_ids, answer_ids, optimizer, criterion):<br/>    &quot;&quot;&quot;<br/>    Training step with gradient clipping.<br/>    <br/>    Why clip? With 24 recursive steps, gradients can grow exponentially.<br/>    Clipping prevents NaN losses and training collapse.<br/>    &quot;&quot;&quot;<br/>    model.train()<br/>    optimizer.zero_grad()<br/>    <br/>    logits = model(question_ids, answer_ids, latent_len=32)<br/>    vocab_size = logits.size(-1)<br/>    loss = criterion(logits.reshape(-1, vocab_size), answer_ids.reshape(-1))<br/>    <br/>    loss.backward()<br/>    <br/>    # CRITICAL: Clip gradients before optimizer step<br/>    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)<br/>    <br/>    optimizer.step()<br/>    <br/>    return loss.item()</span></pre><h3 id="e81e" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">2. Learning Rate Warmup (Gentle Start)</h3><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="8f3e" class="qt nu hl qq b bh qu qv m qw qx">def get_lr_scheduler(optimizer, warmup_steps=1000, total_steps=50000):<br/>    &quot;&quot;&quot;<br/>    Learning rate schedule with warmup and cosine decay.<br/>    <br/>    Warmup: Gradually increase LR from 0 to target<br/>    Cosine decay: Smoothly decrease LR over training<br/>    <br/>    This is what makes training stable!<br/>    &quot;&quot;&quot;<br/>    def lr_lambda(current_step):<br/>        if current_step &lt; warmup_steps:<br/>            # Linear warmup<br/>            return float(current_step) / float(max(1, warmup_steps))<br/>        # Cosine decay<br/>        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))<br/>        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))<br/>    <br/>    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)<br/><br/># Usage<br/>optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)<br/>scheduler = get_lr_scheduler(optimizer)<br/><br/># In training loop:<br/># loss = train_step(...)<br/># scheduler.step()  # Update learning rate</span></pre><h3 id="94eb" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">3. Mixed Precision Training (2‚Äì3x Faster!)</h3><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="93fe" class="qt nu hl qq b bh qu qv m qw qx">from torch.cuda.amp import autocast, GradScaler<br/><br/>def train_with_mixed_precision(model, train_loader, optimizer, criterion, device):<br/>    &quot;&quot;&quot;<br/>    Mixed precision training: Use FP16 for speed, FP32 for stability.<br/>    <br/>    Benefits:<br/>    - 2-3x faster training<br/>    - 50% less GPU memory<br/>    - Maintains accuracy<br/>    &quot;&quot;&quot;<br/>    scaler = GradScaler()<br/>    <br/>    for questions, answers in train_loader:<br/>        questions = questions.to(device)<br/>        answers = answers.to(device)<br/>        <br/>        optimizer.zero_grad()<br/>        <br/>        # Forward pass in FP16<br/>        with autocast():<br/>            logits = model(questions, answers)<br/>            loss = criterion(<br/>                logits.reshape(-1, model.reverse_embedding.out_features),<br/>                answers.reshape(-1)<br/>            )<br/>        <br/>        # Backward pass with gradient scaling<br/>        scaler.scale(loss).backward()<br/>        <br/>        # Unscale before clipping<br/>        scaler.unscale_(optimizer)<br/>        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)<br/>        <br/>        # Optimizer step with scaling<br/>        scaler.step(optimizer)<br/>        scaler.update()</span></pre><h2 id="6363" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 8: Evaluation and Generation (Putting It to Use)</h2><p id="6f90" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">After training, let‚Äôs see what the model can do:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="9dd1" class="qt nu hl qq b bh qu qv m qw qx">@torch.no_grad()<br/>def evaluate_accuracy(model, test_loader, device):<br/>    &quot;&quot;&quot;<br/>    Calculate accuracy on test set.<br/>    <br/>    This is the metric you care about:<br/>    &quot;What percentage of problems did the model solve correctly?&quot;<br/>    &quot;&quot;&quot;<br/>    model.eval()<br/>    correct = 0<br/>    total = 0<br/>    <br/>    for questions, answers in test_loader:<br/>        questions = questions.to(device)<br/>        answers = answers.to(device)<br/>        <br/>        # Generate predictions<br/>        logits = model(questions, answers, latent_len=32)<br/>        predictions = logits.argmax(dim=-1)<br/>        <br/>        # Calculate accuracy (ignore padding tokens)<br/>        mask = answers != 0<br/>        correct += (predictions[mask] == answers[mask]).sum().item()<br/>        total += mask.sum().item()<br/>    <br/>    accuracy = correct / total * 100<br/>    return accuracy<br/><br/><br/>@torch.no_grad()<br/>def generate_answer(model, question_text, tokenizer, device, max_length=50):<br/>    &quot;&quot;&quot;<br/>    Generate an answer for a single question.<br/>    <br/>    This is how you&#x27;d use TRM in production:<br/>    User asks question -&gt; TRM generates answer<br/>    &quot;&quot;&quot;<br/>    model.eval()<br/>    <br/>    # Tokenize question<br/>    question_tokens = tokenizer.encode(question_text)<br/>    question_ids = torch.tensor([question_tokens]).to(device)<br/>    <br/>    # Generate answer<br/>    print(f&quot;\nQuestion: {question_text}&quot;)<br/>    print(&quot;Thinking...&quot;)<br/>    <br/>    generated_ids = model.generate(<br/>        question_ids,<br/>        max_length=max_length,<br/>        latent_len=32,<br/>        temperature=0.7  # Lower = more deterministic, Higher = more random<br/>    )<br/>    <br/>    # Decode to text<br/>    answer_tokens = generated_ids[0].cpu().tolist()<br/>    answer_text = tokenizer.decode(answer_tokens)<br/>    <br/>    print(f&quot;Answer: {answer_text}\n&quot;)<br/>    return answer_text<br/><br/><br/>@torch.no_grad()<br/>def visualize_reasoning_process(model, question_ids, answer_ids, device):<br/>    &quot;&quot;&quot;<br/>    Visualize how the model thinks.<br/>    <br/>    This is super cool - you can actually see the reasoning<br/>    evolve over the 24 recursive steps!<br/>    &quot;&quot;&quot;<br/>    model.eval()<br/>    <br/>    # Get reasoning trajectory<br/>    x = model.embed_tokens(question_ids.to(device))<br/>    y = model.embed_tokens(answer_ids.to(device))<br/>    z = torch.randn(1, 32, model.d_model, device=device) * 0.02<br/>    <br/>    y_final, trajectory = model.recursive_reasoning(<br/>        x, y, z, return_trajectory=True<br/>    )<br/>    <br/>    print(&quot;\n Reasoning Evolution:&quot;)<br/>    print(&quot;=&quot; * 50)<br/>    <br/>    # Show how z evolves (reasoning)<br/>    print(&quot;\n Reasoning Stream (z):&quot;)<br/>    for i, z_state in enumerate(trajectory[&#x27;z_states&#x27;][:5]):  # First 5 steps<br/>        z_norm = z_state.norm(dim=-1).mean().item()<br/>        print(f&quot;  Step {i+1}: norm = {z_norm:.4f}&quot;)<br/>    <br/>    # Show how y evolves (answer)<br/>    print(&quot;\n Answer Stream (y):&quot;)<br/>    for i, y_state in enumerate(trajectory[&#x27;y_states&#x27;][:5]):  # First 5 steps<br/>        y_norm = y_state.norm(dim=-1).mean().item()<br/>        print(f&quot;  Step {i+1}: norm = {y_norm:.4f}&quot;)<br/>    <br/>    print(&quot;\n Final answer generated!&quot;)</span></pre><h2 id="b4df" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 9: Real-World Example (Let‚Äôs Solve Sudoku!)</h2><p id="ca65" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Here‚Äôs how you‚Äôd apply TRM to actually solve Sudoku:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="4c06" class="qt nu hl qq b bh qu qv m qw qx">class SudokuDataset(Dataset):<br/>    &quot;&quot;&quot;<br/>    Dataset for Sudoku puzzles.<br/>    <br/>    Input: 9x9 grid with some numbers filled in<br/>    Output: Complete 9x9 grid<br/>    &quot;&quot;&quot;<br/>    <br/>    def __init__(self, puzzles, solutions):<br/>        &quot;&quot;&quot;<br/>        puzzles: List of 9x9 numpy arrays (0 = empty cell)<br/>        solutions: List of 9x9 numpy arrays (complete grids)<br/>        &quot;&quot;&quot;<br/>        self.puzzles = puzzles<br/>        self.solutions = solutions<br/>    <br/>    def __len__(self):<br/>        return len(self.puzzles)<br/>    <br/>    def __getitem__(self, idx):<br/>        # Flatten grid to sequence<br/>        puzzle = self.puzzles[idx].flatten()  # 81 tokens<br/>        solution = self.solutions[idx].flatten()  # 81 tokens<br/>        <br/>        # Add 1 to avoid 0 (reserved for padding)<br/>        puzzle = torch.tensor(puzzle + 1, dtype=torch.long)<br/>        solution = torch.tensor(solution + 1, dtype=torch.long)<br/>        <br/>        return puzzle, solution<br/><br/><br/>def train_sudoku_solver():<br/>    &quot;&quot;&quot;<br/>    Train TRM to solve Sudoku puzzles.<br/>    <br/>    Paper results:<br/>    - TRM-MLP: 87.4% accuracy on Sudoku-Extreme<br/>    - DeepSeek R1 (671B params): 0.0% accuracy<br/>    - Claude 3.7: 0.0% accuracy<br/>    &quot;&quot;&quot;<br/>    print(&quot; Training Sudoku Solver&quot;)<br/>    print(&quot;=&quot; * 50)<br/>    <br/>    # Model setup<br/>    vocab_size = 11  # Digits 1-9, plus 0 for padding, plus 1 for BOS/EOS<br/>    device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)<br/>    <br/>    # Use TRM-MLP (better for Sudoku!)<br/>    model = create_trm_mlp(vocab_size=vocab_size, d_model=256, n_layers=4)<br/>    model = model.to(device)<br/>    <br/>    print(f&quot;Model: TRM-MLP&quot;)<br/>    print(f&quot;Parameters: {model.count_parameters() / 1e6:.2f}M&quot;)<br/>    print(f&quot;Device: {device}&quot;)<br/>    <br/>    # Optimizer<br/>    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)<br/>    criterion = nn.CrossEntropyLoss(ignore_index=0)<br/>    <br/>    # Load Sudoku data (you&#x27;d replace this with actual data)<br/>    # puzzles = load_sudoku_puzzles()<br/>    # solutions = load_sudoku_solutions()<br/>    # <br/>    # train_dataset = SudokuDataset(puzzles, solutions)<br/>    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)<br/>    <br/>    # Training loop<br/>    # num_epochs = 100<br/>    # for epoch in range(num_epochs):<br/>    #     epoch_loss = 0<br/>    #     for puzzles, solutions in train_loader:<br/>    #         puzzles = puzzles.to(device)<br/>    #         solutions = solutions.to(device)<br/>    #         <br/>    #         loss = train_step_with_clipping(<br/>    #             model, puzzles, solutions, optimizer, criterion<br/>    #         )<br/>    #         epoch_loss += loss<br/>    #     <br/>    #     avg_loss = epoch_loss / len(train_loader)<br/>    #     <br/>    #     if (epoch + 1) % 10 == 0:<br/>    #         # Evaluate<br/>    #         acc = evaluate_accuracy(model, val_loader, device)<br/>    #         print(f&quot;Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={acc:.2f}%&quot;)<br/>    <br/>    return model<br/><br/><br/>def solve_sudoku_puzzle(model, puzzle, device):<br/>    &quot;&quot;&quot;<br/>    Solve a single Sudoku puzzle.<br/>    <br/>    Args:<br/>        model: Trained TRM model<br/>        puzzle: 9x9 numpy array (0 = empty)<br/>        device: torch device<br/>    <br/>    Returns:<br/>        solution: 9x9 numpy array (complete grid)<br/>    &quot;&quot;&quot;<br/>    model.eval()<br/>    <br/>    # Flatten and convert to tensor<br/>    puzzle_flat = torch.tensor(puzzle.flatten() + 1, dtype=torch.long)<br/>    puzzle_flat = puzzle_flat.unsqueeze(0).to(device)<br/>    <br/>    # Generate solution<br/>    with torch.no_grad():<br/>        solution_flat = model.generate(<br/>            puzzle_flat,<br/>            max_length=81,<br/>            latent_len=32,<br/>            temperature=0.1  # Low temperature for deterministic solving<br/>        )<br/>    <br/>    # Convert back to 9x9 grid<br/>    solution = solution_flat[0].cpu().numpy() - 1<br/>    solution = solution.reshape(9, 9)<br/>    <br/>    return solution<br/><br/><br/># Example usage<br/>if __name__ == &quot;__main__&quot;:<br/>    # Create and train model<br/>    # model = train_sudoku_solver()<br/>    <br/>    # Solve a puzzle<br/>    # puzzle = np.array([<br/>    #     [5, 3, 0, 0, 7, 0, 0, 0, 0],<br/>    #     [6, 0, 0, 1, 9, 5, 0, 0, 0],<br/>    #     ...<br/>    # ])<br/>    # <br/>    # solution = solve_sudoku_puzzle(model, puzzle, device)<br/>    # print(&quot;Solution:&quot;)<br/>    # print(solution)<br/>    pass</span></pre><h2 id="d898" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 10: Debugging Guide (When Things Go Wrong)</h2><p id="77fc" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Let me share the issues I ran into and how I fixed them:</p><h3 id="9ea5" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">Issue 1: Loss Stays Constant</h3><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="944c" class="qt nu hl qq b bh qu qv m qw qx"># Symptom: Loss doesn&#x27;t decrease<br/># Epoch 1: 8.5234<br/># Epoch 2: 8.5198<br/># Epoch 3: 8.5201<br/><br/>def debug_static_loss(model, optimizer):<br/>    &quot;&quot;&quot;<br/>    Checklist when loss won&#x27;t decrease:<br/>    &quot;&quot;&quot;<br/>    <br/>    # 1. Check if gradients are flowing<br/>    print(&quot;\nüîç Checking gradients...&quot;)<br/>    for name, param in model.named_parameters():<br/>        if param.grad is not None:<br/>            grad_norm = param.grad.norm().item()<br/>            print(f&quot;  {name}: {grad_norm:.6f}&quot;)<br/>            if grad_norm &lt; 1e-7:<br/>                print(f&quot;    Warning: Very small gradient!&quot;)<br/>    <br/>    # 2. Check learning rate<br/>    print(f&quot;\n Learning rate: {optimizer.param_groups[0][&#x27;lr&#x27;]}&quot;)<br/>    if optimizer.param_groups[0][&#x27;lr&#x27;] &lt; 1e-6:<br/>        print(&quot;  Learning rate might be too small!&quot;)<br/>    <br/>    # 3. Try increasing learning rate<br/>    print(&quot;\n Try: Increase learning rate to 1e-3&quot;)<br/>    <br/>    # 4. Try more reasoning steps<br/>    print(&quot; Try: Increase n_reasoning_steps from 8 to 12&quot;)</span></pre><h3 id="dbe3" class="pi nu hl bg nv pj px ef nz pl py eh od nf pz po pp nj qa pr ps nn qb pu pv pw bl">Issue 3: Out of Memory</h3><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="f149" class="qt nu hl qq b bh qu qv m qw qx">def optimize_memory_usage(model, batch_size):<br/>    &quot;&quot;&quot;<br/>    Strategies to reduce memory usage.<br/>    &quot;&quot;&quot;<br/>    print(&quot;\n Memory Optimization Strategies:&quot;)<br/>    <br/>    print(&quot;\n1. Reduce batch size&quot;)<br/>    print(f&quot;   Current: {batch_size}&quot;)<br/>    print(f&quot;   Try: {batch_size // 2}&quot;)<br/>    <br/>    print(&quot;\n2. Reduce latent length&quot;)<br/>    print(&quot;   Current: 32&quot;)<br/>    print(&quot;   Try: 16&quot;)<br/>    <br/>    print(&quot;\n3. Enable gradient checkpointing&quot;)<br/>    print(&quot;&quot;&quot;<br/>   from torch.utils.checkpoint import checkpoint<br/>   <br/>   def apply_transformer_blocks(self, x):<br/>       for block in self.transformer_blocks:<br/>           x = checkpoint(block, x)<br/>       return x<br/>   &quot;&quot;&quot;)<br/>    <br/>    print(&quot;\n4. Clear cache periodically&quot;)<br/>    print(&quot;&quot;&quot;<br/>   if batch_idx % 10 == 0:<br/>       torch.cuda.empty_cache()<br/>   &quot;&quot;&quot;)</span></pre><h2 id="563c" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Part 11: Complete End-to-End Example</h2><p id="8608" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">Let me put it all together with a complete, runnable example:</p><pre class="qk ql qm qn qo qp qq qr bq qs bc bl"><span id="a5dd" class="qt nu hl qq b bh qu qv m qw qx">&quot;&quot;&quot;<br/>Complete TRM Example: Training and Evaluation<br/>&quot;&quot;&quot;<br/><br/>import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>from torch.utils.data import DataLoader, Dataset<br/>import math<br/><br/># [All the classes we defined above would go here:<br/>#  MultiHeadAttention, FeedForward, TransformerBlock, TRM, etc.]<br/><br/>def main():<br/>    &quot;&quot;&quot;<br/>    Complete training pipeline.<br/>    &quot;&quot;&quot;<br/>    print(&quot;=&quot; * 70)<br/>    print(&quot;  TRM: Transformer Reasoning Model&quot;)<br/>    print(&quot;  Less is More: Recursive Reasoning with Tiny Networks&quot;)<br/>    print(&quot;=&quot; * 70)<br/>    <br/>    # Configuration<br/>    vocab_size = 10000<br/>    d_model = 256<br/>    n_layers = 4<br/>    batch_size = 32<br/>    num_epochs = 50<br/>    learning_rate = 1e-4<br/>    device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)<br/>    <br/>    print(f&quot;\n Configuration:&quot;)<br/>    print(f&quot;  Vocabulary size: {vocab_size}&quot;)<br/>    print(f&quot;  Model dimension: {d_model}&quot;)<br/>    print(f&quot;  Transformer layers: {n_layers}&quot;)<br/>    print(f&quot;  Batch size: {batch_size}&quot;)<br/>    print(f&quot;  Learning rate: {learning_rate}&quot;)<br/>    print(f&quot;  Device: {device}&quot;)<br/>    <br/>    # Create model<br/>    print(f&quot;\nüèóÔ∏è  Building model...&quot;)<br/>    model = create_trm_att(vocab_size, d_model, n_layers)<br/>    model = model.to(device)<br/>    <br/>    n_params = model.count_parameters()<br/>    print(f&quot;  Parameters: {n_params / 1e6:.2f}M&quot;)<br/>    print(f&quot;  Model type: TRM-Att (with attention)&quot;)<br/>    <br/>    # Optimizer and criterion<br/>    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)<br/>    scheduler = get_lr_scheduler(optimizer, warmup_steps=1000)<br/>    criterion = nn.CrossEntropyLoss(ignore_index=0)<br/>    <br/>    # Data (replace with your actual data)<br/>    print(f&quot;\n Loading data...&quot;)<br/>    # train_dataset = YourDataset(...)<br/>    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)<br/>    # val_loader = DataLoader(val_dataset, batch_size=batch_size)<br/>    <br/>    # Training<br/>    print(f&quot;\n Starting training...&quot;)<br/>    print(&quot;=&quot; * 70)<br/>    <br/>    best_val_accuracy = 0<br/>    <br/>    for epoch in range(num_epochs):<br/>        # Training phase<br/>        model.train()<br/>        train_loss = 0<br/>        num_batches = 0<br/>        <br/>        # for questions, answers in train_loader:<br/>        #     questions = questions.to(device)<br/>        #     answers = answers.to(device)<br/>        #     <br/>        #     loss = train_step_with_clipping(<br/>        #         model, questions, answers, optimizer, criterion<br/>        #     )<br/>        #     train_loss += loss<br/>        #     num_batches += 1<br/>        #     scheduler.step()<br/>        <br/>        # avg_train_loss = train_loss / num_batches<br/>        <br/>        # Evaluation phase<br/>        # if (epoch + 1) % 5 == 0:<br/>        #     val_accuracy = evaluate_accuracy(model, val_loader, device)<br/>        #     current_lr = optimizer.param_groups[0][&#x27;lr&#x27;]<br/>        #     <br/>        #     print(f&quot;\nEpoch {epoch+1}/{num_epochs}&quot;)<br/>        #     print(f&quot;  Train Loss: {avg_train_loss:.4f}&quot;)<br/>        #     print(f&quot;  Val Accuracy: {val_accuracy:.2f}%&quot;)<br/>        #     print(f&quot;  Learning Rate: {current_lr:.6f}&quot;)<br/>        #     <br/>        #     if val_accuracy &gt; best_val_accuracy:<br/>        #         best_val_accuracy = val_accuracy<br/>        #         torch.save(model.state_dict(), &#x27;best_trm_model.pt&#x27;)<br/>        #         print(f&quot;  New best model saved!&quot;)<br/>        <br/>        pass  # Remove this when uncommenting above<br/>    <br/>    print(&quot;\n&quot; + &quot;=&quot; * 70)<br/>    print(f&quot; Training complete!&quot;)<br/>    print(f&quot;   Best validation accuracy: {best_val_accuracy:.2f}%&quot;)<br/>    print(&quot;=&quot; * 70)<br/><br/><br/>if __name__ == &quot;__main__&quot;:<br/>    main()</span></pre><h2 id="abcd" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Results That Changed My Mind</h2><p id="d42a" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">When I first read the TRM paper, I was skeptical. ‚ÄúA 7M parameter model beating GPT-4? Come on.‚Äù</p><p id="25e7" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">Then I implemented it and saw the results:</p><h2 id="8d4c" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Sudoku Performance</h2><figure class="qk ql qm qn qo rb qy qz paragraph-image"><div role="button" tabindex="0" class="rc rd fr re bi rf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="qy qz ra"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDWsCZ770WC4WSz0nzmesg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*fDWsCZ770WC4WSz0nzmesg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*fDWsCZ770WC4WSz0nzmesg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*fDWsCZ770WC4WSz0nzmesg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*fDWsCZ770WC4WSz0nzmesg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*fDWsCZ770WC4WSz0nzmesg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*fDWsCZ770WC4WSz0nzmesg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*fDWsCZ770WC4WSz0nzmesg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bi mb rg c" width="700" height="537" loading="lazy" role="presentation"/></picture></div></div></figure><h2 id="efc2" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">ARC-AGI (Abstract Reasoning)</h2><figure class="qk ql qm qn qo rb qy qz paragraph-image"><div role="button" tabindex="0" class="rc rd fr re bi rf"><span class="fw fx fy ao fz ga gb gc gd speechify-ignore">Press enter or click to view image in full size</span><div class="qy qz ra"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfGxWB-bTDPepo-jqu6WKA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*xfGxWB-bTDPepo-jqu6WKA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xfGxWB-bTDPepo-jqu6WKA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xfGxWB-bTDPepo-jqu6WKA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xfGxWB-bTDPepo-jqu6WKA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xfGxWB-bTDPepo-jqu6WKA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xfGxWB-bTDPepo-jqu6WKA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xfGxWB-bTDPepo-jqu6WKA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bi mb rg c" width="700" height="646" loading="lazy" role="presentation"/></picture></div></div></figure><p id="8f20" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">This isn‚Äôt just incremental improvement. This is a <strong class="mw hm">paradigm shift</strong>.</p><h2 id="6339" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">The Challenges</h2><p id="b160" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl"><strong class="mw hm">Challenge 1</strong>: Getting gradients to flow properly through 24 recursive steps. Solution: Gradient clipping and careful initialization.</p><p id="2c0a" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Challenge 2</strong>: Figuring out the right number of reasoning vs refinement steps. Too few: underfitting. Too many: no benefit.</p><p id="f33f" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><strong class="mw hm">Challenge 3</strong>: Understanding how to supervise the model without micromanaging z. Answer: Don‚Äôt! Let it learn.</p><h2 id="e0ac" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Conclusion: The Future is Small</h2><p id="547b" class="pw-post-body-paragraph mu mv hl mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr he bl">We‚Äôve spent years in an arms race for bigger models. GPT-2 ‚Üí GPT-3 ‚Üí GPT-4, each iteration bigger than the last.</p><p id="0c4c" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">TRM shows us a different path: <strong class="mw hm">iterate, don‚Äôt scale.</strong></p><p id="b181" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">The future of AI isn‚Äôt just about billion-parameter models trained on internet-scale data. It‚Äôs about clever architectures that use computation efficiently.</p><p id="39b3" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">TRM is just the beginning. What else can we achieve by rethinking how models think?</p><p id="5fd0" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl">I don‚Äôt know about you, but I‚Äôm excited to find out.</p><h2 id="6db3" class="nt nu hl bg nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bl">Resources</h2><div class="rl rm rn ro rp rq"><a href="https://arxiv.org/html/2510.04871v1?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="rr ac cb"><div class="rs ac cv ci cd rt"><h2 class="bg hm ru ab ga rv rw rx ry rz sa hk bl">Less is More: Recursive Reasoning with Tiny Networks</h2><div class="sb m"><h3 class="bg b ru ab ga rv rw rx ry rz sa eb">Abstract Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different‚Ä¶</h3></div><div class="sc m"><p class="bg b ec ab ga rv rw rx ry rz sa eb">arxiv.org</p></div></div></div></a></div><p id="f351" class="pw-post-body-paragraph mu mv hl mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr he bl"><em class="ns">Thanks for reading! If you build something cool with TRM, I‚Äôd love to hear about it üöÄ</em></p></div></div></div></div></section></div></div></article></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="sd se ac ji"><div class="sb ac"><a class="sf ak ao aq" href="https://medium.com/tag/trm?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><div class="sg fr de sh gv si sj bg b bh ab bl gc">Trm</div></a></div><div class="sb ac"><a class="sf ak ao aq" href="https://medium.com/tag/tiny-recursive-model?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><div class="sg fr de sh gv si sj bg b bh ab bl gc">Tiny Recursive Model</div></a></div><div class="sb ac"><a class="sf ak ao aq" href="https://medium.com/tag/hrm?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><div class="sg fr de sh gv si sj bg b bh ab bl gc">Hrm</div></a></div><div class="sb ac"><a class="sf ak ao aq" href="https://medium.com/tag/hierarchical-reasoning?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><div class="sg fr de sh gv si sj bg b bh ab bl gc">Hierarchical Reasoning</div></a></div><div class="sb ac"><a class="sf ak ao aq" href="https://medium.com/tag/multihead-attention?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><div class="sg fr de sh gv si sj bg b bh ab bl gc">Multihead Attention</div></a></div></div></div></div><div class="m"></div><footer class="sk sl sm sn so ac r sp sq c"><div class="m ag"><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac cw sr"><div class="ac r kr"><div class="ss m"><span class="m st su sv f e"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F68d9df9e1fdb&amp;operation=register&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;user=azhar&amp;userId=685a4c0e34a2&amp;source=---footer_actions--68d9df9e1fdb---------------------clap_footer------------------" rel="noopener follow"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><p class="bg b ec ab eb"><span class="lm">--</span></p></div></div></span><span class="m i h g sw sx"><div class="ac r kr ks"><div class="pw-multi-vote-icon fr kt ku kv kw"><span data-dd-action-name="Susi presentation tracker clap_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F68d9df9e1fdb&amp;operation=register&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;user=azhar&amp;userId=685a4c0e34a2&amp;source=---footer_actions--68d9df9e1fdb---------------------clap_footer------------------" rel="noopener follow"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><div class="kx aq ky kz la lb ao lc ld le kw" role="presentation"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></div></a></span></div><div class="pw-multi-vote-count m lf lg lh li lj lk ll"><p class="bg b ec ab eb"><span class="lm">--</span></p></div></div></span></div><div class="az ac"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button class="aq kx lp lq ac r fs lr ls" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lo"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="bg b bh ab eb"><span class="pw-responses-count ln lo">2</span></p></button></div></div></div></div></div><div class="ac r"><div class="sy m cb"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><span data-dd-action-name="Susi presentation tracker bookmark_footer"><a class="ah ai aj fo al am an ao ap aq ar as at au av" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68d9df9e1fdb&amp;operation=register&amp;redirect=https%3A%2F%2Fmoazharu.medium.com%2Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb&amp;source=---footer_actions--68d9df9e1fdb---------------------bookmark_footer------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="eb lu" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div></div><div class="sy m cb"><div class="bn" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="ah fs aj fo al am an mc ap aq ar fe md me ls mf"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></footer><div class="sz m"><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac iv it ir ta tb"><div class="tc td te tf tg th ti tj tk tl ac cw"><div class="i l"><a tabindex="0" rel="noopener follow" href="/?source=post_page---post_author_info--68d9df9e1fdb---------------------------------------" data-discover="true"><div class="m fr"><img alt="azhar" class="m fk by tm tn de" src="https://miro.medium.com/v2/resize:fill:96:96/1*OlAeNq-E9M64u96VI8Bv-Q@2x.jpeg" width="48" height="48" loading="lazy"/><div class="gj by m tm tn fw o ak to"></div></div></a></div><div class="k j e"><a tabindex="0" rel="noopener follow" href="/?source=post_page---post_author_info--68d9df9e1fdb---------------------------------------" data-discover="true"><div class="m fr"><img alt="azhar" class="m fk by tp tq de" src="https://miro.medium.com/v2/resize:fill:128:128/1*OlAeNq-E9M64u96VI8Bv-Q@2x.jpeg" width="64" height="64" loading="lazy"/><div class="gj by m tp tq fw o ak to"></div></div></a></div><div class="k j e tr cb"><div class="ac"></div></div></div><div class="ac cv cd"><div class="ts tt tu tv tw m"><a class="ah ai aj al am an ao ap aq ar as at au av ac r" rel="noopener follow" href="/?source=post_page---post_author_info--68d9df9e1fdb---------------------------------------" data-discover="true"><h2 class="pw-author-name bg ty tz ua ub uc ud ue nf po pp nj pr ps nn pu pv bl"><span class="he tx">Written by <!-- -->azhar</span></h2></a><div class="sb ac ix"><div class="m cb"><span class="pw-follower-count bg b bh ab eb"><a class="ah ai aj fo al am an ao ap aq ar as at jg" rel="noopener follow" href="/followers?source=post_page---post_author_info--68d9df9e1fdb---------------------------------------" data-discover="true">715 followers</a></span></div><div class="bg b bh ab eb ac uf"><span class="ug m" aria-hidden="true"><span class="bg b bh ab eb">¬∑</span></span><a class="ah ai aj fo al am an ao ap aq ar as at jg" rel="noopener follow" href="/following?source=post_page---post_author_info--68d9df9e1fdb---------------------------------------" data-discover="true">31 following</a></div></div><div class="uh m"><p class="bg b bh ab bl">Data Scientist | Exploring interesting (research paper / concepts). LinkedIn : <a class="ah ai aj fo al am an ao ap aq ar as at ow hf he" href="https://www.linkedin.com/in/mohamed-azharudeen/" rel="noopener  ugc nofollow">https://www.linkedin.com/in/mohamed-azharudeen/</a></p></div></div></div><div class="i l"><div class="ac"></div></div></div></div></div></div><div class="ui uj uk ul um m"><div class="un bi s sz"></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="ac r cw"><h2 class="bg ty nw ny nz oa oc od oe og oh oi ok ol om oo op bl">Responses (<!-- -->2<!-- -->)</h2><div class="ac uo"><div><div class="bn" role="tooltip"><div tabindex="-1" class="bf"><a class="up uq" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--68d9df9e1fdb---------------------------------------" rel="noopener follow" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" aria-label="Shield with a checkmark" viewBox="0 0 25 25"><path fill-rule="evenodd" d="M11.987 5.036a.754.754 0 0 1 .914-.01c.972.721 1.767 1.218 2.6 1.543.828.322 1.719.485 2.887.505a.755.755 0 0 1 .741.757c-.018 3.623-.43 6.256-1.449 8.21-1.034 1.984-2.662 3.209-4.966 4.083a.75.75 0 0 1-.537-.003c-2.243-.874-3.858-2.095-4.897-4.074-1.024-1.951-1.457-4.583-1.476-8.216a.755.755 0 0 1 .741-.757c1.195-.02 2.1-.182 2.923-.503.827-.322 1.6-.815 2.519-1.535m.468.903c-.897.69-1.717 1.21-2.623 1.564-.898.35-1.856.527-3.026.565.037 3.45.469 5.817 1.36 7.515.884 1.684 2.25 2.762 4.284 3.571 2.092-.81 3.465-1.89 4.344-3.575.886-1.698 1.299-4.065 1.334-7.512-1.149-.039-2.091-.217-2.99-.567-.906-.353-1.745-.873-2.683-1.561m-.009 9.155a2.672 2.672 0 1 0 0-5.344 2.672 2.672 0 0 0 0 5.344m0 1a3.672 3.672 0 1 0 0-7.344 3.672 3.672 0 0 0 0 7.344m-1.813-3.777.525-.526.916.917 1.623-1.625.526.526-2.149 2.152z" clip-rule="evenodd"></path></svg></a></div></div></div></div></div><div class="ur us ut uu uv uw ux m"></div><div class="uy m"><button class="bg b bh ab bl sg uz va vb lu lr vc fc fd fe vd ve vf fh vg vh vi vj vk fi fj fk bn fl fm">See all responses</button></div></div></div></div><div class="vl vm vn vo vp m bx"><div class="i l k"><div class="un bi vq vr"></div><div class="ac ci"><div class="cp bi gq gr gs gt"><div class="vs ac kr ji"><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://help.medium.com/hc/en-us?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Help</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://status.medium.com/?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Status</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://medium.com/about?autoplay=1&amp;source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">About</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Careers</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="mailto:pressinquiries@medium.com" rel="noopener follow"><p class="bg b ec ab eb">Press</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://blog.medium.com/?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Blog</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Privacy</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Rules</p></a></div><div class="vt vu m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Terms</p></a></div><div class="vt m"><a class="ah ai aj fo al am an ao ap aq ar as at au av" href="https://speechify.com/medium?source=post_page-----68d9df9e1fdb---------------------------------------" rel="noopener follow"><p class="bg b ec ab eb">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20251118-180542-78bd38dca6"</script><script>window.__GRAPHQL_URI__ = "https://moazharu.medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-68d9df9e1fdb","user-685a4c0e34a2"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"pubFeaturingPostPageLabelEnabled":false,"shouldFollowPostQueryEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"USER","id":"685a4c0e34a2","explicit":true},"viewerIsBot":false},"debug":{"requestId":"ab7ad796-9ae2-4670-bc70-31afccbe9b05","requestTag":"","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-874cfa0bb2ef0cc338546e5bcc4e4afe-67ee18c66386a702-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","host":"moazharu.medium.com","hostname":"moazharu.medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"staticRouterContext":{"route":{"name":"ShowPostUnderUser"},"statusCode":200},"toastQueue":[],"currentToast":null,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20251118-180542-78bd38dca6","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","iosAppId":"828256236","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20251118-180542-78bd38dca6","commit":"78bd38dca616cc8d41e4dc48315b95867b757bc4"}},"datacenter":"us"},"googleAdsCode":"AW-17106321204","googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"167cff2a3d17ac1e64d0762539978f2d54c0058886e8b3c8a03a725a83012ec0","height":630,"width":1200},"postPreviewImage":{"imageId":"bc1f8416df0cad099e43cda2872716e5864f18a73bda2a7547ea082aca9b5632","height":630,"width":1200}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don‚Äôt fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"moazharu.medium.com\"})":null,"postResult({\"id\":\"68d9df9e1fdb\"})":{"__ref":"Post:68d9df9e1fdb"}},"LinkedAccounts:685a4c0e34a2":{"__typename":"LinkedAccounts","mastodon":null,"id":"685a4c0e34a2"},"NewsletterV3:b60770c04658":{"__typename":"NewsletterV3","id":"b60770c04658","type":"NEWSLETTER_TYPE_AUTHOR","slug":"685a4c0e34a2","name":"685a4c0e34a2","collection":null,"user":{"__ref":"User:685a4c0e34a2"}},"User:685a4c0e34a2":{"__typename":"User","id":"685a4c0e34a2","name":"azhar","username":"moazharu","newsletterV3":{"__ref":"NewsletterV3:b60770c04658"},"linkedAccounts":{"__ref":"LinkedAccounts:685a4c0e34a2"},"isSuspended":false,"imageId":"1*OlAeNq-E9M64u96VI8Bv-Q@2x.jpeg","customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"moazharu.medium.com"}},"hasSubdomain":true,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":715,"followingCount":20,"collectionFollowingCount":11},"bio":"Data Scientist | Exploring interesting (research paper \u002F concepts). LinkedIn : https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmohamed-azharudeen\u002F","membership":{"__ref":"Membership:6590a7f7-19aa-4224-9740-0ff3c44f0f2f"},"allowNotes":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:685a4c0e34a2-viewerId:lo_851a71d889ff"},"twitterScreenName":"Azhar41429690"},"Membership:6590a7f7-19aa-4224-9740-0ff3c44f0f2f":{"__typename":"Membership","tier":"MEMBER","id":"6590a7f7-19aa-4224-9740-0ff3c44f0f2f"},"Paragraph:b6b44fd7044e_0":{"__typename":"Paragraph","id":"b6b44fd7044e_0","name":"a81b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants at Their Own Game","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_1":{"__typename":"Paragraph","id":"b6b44fd7044e_1","name":"afa3","type":"P","href":null,"layout":null,"metadata":null,"text":"How a 7 million parameter model outperforms 671 billion parameter models on reasoning tasks and why this changes everything","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":123,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_2":{"__typename":"Paragraph","id":"b6b44fd7044e_2","name":"00c7","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Moment Everything Changed","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_3":{"__typename":"Paragraph","id":"b6b44fd7044e_3","name":"2005","type":"P","href":null,"layout":null,"metadata":null,"text":"Picture this: You‚Äôre working on a Sudoku puzzle. You read the clues once, think hard, and try to write down the complete solution in one shot. Sounds impossible, right?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_4":{"__typename":"Paragraph","id":"b6b44fd7044e_4","name":"d390","type":"P","href":null,"layout":null,"metadata":null,"text":"That‚Äôs exactly how traditional large language models work. They read the problem once and generate an answer in a single forward pass. No wonder GPT-4, Claude, and even the massive 671 billion parameter DeepSeek R1 score 0% on hard Sudoku puzzles.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":221,"end":246,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_5":{"__typename":"Paragraph","id":"b6b44fd7044e_5","name":"191c","type":"P","href":null,"layout":null,"metadata":null,"text":"Now imagine a different approach. You read the puzzle, think about it, maybe even think about your thinking, and then start filling in numbers. You check your work, reconsider, make corrections, and iterate until you‚Äôve got it.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_6":{"__typename":"Paragraph","id":"b6b44fd7044e_6","name":"3dd2","type":"P","href":null,"layout":null,"metadata":null,"text":"This is how humans solve problems. And this is exactly what TRM (Transformer Reasoning Model) does with just 7 million parameters.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_7":{"__typename":"Paragraph","id":"b6b44fd7044e_7","name":"d255","type":"P","href":null,"layout":null,"metadata":null,"text":"The results? 87.4% accuracy on Sudoku puzzles that stumped models 100,000x larger.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_8":{"__typename":"Paragraph","id":"b6b44fd7044e_8","name":"bda7","type":"P","href":null,"layout":null,"metadata":null,"text":"Before we proceed, let‚Äôs stay connected! Please consider following me on Medium, and don‚Äôt forget to connect with me on LinkedIn for a regular dose of data science and deep learning insights.‚Äù üöÄüìäü§ñ","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":120,"end":128,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmohamed-azharudeen\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":73,"end":79,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_9":{"__typename":"Paragraph","id":"b6b44fd7044e_9","name":"9b63","type":"PQ","href":null,"layout":null,"metadata":null,"text":"üì© Note: I‚Äôm not actively checking Medium messages if you have any doubts or concerns about the article, please feel free to reach out to me on LinkedIn.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":153,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_10":{"__typename":"Paragraph","id":"b6b44fd7044e_10","name":"3d32","type":"H4","href":null,"layout":null,"metadata":null,"text":"Why Should You Care?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_11":{"__typename":"Paragraph","id":"b6b44fd7044e_11","name":"cc8f","type":"P","href":null,"layout":null,"metadata":null,"text":"Before we dive into code, let‚Äôs talk about why this is revolutionary:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_12":{"__typename":"Paragraph","id":"b6b44fd7044e_12","name":"213a","type":"H4","href":null,"layout":null,"metadata":null,"text":"The Old Paradigm: Bigger is Better","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_13":{"__typename":"Paragraph","id":"b6b44fd7044e_13","name":"d3ab","type":"P","href":null,"layout":null,"metadata":null,"text":"For years, AI progress looked like this:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_14":{"__typename":"Paragraph","id":"b6b44fd7044e_14","name":"8aa6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"2018: BERT (110M parameters)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_15":{"__typename":"Paragraph","id":"b6b44fd7044e_15","name":"8a0d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"2019: GPT-2 (1.5B parameters)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_16":{"__typename":"Paragraph","id":"b6b44fd7044e_16","name":"95bc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"2020: GPT-3 (175B parameters)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_17":{"__typename":"Paragraph","id":"b6b44fd7044e_17","name":"6778","type":"ULI","href":null,"layout":null,"metadata":null,"text":"2023: GPT-4 (rumored 1.7T parameters)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_18":{"__typename":"Paragraph","id":"b6b44fd7044e_18","name":"27d1","type":"P","href":null,"layout":null,"metadata":null,"text":"The assumption: More parameters = Better reasoning","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_19":{"__typename":"Paragraph","id":"b6b44fd7044e_19","name":"b7e3","type":"H3","href":null,"layout":null,"metadata":null,"text":"The New Reality: Architecture Matters More","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_20":{"__typename":"Paragraph","id":"b6b44fd7044e_20","name":"c423","type":"P","href":null,"layout":null,"metadata":null,"text":"TRM flips this on its head. The paper ‚ÄúLess is More: Recursive Reasoning with Tiny Networks‚Äù shows that a 7M parameter model can beat a 671B parameter model on systematic reasoning tasks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_21":{"__typename":"Paragraph","id":"b6b44fd7044e_21","name":"6d51","type":"P","href":null,"layout":null,"metadata":null,"text":"The insight: It‚Äôs not about how big your brain is; it‚Äôs about how you use it.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_22":{"__typename":"Paragraph","id":"b6b44fd7044e_22","name":"091c","type":"P","href":null,"layout":null,"metadata":null,"text":"This has massive implications:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_23":{"__typename":"Paragraph","id":"b6b44fd7044e_23","name":"4460","type":"ULI","href":null,"layout":null,"metadata":null,"text":"‚úÖ Run powerful AI on your laptop (no cloud needed)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_24":{"__typename":"Paragraph","id":"b6b44fd7044e_24","name":"f6d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"‚úÖ Deploy reasoning models on mobile devices","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_25":{"__typename":"Paragraph","id":"b6b44fd7044e_25","name":"65ca","type":"ULI","href":null,"layout":null,"metadata":null,"text":"‚úÖ Train models in hours instead of weeks","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_26":{"__typename":"Paragraph","id":"b6b44fd7044e_26","name":"6d2c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"‚úÖ Democratize AI (you don‚Äôt need millions of dollars)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_27":{"__typename":"Paragraph","id":"b6b44fd7044e_27","name":"3574","type":"P","href":null,"layout":null,"metadata":null,"text":"Okay, enough philosophy. Let‚Äôs build this thing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_28":{"__typename":"Paragraph","id":"b6b44fd7044e_28","name":"ccd1","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Big Idea: Three Streams and Recursive Thinking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_29":{"__typename":"Paragraph","id":"b6b44fd7044e_29","name":"7182","type":"P","href":null,"layout":null,"metadata":null,"text":"Here‚Äôs the core innovation in one sentence:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_30":{"__typename":"Paragraph","id":"b6b44fd7044e_30","name":"ed0f","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of processing a problem once with a huge network, TRM processes it many times with a tiny network and keeps three separate ‚Äúthoughts‚Äù running in parallel.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":162,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_31":{"__typename":"Paragraph","id":"b6b44fd7044e_31","name":"2bf4","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Three Streams","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_32":{"__typename":"Paragraph","id":"b6b44fd7044e_32","name":"a387","type":"P","href":null,"layout":null,"metadata":null,"text":"Think of it like three Post-it notes on your desk:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_33":{"__typename":"Paragraph","id":"b6b44fd7044e_33","name":"d309","type":"P","href":null,"layout":null,"metadata":null,"text":"1. The Question (x-stream) This is your problem statement. It never changes. You keep referring back to it as you work.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_34":{"__typename":"Paragraph","id":"b6b44fd7044e_34","name":"7c14","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\"Solve: 2x + 3 = 7\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_35":{"__typename":"Paragraph","id":"b6b44fd7044e_35","name":"a221","type":"P","href":null,"layout":null,"metadata":null,"text":"2. Your Current Answer (y-stream) This is your working solution. It starts rough and gets refined through iteration.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_36":{"__typename":"Paragraph","id":"b6b44fd7044e_36","name":"dc34","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Iteration 1: \"x = ?\"\nIteration 5: \"x = maybe 2 or 3\"\nIteration 16: \"x = 2\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"bash"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_37":{"__typename":"Paragraph","id":"b6b44fd7044e_37","name":"af96","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Your Reasoning Notes (z-stream) This is your scratch work. The intermediate thoughts that help you get to the answer.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":34,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_38":{"__typename":"Paragraph","id":"b6b44fd7044e_38","name":"66f6","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\"Need to isolate x... subtract 3 from both sides... \nthen divide by 2... checking: 2*2 + 3 = 7 ‚úì\"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"css"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_39":{"__typename":"Paragraph","id":"b6b44fd7044e_39","name":"eb9e","type":"P","href":null,"layout":null,"metadata":null,"text":"The magic happens when these three streams talk to each other through transformer layers.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_40":{"__typename":"Paragraph","id":"b6b44fd7044e_40","name":"8f39","type":"H3","href":null,"layout":null,"metadata":null,"text":"Architecture Overview: The 10,000 Foot View","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_41":{"__typename":"Paragraph","id":"b6b44fd7044e_41","name":"b4f5","type":"P","href":null,"layout":null,"metadata":null,"text":"Before we write code, let‚Äôs visualize the flow:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*RE5SGAeCzfzpA7dl_PUBpQ.png":{"__typename":"ImageMetadata","id":"1*RE5SGAeCzfzpA7dl_PUBpQ.png","originalHeight":1330,"originalWidth":848,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:b6b44fd7044e_42":{"__typename":"Paragraph","id":"b6b44fd7044e_42","name":"b69a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*RE5SGAeCzfzpA7dl_PUBpQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_43":{"__typename":"Paragraph","id":"b6b44fd7044e_43","name":"7517","type":"P","href":null,"layout":null,"metadata":null,"text":"Simple, right? Now let‚Äôs implement it piece by piece.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_44":{"__typename":"Paragraph","id":"b6b44fd7044e_44","name":"a545","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 1: Building Blocks ‚Äî The Attention Mechanism","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_45":{"__typename":"Paragraph","id":"b6b44fd7044e_45","name":"c97f","type":"P","href":null,"layout":null,"metadata":null,"text":"Let me start with a confession: I‚Äôve implemented attention dozens of times, and it still feels like magic every time it works.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_46":{"__typename":"Paragraph","id":"b6b44fd7044e_46","name":"b3f2","type":"P","href":null,"layout":null,"metadata":null,"text":"Here‚Äôs the intuition: Attention lets each word ask every other word ‚ÄúHey, how relevant are you to me right now?‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":22,"end":112,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_47":{"__typename":"Paragraph","id":"b6b44fd7044e_47","name":"814d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\"\n    Multi-head attention: The secret sauce of transformers.\n    \n    Intuition: Instead of one attention mechanism, we have multiple \n    \"attention heads\" that each focus on different aspects of the input.\n    \n    Head 1 might focus on: \"What words are nouns?\"\n    Head 2 might focus on: \"What words are related to time?\"\n    Head 3 might focus on: \"What words are negations?\"\n    \"\"\"\n    \n    def __init__(self, d_model, n_heads, dropout=0.1):\n        super().__init__()\n        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n        \n        self.d_model = d_model      # Total embedding dimension (e.g., 256)\n        self.n_heads = n_heads      # Number of attention heads (e.g., 4)\n        self.d_k = d_model \u002F\u002F n_heads  # Dimension per head (256\u002F4 = 64)\n        \n        # These projections create our Queries, Keys, and Values\n        self.q_proj = nn.Linear(d_model, d_model)\n        self.k_proj = nn.Linear(d_model, d_model)\n        self.v_proj = nn.Linear(d_model, d_model)\n        \n        # Final output projection\n        self.out_proj = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask=None):\n        batch_size, seq_len, d_model = x.shape\n        \n        # Step 1: Project to Q, K, V\n        # Think of this as creating three different \"views\" of the input\n        q = self.q_proj(x)  # Queries: \"What am I looking for?\"\n        k = self.k_proj(x)  # Keys: \"What information do I have?\"\n        v = self.v_proj(x)  # Values: \"What should I output?\"\n        \n        # Step 2: Split into multiple heads\n        # Shape: [batch, seq_len, d_model] -\u003E [batch, n_heads, seq_len, d_k]\n        q = q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        k = k.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        v = v.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n        \n        # Step 3: Compute attention scores\n        # This is the \"How much should I pay attention to each word?\" step\n        scores = torch.matmul(q, k.transpose(-2, -1)) \u002F math.sqrt(self.d_k)\n        \n        # Why divide by sqrt(d_k)? \n        # Without it, dot products get very large -\u003E softmax becomes peaked\n        # -\u003E gradients vanish -\u003E training fails\n        # With it, we keep values in a nice range for softmax\n        \n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        \n        # Step 4: Apply softmax to get attention weights\n        # Now scores are probabilities (sum to 1)\n        attn_weights = F.softmax(scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        \n        # Step 5: Apply attention to values\n        # This is the actual \"paying attention\" step\n        attn_output = torch.matmul(attn_weights, v)\n        \n        # Step 6: Reshape and project back\n        attn_output = attn_output.transpose(1, 2).contiguous()\n        attn_output = attn_output.view(batch_size, seq_len, d_model)\n        output = self.out_proj(attn_output)\n        \n        return output","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_48":{"__typename":"Paragraph","id":"b6b44fd7044e_48","name":"a1fd","type":"P","href":null,"layout":null,"metadata":null,"text":"Real Talk: When I first learned attention, the sqrt(d_k) scaling confused me. Here‚Äôs why it matters:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_49":{"__typename":"Paragraph","id":"b6b44fd7044e_49","name":"3289","type":"P","href":null,"layout":null,"metadata":null,"text":"Imagine you‚Äôre at a party trying to have a conversation. If everyone whispers (small dot products), you can hear multiple people. If everyone shouts (large dot products), you can only focus on the loudest person. The scaling keeps everyone at ‚Äúnormal speaking volume.‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_50":{"__typename":"Paragraph","id":"b6b44fd7044e_50","name":"e031","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 2: The Feed-Forward Network (The Thinking Layer)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_51":{"__typename":"Paragraph","id":"b6b44fd7044e_51","name":"aef9","type":"P","href":null,"layout":null,"metadata":null,"text":"After attention figures out what‚Äôs relevant, the feed-forward network does the actual ‚Äúthinking‚Äù:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_52":{"__typename":"Paragraph","id":"b6b44fd7044e_52","name":"081a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class FeedForward(nn.Module):\n    \"\"\"\n    Feed-forward network (also called MLP - Multi-Layer Perceptron).\n    \n    This is where the actual transformation happens. Think of it as:\n    - Layer 1: Expand your thoughts (d_model -\u003E d_ff)\n    - Activation: Non-linear thinking (GELU)\n    - Layer 2: Compress back to useful format (d_ff -\u003E d_model)\n    \"\"\"\n    \n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        # Typical: d_ff = 4 * d_model (e.g., 256 -\u003E 1024)\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        # Expand -\u003E Activate -\u003E Compress\n        return self.linear2(self.dropout(F.gelu(self.linear1(x))))","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_53":{"__typename":"Paragraph","id":"b6b44fd7044e_53","name":"74cc","type":"P","href":null,"layout":null,"metadata":null,"text":"Why GELU instead of ReLU?","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_54":{"__typename":"Paragraph","id":"b6b44fd7044e_54","name":"ce6d","type":"P","href":null,"layout":null,"metadata":null,"text":"I used to always use ReLU (the classic activation function). But GELU (Gaussian Error Linear Unit) is smoother.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_55":{"__typename":"Paragraph","id":"b6b44fd7044e_55","name":"8ea4","type":"P","href":null,"layout":null,"metadata":null,"text":"Think of it this way:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_56":{"__typename":"Paragraph","id":"b6b44fd7044e_56","name":"46c9","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ReLU: ‚ÄúIs this positive? YES ‚Üí keep it. NO ‚Üí kill it.‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_57":{"__typename":"Paragraph","id":"b6b44fd7044e_57","name":"8d81","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GELU: ‚ÄúIs this positive? Probably ‚Üí keep most of it. Probably not ‚Üí keep a little bit.‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_58":{"__typename":"Paragraph","id":"b6b44fd7044e_58","name":"d868","type":"P","href":null,"layout":null,"metadata":null,"text":"GELU‚Äôs smoothness helps gradients flow better during training. It‚Äôs like the difference between binary decisions and nuanced thinking.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_59":{"__typename":"Paragraph","id":"b6b44fd7044e_59","name":"26dc","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 3: The Transformer Block (Putting It Together)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_60":{"__typename":"Paragraph","id":"b6b44fd7044e_60","name":"0fa4","type":"P","href":null,"layout":null,"metadata":null,"text":"Now we combine attention and feed-forward into a transformer block:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_61":{"__typename":"Paragraph","id":"b6b44fd7044e_61","name":"c61f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class TransformerBlock(nn.Module):\n    \"\"\"\n    A single transformer block. The paper uses 4 of these in sequence.\n    \n    Structure:\n    1. Multi-head attention (tokens talk to each other)\n    2. Add & Normalize (residual connection)\n    3. Feed-forward (actually process the information)\n    4. Add & Normalize (another residual connection)\n    \n    The \"Add\" parts are crucial - they let information flow directly\n    through the network without going through all the transformations.\n    This prevents vanishing gradients.\n    \"\"\"\n    \n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1, use_attention=True):\n        super().__init__()\n        self.use_attention = use_attention  # False for TRM-MLP variant\n        \n        if use_attention:\n            self.attention = MultiHeadAttention(d_model, n_heads, dropout)\n            self.norm1 = nn.LayerNorm(d_model)\n        \n        self.ffn = FeedForward(d_model, d_ff, dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask=None):\n        # Block 1: Self-attention (if enabled)\n        if self.use_attention:\n            # Save input for residual connection\n            residual = x\n            # Apply attention\n            x = self.attention(x, mask)\n            # Add residual and normalize\n            x = self.norm1(residual + self.dropout(x))\n        \n        # Block 2: Feed-forward\n        residual = x\n        x = self.ffn(x)\n        x = self.norm2(residual + self.dropout(x))\n        \n        return x","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_62":{"__typename":"Paragraph","id":"b6b44fd7044e_62","name":"259b","type":"P","href":null,"layout":null,"metadata":null,"text":"A Cool Finding from the Paper:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_63":{"__typename":"Paragraph","id":"b6b44fd7044e_63","name":"80ee","type":"P","href":null,"layout":null,"metadata":null,"text":"The TRM-MLP variant (where use_attention=False) actually works better on some tasks!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":27,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_64":{"__typename":"Paragraph","id":"b6b44fd7044e_64","name":"d04b","type":"P","href":null,"layout":null,"metadata":null,"text":"For Sudoku: TRM-MLP gets 87.4% accuracy vs TRM-Att‚Äôs 74.7%.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_65":{"__typename":"Paragraph","id":"b6b44fd7044e_65","name":"2330","type":"P","href":null,"layout":null,"metadata":null,"text":"This blew my mind. Attention is supposed to be the key to transformers, right? But sometimes, simpler is better. The MLP-only version is faster, uses less memory, and learns better for certain structured problems.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_66":{"__typename":"Paragraph","id":"b6b44fd7044e_66","name":"07b4","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 4: The Complete TRM Model (Here‚Äôs Where Magic Happens)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_67":{"__typename":"Paragraph","id":"b6b44fd7044e_67","name":"20e8","type":"P","href":null,"layout":null,"metadata":null,"text":"Now for the main event. This is where we implement the three-stream architecture and recursive reasoning:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_68":{"__typename":"Paragraph","id":"b6b44fd7044e_68","name":"efaa","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class TRM(nn.Module):\n    \"\"\"\n    Transformer Reasoning Model - The Full Implementation\n    \n    This is where TRM's innovation shines:\n    - Three separate streams: question (x), answer (y), reasoning (z)\n    - Recursive updates: process multiple times instead of once\n    - Selective updates: only change what needs changing at each step\n    \n    Result: Tiny network (7M params) beats huge networks (671B params)\n    \"\"\"\n    \n    def __init__(\n        self,\n        vocab_size,           # Size of your vocabulary\n        d_model=256,          # Embedding dimension\n        n_heads=4,            # Number of attention heads\n        d_ff=1024,            # Feed-forward dimension (4x d_model)\n        n_layers=4,           # Number of transformer blocks\n        max_seq_len=512,      # Maximum sequence length\n        dropout=0.1,          # Dropout probability\n        n_reasoning_steps=8,  # How many times to update z\n        n_refinement_steps=16,# How many times to update y\n        use_attention=True,   # False for TRM-MLP variant\n        tie_embeddings=True   # Share input\u002Foutput embeddings (saves params)\n    ):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.n_reasoning_steps = n_reasoning_steps\n        self.n_refinement_steps = n_refinement_steps\n        self.use_attention = use_attention\n        \n        # Token embeddings: converts token IDs to vectors\n        # Example: token \"hello\" (ID: 42) -\u003E 256-dim vector\n        self.token_embedding = nn.Embedding(vocab_size, d_model)\n        \n        # Positional embeddings: adds position information\n        # Transformers have no inherent notion of order!\n        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n        \n        self.embedding_dropout = nn.Dropout(dropout)\n        \n        # Stack of transformer blocks (4x in the paper)\n        self.transformer_blocks = nn.ModuleList([\n            TransformerBlock(d_model, n_heads, d_ff, dropout, use_attention)\n            for _ in range(n_layers)\n        ])\n        \n        # Reverse embedding: converts vectors back to token probabilities\n        # This is how we go from hidden states to actual words\n        self.reverse_embedding = nn.Linear(d_model, vocab_size, bias=False)\n        \n        # Weight tying: a clever trick to reduce parameters\n        # Use the same weights for embedding and un-embedding\n        if tie_embeddings:\n            self.reverse_embedding.weight = self.token_embedding.weight\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        \"\"\"\n        Initialize weights properly. This matters more than you'd think!\n        \n        Too large: training explodes\n        Too small: training is too slow\n        Just right: Goldilocks initialization\n        \"\"\"\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                # Initialize with small random values\n                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            elif isinstance(module, nn.LayerNorm):\n                nn.init.ones_(module.weight)\n                nn.init.zeros_(module.bias)\n    \n    def embed_tokens(self, token_ids):\n        \"\"\"\n        Convert token IDs to embeddings with positional information.\n        \n        Example:\n        Input:  [1, 42, 7, 13]  (token IDs)\n        Output: [[0.23, -0.45, ...],  (256-dim vectors)\n                 [0.12, 0.89, ...],\n                 [-0.34, 0.67, ...],\n                 [0.56, -0.12, ...]]\n        \"\"\"\n        batch_size, seq_len = token_ids.shape\n        \n        # Get token embeddings\n        token_emb = self.token_embedding(token_ids)\n        \n        # Get positional embeddings\n        # Position 0, 1, 2, 3, ... for each sequence\n        positions = torch.arange(seq_len, device=token_ids.device)\n        positions = positions.unsqueeze(0).expand(batch_size, -1)\n        pos_emb = self.position_embedding(positions)\n        \n        # Combine token + position information\n        embeddings = self.embedding_dropout(token_emb + pos_emb)\n        \n        return embeddings\n    \n    def apply_transformer_blocks(self, x, mask=None):\n        \"\"\"Apply all transformer blocks sequentially.\"\"\"\n        for block in self.transformer_blocks:\n            x = block(x, mask)\n        return x\n    \n    def forward_pass(self, x, y, z, mask=None):\n        \"\"\"\n        THIS IS THE KEY INNOVATION!\n        \n        Single forward pass through the model. We:\n        1. Concatenate x, y, z (all three streams)\n        2. Process through transformers (they all talk to each other)\n        3. Split back into x, y, z (separate the streams again)\n        \n        This allows cross-stream attention:\n        - y can look at x to remember the question\n        - y can look at z to use the reasoning\n        - z can look at x to understand the problem\n        - z can look at y to see current progress\n        \"\"\"\n        # Remember the lengths (we need to split back later)\n        len_x = x.size(1)\n        len_y = y.size(1)\n        len_z = z.size(1)\n        \n        # Concatenate along sequence dimension\n        # If x is length 10, y is length 5, z is length 32\n        # combined is length 10+5+32 = 47\n        combined = torch.cat([x, y, z], dim=1)\n        \n        # Pass through all transformer blocks\n        # Each position can now attend to all other positions\n        # across all three streams!\n        combined = self.apply_transformer_blocks(combined, mask)\n        \n        # Split back into three streams\n        x_new = combined[:, :len_x, :]\n        y_new = combined[:, len_x:len_x + len_y, :]\n        z_new = combined[:, len_x + len_y:, :]\n        \n        return x_new, y_new, z_new\n    \n    def recursive_reasoning(self, x, y, z, mask=None, return_trajectory=False):\n        \"\"\"\n        The heart of TRM: recursive reasoning.\n        \n        Phase 1 (8 steps): Build up reasoning in z\n        Phase 2 (16 steps): Refine answer in y\n        \n        This is like:\n        Phase 1: Reading and understanding the problem deeply\n        Phase 2: Working through the solution step by step\n        \"\"\"\n        trajectory = {'z_states': [], 'y_states': []} if return_trajectory else None\n        \n        # ===== PHASE 1: BUILD REASONING =====\n        print(f\"Phase 1: Building reasoning ({self.n_reasoning_steps} steps)...\")\n        for step in range(self.n_reasoning_steps):\n            # Process all three streams\n            x_new, y_new, z_new = self.forward_pass(x, y, z, mask)\n            \n            # ONLY UPDATE Z\n            # x stays fixed (question doesn't change)\n            # y stays fixed (not ready to answer yet)\n            # z gets updated (building understanding)\n            z = z_new\n            \n            if return_trajectory:\n                trajectory['z_states'].append(z.detach().clone())\n        \n        print(f\"Phase 2: Refining answer ({self.n_refinement_steps} steps)...\")\n        # ===== PHASE 2: REFINE ANSWER =====\n        for step in range(self.n_refinement_steps):\n            x_new, y_new, z_new = self.forward_pass(x, y, z, mask)\n            \n            # ONLY UPDATE Y\n            # x stays fixed (question doesn't change)\n            # z stays fixed (we've built our reasoning)\n            # y gets updated (refining our answer)\n            y = y_new\n            \n            if return_trajectory:\n                trajectory['y_states'].append(y.detach().clone())\n        \n        return (y, trajectory) if return_trajectory else y\n    \n    def forward(self, question_ids, answer_ids=None, latent_len=32, mask=None):\n        \"\"\"\n        Complete forward pass.\n        \n        Args:\n            question_ids: Input question as token IDs [batch, len_q]\n            answer_ids: Target answer as token IDs [batch, len_a]\n            latent_len: Length of reasoning sequence (typically 32)\n        \n        Returns:\n            logits: Predicted tokens [batch, len_a, vocab_size]\n        \"\"\"\n        batch_size = question_ids.size(0)\n        device = question_ids.device\n        \n        # Step 1: Embed the question (x stream)\n        x = self.embed_tokens(question_ids)\n        \n        # Step 2: Initialize or embed the answer (y stream)\n        if answer_ids is not None:\n            # Training: start with target answer embeddings\n            y = self.embed_tokens(answer_ids)\n        else:\n            # Inference: start with random embeddings\n            len_a = 32  # default answer length\n            y = torch.randn(batch_size, len_a, self.d_model, device=device) * 0.02\n        \n        # Step 3: Initialize reasoning (z stream) with random noise\n        # The model will learn what to put here!\n        z = torch.randn(batch_size, latent_len, self.d_model, device=device) * 0.02\n        \n        # Step 4: Do the recursive reasoning magic!\n        y_final = self.recursive_reasoning(x, y, z, mask)\n        \n        # Step 5: Convert final answer embeddings to token probabilities\n        logits = self.reverse_embedding(y_final)\n        \n        return logits\n    \n    def generate(self, question_ids, max_length=50, latent_len=32, temperature=1.0):\n        \"\"\"\n        Generate an answer autoregressively.\n        \n        This is how you'd use the model in production:\n        1. Give it a question\n        2. It thinks recursively\n        3. It generates an answer token by token\n        \"\"\"\n        batch_size = question_ids.size(0)\n        device = question_ids.device\n        \n        # Start with a beginning-of-sequence token (or zeros)\n        generated = torch.zeros(batch_size, 1, dtype=torch.long, device=device)\n        \n        for i in range(max_length):\n            # Get predictions for current sequence\n            logits = self.forward(question_ids, generated, latent_len)\n            \n            # Sample next token (with temperature for randomness)\n            next_token_logits = logits[:, -1, :] \u002F temperature\n            probs = F.softmax(next_token_logits, dim=-1)\n            next_token = torch.multinomial(probs, num_samples=1)\n            \n            # Add to sequence\n            generated = torch.cat([generated, next_token], dim=1)\n            \n            # Optional: stop if end-of-sequence token\n            # if (next_token == eos_token_id).all():\n            #     break\n        \n        return generated\n    \n    def count_parameters(self):\n        \"\"\"Count total trainable parameters.\"\"\"\n        return sum(p.numel() for p in self.parameters() if p.requires_grad)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_69":{"__typename":"Paragraph","id":"b6b44fd7044e_69","name":"b9d8","type":"P","href":null,"layout":null,"metadata":null,"text":"Let me explain what just happened:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":34,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_70":{"__typename":"Paragraph","id":"b6b44fd7044e_70","name":"4d33","type":"P","href":null,"layout":null,"metadata":null,"text":"The recursive_reasoning method is where TRM's magic lives. Instead of processing the problem once, it processes it 24 times (8 + 16).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":4,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_71":{"__typename":"Paragraph","id":"b6b44fd7044e_71","name":"cde6","type":"P","href":null,"layout":null,"metadata":null,"text":"Phase 1 (Update z): ‚ÄúLet me really understand this problem‚Ä¶‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_72":{"__typename":"Paragraph","id":"b6b44fd7044e_72","name":"5ad1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 1: ‚ÄúOkay, I see the question‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_73":{"__typename":"Paragraph","id":"b6b44fd7044e_73","name":"a85e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 2: ‚ÄúThese seem to be the constraints‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_74":{"__typename":"Paragraph","id":"b6b44fd7044e_74","name":"c630","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 3‚Äì6: ‚ÄúI‚Äôm building a mental model of the solution space‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_75":{"__typename":"Paragraph","id":"b6b44fd7044e_75","name":"a450","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 7‚Äì8: ‚ÄúGot it, I know how to approach this‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_76":{"__typename":"Paragraph","id":"b6b44fd7044e_76","name":"e3bd","type":"P","href":null,"layout":null,"metadata":null,"text":"Phase 2 (Update y): ‚ÄúNow let me work through the solution‚Ä¶‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_77":{"__typename":"Paragraph","id":"b6b44fd7044e_77","name":"bceb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 1‚Äì4: ‚ÄúHere‚Äôs my first attempt‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_78":{"__typename":"Paragraph","id":"b6b44fd7044e_78","name":"ead6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 5‚Äì8: ‚ÄúWait, that doesn‚Äôt work, let me revise‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_79":{"__typename":"Paragraph","id":"b6b44fd7044e_79","name":"3c4e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 9‚Äì12: ‚ÄúGetting closer‚Ä¶‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_80":{"__typename":"Paragraph","id":"b6b44fd7044e_80","name":"aadc","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Step 13‚Äì16: ‚ÄúFinal answer!‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_81":{"__typename":"Paragraph","id":"b6b44fd7044e_81","name":"8364","type":"P","href":null,"layout":null,"metadata":null,"text":"This is exactly how you‚Äôd solve a hard problem yourself.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_82":{"__typename":"Paragraph","id":"b6b44fd7044e_82","name":"5797","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 5: Model Variants (The Plot Twist)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_83":{"__typename":"Paragraph","id":"b6b44fd7044e_83","name":"5e77","type":"P","href":null,"layout":null,"metadata":null,"text":"Remember how I said attention was optional? Here are helper functions to create both variants:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_84":{"__typename":"Paragraph","id":"b6b44fd7044e_84","name":"d57d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def create_trm_att(vocab_size, d_model=256, n_layers=4):\n    \"\"\"\n    Create TRM-Att variant (with attention).\n    \n    This is the \"standard\" transformer approach.\n    Parameters: ~7M\n    Best for: General reasoning tasks\n    \"\"\"\n    return TRM(\n        vocab_size=vocab_size,\n        d_model=d_model,\n        n_heads=4,\n        d_ff=d_model * 4,  # 256 * 4 = 1024\n        n_layers=n_layers,\n        n_reasoning_steps=8,\n        n_refinement_steps=16,\n        use_attention=True  # Key difference!\n    )\n\n\ndef create_trm_mlp(vocab_size, d_model=256, n_layers=4):\n    \"\"\"\n    Create TRM-MLP variant (MLP-only, no attention).\n    \n    Simpler, faster, sometimes better!\n    Parameters: ~5M (30% fewer than TRM-Att)\n    Best for: Structured problems like Sudoku\n    \n    Fun fact: This variant scored 87.4% on Sudoku vs 74.7% for TRM-Att.\n    Sometimes less really is more!\n    \"\"\"\n    return TRM(\n        vocab_size=vocab_size,\n        d_model=d_model,\n        n_heads=4,  # Not used, but kept for compatibility\n        d_ff=d_model * 4,\n        n_layers=n_layers,\n        n_reasoning_steps=8,\n        n_refinement_steps=16,\n        use_attention=False  # This is the magic!\n    )","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_85":{"__typename":"Paragraph","id":"b6b44fd7044e_85","name":"86af","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 6: Training the Model (Making It Smart)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_86":{"__typename":"Paragraph","id":"b6b44fd7044e_86","name":"c7e8","type":"P","href":null,"layout":null,"metadata":null,"text":"Now let‚Äôs write the training code. This is where the model actually learns:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_87":{"__typename":"Paragraph","id":"b6b44fd7044e_87","name":"ffc9","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def train_step(model, question_ids, answer_ids, optimizer, criterion):\n    \"\"\"\n    Single training step. This runs thousands of times during training.\n    \n    The beauty of TRM is that we only need to supervise the final output.\n    The model figures out how to use the z-stream on its own!\n    \"\"\"\n    model.train()  # Enable dropout, etc.\n    optimizer.zero_grad()  # Reset gradients\n    \n    # Forward pass with all that recursive reasoning\n    logits = model(question_ids, answer_ids, latent_len=32)\n    \n    # Compute loss\n    # We're doing cross-entropy: \"How well did you predict the right token?\"\n    vocab_size = logits.size(-1)\n    loss = criterion(\n        logits.reshape(-1, vocab_size),  # Flatten to [batch*seq_len, vocab]\n        answer_ids.reshape(-1)            # Flatten to [batch*seq_len]\n    )\n    \n    # Backward pass (compute gradients)\n    loss.backward()\n    \n    # Update weights\n    optimizer.step()\n    \n    return loss.item()\n\n\ndef evaluate(model, question_ids, answer_ids, criterion):\n    \"\"\"Evaluation without updating weights.\"\"\"\n    model.eval()  # Disable dropout\n    with torch.no_grad():  # Don't compute gradients (faster, less memory)\n        logits = model(question_ids, answer_ids, latent_len=32)\n        vocab_size = logits.size(-1)\n        loss = criterion(logits.reshape(-1, vocab_size), answer_ids.reshape(-1))\n    return loss.item()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_88":{"__typename":"Paragraph","id":"b6b44fd7044e_88","name":"4641","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Complete Training Loop","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_89":{"__typename":"Paragraph","id":"b6b44fd7044e_89","name":"dc6e","type":"P","href":null,"layout":null,"metadata":null,"text":"Here‚Äôs a full training script you can actually run:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_90":{"__typename":"Paragraph","id":"b6b44fd7044e_90","name":"4e9a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from torch.utils.data import DataLoader, Dataset\n\nclass ReasoningDataset(Dataset):\n    \"\"\"\n    Custom dataset for reasoning tasks.\n    \n    You'd replace this with your actual data:\n    - Sudoku puzzles and solutions\n    - Math problems and answers\n    - Logic puzzles and solutions\n    \"\"\"\n    \n    def __init__(self, questions, answers, tokenizer):\n        self.questions = questions\n        self.answers = answers\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.questions)\n    \n    def __getitem__(self, idx):\n        # Tokenize question and answer\n        q_tokens = self.tokenizer.encode(self.questions[idx])\n        a_tokens = self.tokenizer.encode(self.answers[idx])\n        return torch.tensor(q_tokens), torch.tensor(a_tokens)\n\n\ndef collate_fn(batch):\n    \"\"\"\n    Pad sequences to same length within a batch.\n    \n    Why? Transformers need fixed-size inputs within a batch.\n    Different batches can have different sizes though.\n    \"\"\"\n    questions, answers = zip(*batch)\n    \n    # Pad questions\n    q_padded = torch.nn.utils.rnn.pad_sequence(\n        questions, \n        batch_first=True, \n        padding_value=0  # 0 is typically the padding token\n    )\n    \n    # Pad answers\n    a_padded = torch.nn.utils.rnn.pad_sequence(\n        answers, \n        batch_first=True, \n        padding_value=0\n    )\n    \n    return q_padded, a_padded\n\n\n# ===== MAIN TRAINING SCRIPT =====\n\n# Setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Create model\nvocab_size = 10000  # Adjust based on your tokenizer\nmodel = create_trm_att(vocab_size=vocab_size, d_model=256, n_layers=4)\nmodel = model.to(device)\n\n# Count parameters\nn_params = model.count_parameters()\nprint(f\"Model has {n_params \u002F 1e6:.2f}M parameters\")\n\n# Optimizer and loss\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n\n# Data loading (replace with your actual data)\n# train_questions = [\"Question 1\", \"Question 2\", ...]\n# train_answers = [\"Answer 1\", \"Answer 2\", ...]\n# tokenizer = YourTokenizer()\n\n# train_dataset = ReasoningDataset(train_questions, train_answers, tokenizer)\n# train_loader = DataLoader(\n#     train_dataset,\n#     batch_size=32,\n#     shuffle=True,\n#     collate_fn=collate_fn\n# )\n\n# Training loop\nnum_epochs = 50\nbest_loss = float('inf')\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Starting training...\")\nprint(\"=\"*50)\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    num_batches = 0\n    \n    # for questions, answers in train_loader:\n    #     questions = questions.to(device)\n    #     answers = answers.to(device)\n    #     \n    #     loss = train_step(model, questions, answers, optimizer, criterion)\n    #     epoch_loss += loss\n    #     num_batches += 1\n    \n    # avg_loss = epoch_loss \u002F num_batches\n    # print(f\"Epoch {epoch+1}\u002F{num_epochs} - Loss: {avg_loss:.4f}\")\n    \n    # Save best model\n    # if avg_loss \u003C best_loss:\n    #     best_loss = avg_loss\n    #     torch.save({\n    #         'epoch': epoch,\n    #         'model_state_dict': model.state_dict(),\n    #         'optimizer_state_dict': optimizer.state_dict(),\n    #         'loss': avg_loss,\n    #     }, 'best_model.pt')\n    #     print(f\"  Saved new best model!\")\n    \n    # Save checkpoint every 10 epochs\n    # if (epoch + 1) % 10 == 0:\n    #     torch.save({\n    #         'epoch': epoch,\n    #         'model_state_dict': model.state_dict(),\n    #         'optimizer_state_dict': optimizer.state_dict(),\n    #     }, f'checkpoint_epoch_{epoch+1}.pt')\n\nprint(\"\\n Training complete!\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_91":{"__typename":"Paragraph","id":"b6b44fd7044e_91","name":"de76","type":"P","href":null,"layout":null,"metadata":null,"text":"Personal Note on Training:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":26,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_92":{"__typename":"Paragraph","id":"b6b44fd7044e_92","name":"ae2e","type":"P","href":null,"layout":null,"metadata":null,"text":"The first time I trained TRM, I made every beginner mistake:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_93":{"__typename":"Paragraph","id":"b6b44fd7044e_93","name":"6787","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Forgot to clip gradients ‚Üí training exploded at epoch 5","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_94":{"__typename":"Paragraph","id":"b6b44fd7044e_94","name":"8472","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Learning rate too high ‚Üí loss oscillated wildly","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_95":{"__typename":"Paragraph","id":"b6b44fd7044e_95","name":"f42f","type":"OLI","href":null,"layout":null,"metadata":null,"text":"No warmup ‚Üí got stuck in a bad local minimum","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_96":{"__typename":"Paragraph","id":"b6b44fd7044e_96","name":"8416","type":"P","href":null,"layout":null,"metadata":null,"text":"After fixing these (code below), training became smooth. Learn from my mistakes!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_97":{"__typename":"Paragraph","id":"b6b44fd7044e_97","name":"d99d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 7: Essential Training Tricks (The Stuff They Don‚Äôt Tell You)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_98":{"__typename":"Paragraph","id":"b6b44fd7044e_98","name":"a969","type":"P","href":null,"layout":null,"metadata":null,"text":"These techniques make the difference between ‚Äúdoesn‚Äôt work‚Äù and ‚Äúworks amazingly‚Äù:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_99":{"__typename":"Paragraph","id":"b6b44fd7044e_99","name":"567e","type":"H4","href":null,"layout":null,"metadata":null,"text":"1. Gradient Clipping (Prevents Explosions)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_100":{"__typename":"Paragraph","id":"b6b44fd7044e_100","name":"f65f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def train_step_with_clipping(model, question_ids, answer_ids, optimizer, criterion):\n    \"\"\"\n    Training step with gradient clipping.\n    \n    Why clip? With 24 recursive steps, gradients can grow exponentially.\n    Clipping prevents NaN losses and training collapse.\n    \"\"\"\n    model.train()\n    optimizer.zero_grad()\n    \n    logits = model(question_ids, answer_ids, latent_len=32)\n    vocab_size = logits.size(-1)\n    loss = criterion(logits.reshape(-1, vocab_size), answer_ids.reshape(-1))\n    \n    loss.backward()\n    \n    # CRITICAL: Clip gradients before optimizer step\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    \n    optimizer.step()\n    \n    return loss.item()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_101":{"__typename":"Paragraph","id":"b6b44fd7044e_101","name":"e81e","type":"H4","href":null,"layout":null,"metadata":null,"text":"2. Learning Rate Warmup (Gentle Start)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_102":{"__typename":"Paragraph","id":"b6b44fd7044e_102","name":"8f3e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def get_lr_scheduler(optimizer, warmup_steps=1000, total_steps=50000):\n    \"\"\"\n    Learning rate schedule with warmup and cosine decay.\n    \n    Warmup: Gradually increase LR from 0 to target\n    Cosine decay: Smoothly decrease LR over training\n    \n    This is what makes training stable!\n    \"\"\"\n    def lr_lambda(current_step):\n        if current_step \u003C warmup_steps:\n            # Linear warmup\n            return float(current_step) \u002F float(max(1, warmup_steps))\n        # Cosine decay\n        progress = float(current_step - warmup_steps) \u002F float(max(1, total_steps - warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n    \n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\n# Usage\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = get_lr_scheduler(optimizer)\n\n# In training loop:\n# loss = train_step(...)\n# scheduler.step()  # Update learning rate","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_103":{"__typename":"Paragraph","id":"b6b44fd7044e_103","name":"94eb","type":"H4","href":null,"layout":null,"metadata":null,"text":"3. Mixed Precision Training (2‚Äì3x Faster!)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_104":{"__typename":"Paragraph","id":"b6b44fd7044e_104","name":"93fe","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from torch.cuda.amp import autocast, GradScaler\n\ndef train_with_mixed_precision(model, train_loader, optimizer, criterion, device):\n    \"\"\"\n    Mixed precision training: Use FP16 for speed, FP32 for stability.\n    \n    Benefits:\n    - 2-3x faster training\n    - 50% less GPU memory\n    - Maintains accuracy\n    \"\"\"\n    scaler = GradScaler()\n    \n    for questions, answers in train_loader:\n        questions = questions.to(device)\n        answers = answers.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass in FP16\n        with autocast():\n            logits = model(questions, answers)\n            loss = criterion(\n                logits.reshape(-1, model.reverse_embedding.out_features),\n                answers.reshape(-1)\n            )\n        \n        # Backward pass with gradient scaling\n        scaler.scale(loss).backward()\n        \n        # Unscale before clipping\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        # Optimizer step with scaling\n        scaler.step(optimizer)\n        scaler.update()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_105":{"__typename":"Paragraph","id":"b6b44fd7044e_105","name":"6363","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 8: Evaluation and Generation (Putting It to Use)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_106":{"__typename":"Paragraph","id":"b6b44fd7044e_106","name":"6f90","type":"P","href":null,"layout":null,"metadata":null,"text":"After training, let‚Äôs see what the model can do:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_107":{"__typename":"Paragraph","id":"b6b44fd7044e_107","name":"9dd1","type":"PRE","href":null,"layout":null,"metadata":null,"text":"@torch.no_grad()\ndef evaluate_accuracy(model, test_loader, device):\n    \"\"\"\n    Calculate accuracy on test set.\n    \n    This is the metric you care about:\n    \"What percentage of problems did the model solve correctly?\"\n    \"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    for questions, answers in test_loader:\n        questions = questions.to(device)\n        answers = answers.to(device)\n        \n        # Generate predictions\n        logits = model(questions, answers, latent_len=32)\n        predictions = logits.argmax(dim=-1)\n        \n        # Calculate accuracy (ignore padding tokens)\n        mask = answers != 0\n        correct += (predictions[mask] == answers[mask]).sum().item()\n        total += mask.sum().item()\n    \n    accuracy = correct \u002F total * 100\n    return accuracy\n\n\n@torch.no_grad()\ndef generate_answer(model, question_text, tokenizer, device, max_length=50):\n    \"\"\"\n    Generate an answer for a single question.\n    \n    This is how you'd use TRM in production:\n    User asks question -\u003E TRM generates answer\n    \"\"\"\n    model.eval()\n    \n    # Tokenize question\n    question_tokens = tokenizer.encode(question_text)\n    question_ids = torch.tensor([question_tokens]).to(device)\n    \n    # Generate answer\n    print(f\"\\nQuestion: {question_text}\")\n    print(\"Thinking...\")\n    \n    generated_ids = model.generate(\n        question_ids,\n        max_length=max_length,\n        latent_len=32,\n        temperature=0.7  # Lower = more deterministic, Higher = more random\n    )\n    \n    # Decode to text\n    answer_tokens = generated_ids[0].cpu().tolist()\n    answer_text = tokenizer.decode(answer_tokens)\n    \n    print(f\"Answer: {answer_text}\\n\")\n    return answer_text\n\n\n@torch.no_grad()\ndef visualize_reasoning_process(model, question_ids, answer_ids, device):\n    \"\"\"\n    Visualize how the model thinks.\n    \n    This is super cool - you can actually see the reasoning\n    evolve over the 24 recursive steps!\n    \"\"\"\n    model.eval()\n    \n    # Get reasoning trajectory\n    x = model.embed_tokens(question_ids.to(device))\n    y = model.embed_tokens(answer_ids.to(device))\n    z = torch.randn(1, 32, model.d_model, device=device) * 0.02\n    \n    y_final, trajectory = model.recursive_reasoning(\n        x, y, z, return_trajectory=True\n    )\n    \n    print(\"\\n Reasoning Evolution:\")\n    print(\"=\" * 50)\n    \n    # Show how z evolves (reasoning)\n    print(\"\\n Reasoning Stream (z):\")\n    for i, z_state in enumerate(trajectory['z_states'][:5]):  # First 5 steps\n        z_norm = z_state.norm(dim=-1).mean().item()\n        print(f\"  Step {i+1}: norm = {z_norm:.4f}\")\n    \n    # Show how y evolves (answer)\n    print(\"\\n Answer Stream (y):\")\n    for i, y_state in enumerate(trajectory['y_states'][:5]):  # First 5 steps\n        y_norm = y_state.norm(dim=-1).mean().item()\n        print(f\"  Step {i+1}: norm = {y_norm:.4f}\")\n    \n    print(\"\\n Final answer generated!\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"less"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_108":{"__typename":"Paragraph","id":"b6b44fd7044e_108","name":"b4df","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 9: Real-World Example (Let‚Äôs Solve Sudoku!)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_109":{"__typename":"Paragraph","id":"b6b44fd7044e_109","name":"ca65","type":"P","href":null,"layout":null,"metadata":null,"text":"Here‚Äôs how you‚Äôd apply TRM to actually solve Sudoku:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_110":{"__typename":"Paragraph","id":"b6b44fd7044e_110","name":"4c06","type":"PRE","href":null,"layout":null,"metadata":null,"text":"class SudokuDataset(Dataset):\n    \"\"\"\n    Dataset for Sudoku puzzles.\n    \n    Input: 9x9 grid with some numbers filled in\n    Output: Complete 9x9 grid\n    \"\"\"\n    \n    def __init__(self, puzzles, solutions):\n        \"\"\"\n        puzzles: List of 9x9 numpy arrays (0 = empty cell)\n        solutions: List of 9x9 numpy arrays (complete grids)\n        \"\"\"\n        self.puzzles = puzzles\n        self.solutions = solutions\n    \n    def __len__(self):\n        return len(self.puzzles)\n    \n    def __getitem__(self, idx):\n        # Flatten grid to sequence\n        puzzle = self.puzzles[idx].flatten()  # 81 tokens\n        solution = self.solutions[idx].flatten()  # 81 tokens\n        \n        # Add 1 to avoid 0 (reserved for padding)\n        puzzle = torch.tensor(puzzle + 1, dtype=torch.long)\n        solution = torch.tensor(solution + 1, dtype=torch.long)\n        \n        return puzzle, solution\n\n\ndef train_sudoku_solver():\n    \"\"\"\n    Train TRM to solve Sudoku puzzles.\n    \n    Paper results:\n    - TRM-MLP: 87.4% accuracy on Sudoku-Extreme\n    - DeepSeek R1 (671B params): 0.0% accuracy\n    - Claude 3.7: 0.0% accuracy\n    \"\"\"\n    print(\" Training Sudoku Solver\")\n    print(\"=\" * 50)\n    \n    # Model setup\n    vocab_size = 11  # Digits 1-9, plus 0 for padding, plus 1 for BOS\u002FEOS\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Use TRM-MLP (better for Sudoku!)\n    model = create_trm_mlp(vocab_size=vocab_size, d_model=256, n_layers=4)\n    model = model.to(device)\n    \n    print(f\"Model: TRM-MLP\")\n    print(f\"Parameters: {model.count_parameters() \u002F 1e6:.2f}M\")\n    print(f\"Device: {device}\")\n    \n    # Optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    # Load Sudoku data (you'd replace this with actual data)\n    # puzzles = load_sudoku_puzzles()\n    # solutions = load_sudoku_solutions()\n    # \n    # train_dataset = SudokuDataset(puzzles, solutions)\n    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    \n    # Training loop\n    # num_epochs = 100\n    # for epoch in range(num_epochs):\n    #     epoch_loss = 0\n    #     for puzzles, solutions in train_loader:\n    #         puzzles = puzzles.to(device)\n    #         solutions = solutions.to(device)\n    #         \n    #         loss = train_step_with_clipping(\n    #             model, puzzles, solutions, optimizer, criterion\n    #         )\n    #         epoch_loss += loss\n    #     \n    #     avg_loss = epoch_loss \u002F len(train_loader)\n    #     \n    #     if (epoch + 1) % 10 == 0:\n    #         # Evaluate\n    #         acc = evaluate_accuracy(model, val_loader, device)\n    #         print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={acc:.2f}%\")\n    \n    return model\n\n\ndef solve_sudoku_puzzle(model, puzzle, device):\n    \"\"\"\n    Solve a single Sudoku puzzle.\n    \n    Args:\n        model: Trained TRM model\n        puzzle: 9x9 numpy array (0 = empty)\n        device: torch device\n    \n    Returns:\n        solution: 9x9 numpy array (complete grid)\n    \"\"\"\n    model.eval()\n    \n    # Flatten and convert to tensor\n    puzzle_flat = torch.tensor(puzzle.flatten() + 1, dtype=torch.long)\n    puzzle_flat = puzzle_flat.unsqueeze(0).to(device)\n    \n    # Generate solution\n    with torch.no_grad():\n        solution_flat = model.generate(\n            puzzle_flat,\n            max_length=81,\n            latent_len=32,\n            temperature=0.1  # Low temperature for deterministic solving\n        )\n    \n    # Convert back to 9x9 grid\n    solution = solution_flat[0].cpu().numpy() - 1\n    solution = solution.reshape(9, 9)\n    \n    return solution\n\n\n# Example usage\nif __name__ == \"__main__\":\n    # Create and train model\n    # model = train_sudoku_solver()\n    \n    # Solve a puzzle\n    # puzzle = np.array([\n    #     [5, 3, 0, 0, 7, 0, 0, 0, 0],\n    #     [6, 0, 0, 1, 9, 5, 0, 0, 0],\n    #     ...\n    # ])\n    # \n    # solution = solve_sudoku_puzzle(model, puzzle, device)\n    # print(\"Solution:\")\n    # print(solution)\n    pass","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_111":{"__typename":"Paragraph","id":"b6b44fd7044e_111","name":"d898","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 10: Debugging Guide (When Things Go Wrong)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_112":{"__typename":"Paragraph","id":"b6b44fd7044e_112","name":"77fc","type":"P","href":null,"layout":null,"metadata":null,"text":"Let me share the issues I ran into and how I fixed them:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_113":{"__typename":"Paragraph","id":"b6b44fd7044e_113","name":"9ea5","type":"H4","href":null,"layout":null,"metadata":null,"text":"Issue 1: Loss Stays Constant","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_114":{"__typename":"Paragraph","id":"b6b44fd7044e_114","name":"944c","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Symptom: Loss doesn't decrease\n# Epoch 1: 8.5234\n# Epoch 2: 8.5198\n# Epoch 3: 8.5201\n\ndef debug_static_loss(model, optimizer):\n    \"\"\"\n    Checklist when loss won't decrease:\n    \"\"\"\n    \n    # 1. Check if gradients are flowing\n    print(\"\\nüîç Checking gradients...\")\n    for name, param in model.named_parameters():\n        if param.grad is not None:\n            grad_norm = param.grad.norm().item()\n            print(f\"  {name}: {grad_norm:.6f}\")\n            if grad_norm \u003C 1e-7:\n                print(f\"    Warning: Very small gradient!\")\n    \n    # 2. Check learning rate\n    print(f\"\\n Learning rate: {optimizer.param_groups[0]['lr']}\")\n    if optimizer.param_groups[0]['lr'] \u003C 1e-6:\n        print(\"  Learning rate might be too small!\")\n    \n    # 3. Try increasing learning rate\n    print(\"\\n Try: Increase learning rate to 1e-3\")\n    \n    # 4. Try more reasoning steps\n    print(\" Try: Increase n_reasoning_steps from 8 to 12\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_115":{"__typename":"Paragraph","id":"b6b44fd7044e_115","name":"dbe3","type":"H4","href":null,"layout":null,"metadata":null,"text":"Issue 3: Out of Memory","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_116":{"__typename":"Paragraph","id":"b6b44fd7044e_116","name":"f149","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def optimize_memory_usage(model, batch_size):\n    \"\"\"\n    Strategies to reduce memory usage.\n    \"\"\"\n    print(\"\\n Memory Optimization Strategies:\")\n    \n    print(\"\\n1. Reduce batch size\")\n    print(f\"   Current: {batch_size}\")\n    print(f\"   Try: {batch_size \u002F\u002F 2}\")\n    \n    print(\"\\n2. Reduce latent length\")\n    print(\"   Current: 32\")\n    print(\"   Try: 16\")\n    \n    print(\"\\n3. Enable gradient checkpointing\")\n    print(\"\"\"\n   from torch.utils.checkpoint import checkpoint\n   \n   def apply_transformer_blocks(self, x):\n       for block in self.transformer_blocks:\n           x = checkpoint(block, x)\n       return x\n   \"\"\")\n    \n    print(\"\\n4. Clear cache periodically\")\n    print(\"\"\"\n   if batch_idx % 10 == 0:\n       torch.cuda.empty_cache()\n   \"\"\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_117":{"__typename":"Paragraph","id":"b6b44fd7044e_117","name":"563c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Part 11: Complete End-to-End Example","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_118":{"__typename":"Paragraph","id":"b6b44fd7044e_118","name":"8608","type":"P","href":null,"layout":null,"metadata":null,"text":"Let me put it all together with a complete, runnable example:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_119":{"__typename":"Paragraph","id":"b6b44fd7044e_119","name":"a5dd","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\"\"\"\nComplete TRM Example: Training and Evaluation\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport math\n\n# [All the classes we defined above would go here:\n#  MultiHeadAttention, FeedForward, TransformerBlock, TRM, etc.]\n\ndef main():\n    \"\"\"\n    Complete training pipeline.\n    \"\"\"\n    print(\"=\" * 70)\n    print(\"  TRM: Transformer Reasoning Model\")\n    print(\"  Less is More: Recursive Reasoning with Tiny Networks\")\n    print(\"=\" * 70)\n    \n    # Configuration\n    vocab_size = 10000\n    d_model = 256\n    n_layers = 4\n    batch_size = 32\n    num_epochs = 50\n    learning_rate = 1e-4\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    print(f\"\\n Configuration:\")\n    print(f\"  Vocabulary size: {vocab_size}\")\n    print(f\"  Model dimension: {d_model}\")\n    print(f\"  Transformer layers: {n_layers}\")\n    print(f\"  Batch size: {batch_size}\")\n    print(f\"  Learning rate: {learning_rate}\")\n    print(f\"  Device: {device}\")\n    \n    # Create model\n    print(f\"\\nüèóÔ∏è  Building model...\")\n    model = create_trm_att(vocab_size, d_model, n_layers)\n    model = model.to(device)\n    \n    n_params = model.count_parameters()\n    print(f\"  Parameters: {n_params \u002F 1e6:.2f}M\")\n    print(f\"  Model type: TRM-Att (with attention)\")\n    \n    # Optimizer and criterion\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = get_lr_scheduler(optimizer, warmup_steps=1000)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    # Data (replace with your actual data)\n    print(f\"\\n Loading data...\")\n    # train_dataset = YourDataset(...)\n    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    # val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    # Training\n    print(f\"\\n Starting training...\")\n    print(\"=\" * 70)\n    \n    best_val_accuracy = 0\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0\n        num_batches = 0\n        \n        # for questions, answers in train_loader:\n        #     questions = questions.to(device)\n        #     answers = answers.to(device)\n        #     \n        #     loss = train_step_with_clipping(\n        #         model, questions, answers, optimizer, criterion\n        #     )\n        #     train_loss += loss\n        #     num_batches += 1\n        #     scheduler.step()\n        \n        # avg_train_loss = train_loss \u002F num_batches\n        \n        # Evaluation phase\n        # if (epoch + 1) % 5 == 0:\n        #     val_accuracy = evaluate_accuracy(model, val_loader, device)\n        #     current_lr = optimizer.param_groups[0]['lr']\n        #     \n        #     print(f\"\\nEpoch {epoch+1}\u002F{num_epochs}\")\n        #     print(f\"  Train Loss: {avg_train_loss:.4f}\")\n        #     print(f\"  Val Accuracy: {val_accuracy:.2f}%\")\n        #     print(f\"  Learning Rate: {current_lr:.6f}\")\n        #     \n        #     if val_accuracy \u003E best_val_accuracy:\n        #         best_val_accuracy = val_accuracy\n        #         torch.save(model.state_dict(), 'best_trm_model.pt')\n        #         print(f\"  New best model saved!\")\n        \n        pass  # Remove this when uncommenting above\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(f\" Training complete!\")\n    print(f\"   Best validation accuracy: {best_val_accuracy:.2f}%\")\n    print(\"=\" * 70)\n\n\nif __name__ == \"__main__\":\n    main()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_120":{"__typename":"Paragraph","id":"b6b44fd7044e_120","name":"abcd","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Results That Changed My Mind","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_121":{"__typename":"Paragraph","id":"b6b44fd7044e_121","name":"d42a","type":"P","href":null,"layout":null,"metadata":null,"text":"When I first read the TRM paper, I was skeptical. ‚ÄúA 7M parameter model beating GPT-4? Come on.‚Äù","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_122":{"__typename":"Paragraph","id":"b6b44fd7044e_122","name":"25e7","type":"P","href":null,"layout":null,"metadata":null,"text":"Then I implemented it and saw the results:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_123":{"__typename":"Paragraph","id":"b6b44fd7044e_123","name":"8d4c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Sudoku Performance","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*fDWsCZ770WC4WSz0nzmesg.png":{"__typename":"ImageMetadata","id":"1*fDWsCZ770WC4WSz0nzmesg.png","originalHeight":650,"originalWidth":848,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:b6b44fd7044e_124":{"__typename":"Paragraph","id":"b6b44fd7044e_124","name":"fd69","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*fDWsCZ770WC4WSz0nzmesg.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_125":{"__typename":"Paragraph","id":"b6b44fd7044e_125","name":"efc2","type":"H3","href":null,"layout":null,"metadata":null,"text":"ARC-AGI (Abstract Reasoning)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*xfGxWB-bTDPepo-jqu6WKA.png":{"__typename":"ImageMetadata","id":"1*xfGxWB-bTDPepo-jqu6WKA.png","originalHeight":782,"originalWidth":848,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:b6b44fd7044e_126":{"__typename":"Paragraph","id":"b6b44fd7044e_126","name":"a91d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xfGxWB-bTDPepo-jqu6WKA.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_127":{"__typename":"Paragraph","id":"b6b44fd7044e_127","name":"8f20","type":"P","href":null,"layout":null,"metadata":null,"text":"This isn‚Äôt just incremental improvement. This is a paradigm shift.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":51,"end":65,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_128":{"__typename":"Paragraph","id":"b6b44fd7044e_128","name":"6339","type":"H3","href":null,"layout":null,"metadata":null,"text":"The Challenges","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_129":{"__typename":"Paragraph","id":"b6b44fd7044e_129","name":"b160","type":"P","href":null,"layout":null,"metadata":null,"text":"Challenge 1: Getting gradients to flow properly through 24 recursive steps. Solution: Gradient clipping and careful initialization.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_130":{"__typename":"Paragraph","id":"b6b44fd7044e_130","name":"2c0a","type":"P","href":null,"layout":null,"metadata":null,"text":"Challenge 2: Figuring out the right number of reasoning vs refinement steps. Too few: underfitting. Too many: no benefit.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_131":{"__typename":"Paragraph","id":"b6b44fd7044e_131","name":"f33f","type":"P","href":null,"layout":null,"metadata":null,"text":"Challenge 3: Understanding how to supervise the model without micromanaging z. Answer: Don‚Äôt! Let it learn.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_132":{"__typename":"Paragraph","id":"b6b44fd7044e_132","name":"e0ac","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion: The Future is Small","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_133":{"__typename":"Paragraph","id":"b6b44fd7044e_133","name":"547b","type":"P","href":null,"layout":null,"metadata":null,"text":"We‚Äôve spent years in an arms race for bigger models. GPT-2 ‚Üí GPT-3 ‚Üí GPT-4, each iteration bigger than the last.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_134":{"__typename":"Paragraph","id":"b6b44fd7044e_134","name":"0c4c","type":"P","href":null,"layout":null,"metadata":null,"text":"TRM shows us a different path: iterate, don‚Äôt scale.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":31,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_135":{"__typename":"Paragraph","id":"b6b44fd7044e_135","name":"b181","type":"P","href":null,"layout":null,"metadata":null,"text":"The future of AI isn‚Äôt just about billion-parameter models trained on internet-scale data. It‚Äôs about clever architectures that use computation efficiently.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_136":{"__typename":"Paragraph","id":"b6b44fd7044e_136","name":"39b3","type":"P","href":null,"layout":null,"metadata":null,"text":"TRM is just the beginning. What else can we achieve by rethinking how models think?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_137":{"__typename":"Paragraph","id":"b6b44fd7044e_137","name":"5fd0","type":"P","href":null,"layout":null,"metadata":null,"text":"I don‚Äôt know about you, but I‚Äôm excited to find out.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_138":{"__typename":"Paragraph","id":"b6b44fd7044e_138","name":"6db3","type":"H3","href":null,"layout":null,"metadata":null,"text":"Resources","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:b6b44fd7044e_139":{"__typename":"Paragraph","id":"b6b44fd7044e_139","name":"5921","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Less is More: Recursive Reasoning with Tiny Networks\nAbstract Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different‚Ä¶arxiv.org","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":181,"href":"https:\u002F\u002Farxiv.org\u002Fhtml\u002F2510.04871v1","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":53,"end":172,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Farxiv.org\u002Fhtml\u002F2510.04871v1","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":""}},"Paragraph:b6b44fd7044e_140":{"__typename":"Paragraph","id":"b6b44fd7044e_140","name":"f351","type":"P","href":null,"layout":null,"metadata":null,"text":"Thanks for reading! If you build something cool with TRM, I‚Äôd love to hear about it üöÄ","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":86,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"UserViewerEdge:userId:685a4c0e34a2-viewerId:lo_851a71d889ff":{"__typename":"UserViewerEdge","id":"userId:685a4c0e34a2-viewerId:lo_851a71d889ff","isMuting":false},"PostViewerEdge:postId:68d9df9e1fdb-viewerId:lo_851a71d889ff":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:68d9df9e1fdb-viewerId:lo_851a71d889ff"},"Tag:trm":{"__typename":"Tag","id":"trm","displayTitle":"Trm","normalizedTagSlug":"trm"},"Tag:tiny-recursive-model":{"__typename":"Tag","id":"tiny-recursive-model","displayTitle":"Tiny Recursive Model","normalizedTagSlug":"tiny-recursive-model"},"Tag:hrm":{"__typename":"Tag","id":"hrm","displayTitle":"Hrm","normalizedTagSlug":"hrm"},"Tag:hierarchical-reasoning":{"__typename":"Tag","id":"hierarchical-reasoning","displayTitle":"Hierarchical Reasoning","normalizedTagSlug":"hierarchical-reasoning"},"Tag:multihead-attention":{"__typename":"Tag","id":"multihead-attention","displayTitle":"Multihead Attention","normalizedTagSlug":"multihead-attention"},"Post:68d9df9e1fdb":{"__typename":"Post","id":"68d9df9e1fdb","collection":null,"content({\"postMeteringOptions\":{\"referrer\":\"\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"cbbc","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:b6b44fd7044e_0"},{"__ref":"Paragraph:b6b44fd7044e_1"},{"__ref":"Paragraph:b6b44fd7044e_2"},{"__ref":"Paragraph:b6b44fd7044e_3"},{"__ref":"Paragraph:b6b44fd7044e_4"},{"__ref":"Paragraph:b6b44fd7044e_5"},{"__ref":"Paragraph:b6b44fd7044e_6"},{"__ref":"Paragraph:b6b44fd7044e_7"},{"__ref":"Paragraph:b6b44fd7044e_8"},{"__ref":"Paragraph:b6b44fd7044e_9"},{"__ref":"Paragraph:b6b44fd7044e_10"},{"__ref":"Paragraph:b6b44fd7044e_11"},{"__ref":"Paragraph:b6b44fd7044e_12"},{"__ref":"Paragraph:b6b44fd7044e_13"},{"__ref":"Paragraph:b6b44fd7044e_14"},{"__ref":"Paragraph:b6b44fd7044e_15"},{"__ref":"Paragraph:b6b44fd7044e_16"},{"__ref":"Paragraph:b6b44fd7044e_17"},{"__ref":"Paragraph:b6b44fd7044e_18"},{"__ref":"Paragraph:b6b44fd7044e_19"},{"__ref":"Paragraph:b6b44fd7044e_20"},{"__ref":"Paragraph:b6b44fd7044e_21"},{"__ref":"Paragraph:b6b44fd7044e_22"},{"__ref":"Paragraph:b6b44fd7044e_23"},{"__ref":"Paragraph:b6b44fd7044e_24"},{"__ref":"Paragraph:b6b44fd7044e_25"},{"__ref":"Paragraph:b6b44fd7044e_26"},{"__ref":"Paragraph:b6b44fd7044e_27"},{"__ref":"Paragraph:b6b44fd7044e_28"},{"__ref":"Paragraph:b6b44fd7044e_29"},{"__ref":"Paragraph:b6b44fd7044e_30"},{"__ref":"Paragraph:b6b44fd7044e_31"},{"__ref":"Paragraph:b6b44fd7044e_32"},{"__ref":"Paragraph:b6b44fd7044e_33"},{"__ref":"Paragraph:b6b44fd7044e_34"},{"__ref":"Paragraph:b6b44fd7044e_35"},{"__ref":"Paragraph:b6b44fd7044e_36"},{"__ref":"Paragraph:b6b44fd7044e_37"},{"__ref":"Paragraph:b6b44fd7044e_38"},{"__ref":"Paragraph:b6b44fd7044e_39"},{"__ref":"Paragraph:b6b44fd7044e_40"},{"__ref":"Paragraph:b6b44fd7044e_41"},{"__ref":"Paragraph:b6b44fd7044e_42"},{"__ref":"Paragraph:b6b44fd7044e_43"},{"__ref":"Paragraph:b6b44fd7044e_44"},{"__ref":"Paragraph:b6b44fd7044e_45"},{"__ref":"Paragraph:b6b44fd7044e_46"},{"__ref":"Paragraph:b6b44fd7044e_47"},{"__ref":"Paragraph:b6b44fd7044e_48"},{"__ref":"Paragraph:b6b44fd7044e_49"},{"__ref":"Paragraph:b6b44fd7044e_50"},{"__ref":"Paragraph:b6b44fd7044e_51"},{"__ref":"Paragraph:b6b44fd7044e_52"},{"__ref":"Paragraph:b6b44fd7044e_53"},{"__ref":"Paragraph:b6b44fd7044e_54"},{"__ref":"Paragraph:b6b44fd7044e_55"},{"__ref":"Paragraph:b6b44fd7044e_56"},{"__ref":"Paragraph:b6b44fd7044e_57"},{"__ref":"Paragraph:b6b44fd7044e_58"},{"__ref":"Paragraph:b6b44fd7044e_59"},{"__ref":"Paragraph:b6b44fd7044e_60"},{"__ref":"Paragraph:b6b44fd7044e_61"},{"__ref":"Paragraph:b6b44fd7044e_62"},{"__ref":"Paragraph:b6b44fd7044e_63"},{"__ref":"Paragraph:b6b44fd7044e_64"},{"__ref":"Paragraph:b6b44fd7044e_65"},{"__ref":"Paragraph:b6b44fd7044e_66"},{"__ref":"Paragraph:b6b44fd7044e_67"},{"__ref":"Paragraph:b6b44fd7044e_68"},{"__ref":"Paragraph:b6b44fd7044e_69"},{"__ref":"Paragraph:b6b44fd7044e_70"},{"__ref":"Paragraph:b6b44fd7044e_71"},{"__ref":"Paragraph:b6b44fd7044e_72"},{"__ref":"Paragraph:b6b44fd7044e_73"},{"__ref":"Paragraph:b6b44fd7044e_74"},{"__ref":"Paragraph:b6b44fd7044e_75"},{"__ref":"Paragraph:b6b44fd7044e_76"},{"__ref":"Paragraph:b6b44fd7044e_77"},{"__ref":"Paragraph:b6b44fd7044e_78"},{"__ref":"Paragraph:b6b44fd7044e_79"},{"__ref":"Paragraph:b6b44fd7044e_80"},{"__ref":"Paragraph:b6b44fd7044e_81"},{"__ref":"Paragraph:b6b44fd7044e_82"},{"__ref":"Paragraph:b6b44fd7044e_83"},{"__ref":"Paragraph:b6b44fd7044e_84"},{"__ref":"Paragraph:b6b44fd7044e_85"},{"__ref":"Paragraph:b6b44fd7044e_86"},{"__ref":"Paragraph:b6b44fd7044e_87"},{"__ref":"Paragraph:b6b44fd7044e_88"},{"__ref":"Paragraph:b6b44fd7044e_89"},{"__ref":"Paragraph:b6b44fd7044e_90"},{"__ref":"Paragraph:b6b44fd7044e_91"},{"__ref":"Paragraph:b6b44fd7044e_92"},{"__ref":"Paragraph:b6b44fd7044e_93"},{"__ref":"Paragraph:b6b44fd7044e_94"},{"__ref":"Paragraph:b6b44fd7044e_95"},{"__ref":"Paragraph:b6b44fd7044e_96"},{"__ref":"Paragraph:b6b44fd7044e_97"},{"__ref":"Paragraph:b6b44fd7044e_98"},{"__ref":"Paragraph:b6b44fd7044e_99"},{"__ref":"Paragraph:b6b44fd7044e_100"},{"__ref":"Paragraph:b6b44fd7044e_101"},{"__ref":"Paragraph:b6b44fd7044e_102"},{"__ref":"Paragraph:b6b44fd7044e_103"},{"__ref":"Paragraph:b6b44fd7044e_104"},{"__ref":"Paragraph:b6b44fd7044e_105"},{"__ref":"Paragraph:b6b44fd7044e_106"},{"__ref":"Paragraph:b6b44fd7044e_107"},{"__ref":"Paragraph:b6b44fd7044e_108"},{"__ref":"Paragraph:b6b44fd7044e_109"},{"__ref":"Paragraph:b6b44fd7044e_110"},{"__ref":"Paragraph:b6b44fd7044e_111"},{"__ref":"Paragraph:b6b44fd7044e_112"},{"__ref":"Paragraph:b6b44fd7044e_113"},{"__ref":"Paragraph:b6b44fd7044e_114"},{"__ref":"Paragraph:b6b44fd7044e_115"},{"__ref":"Paragraph:b6b44fd7044e_116"},{"__ref":"Paragraph:b6b44fd7044e_117"},{"__ref":"Paragraph:b6b44fd7044e_118"},{"__ref":"Paragraph:b6b44fd7044e_119"},{"__ref":"Paragraph:b6b44fd7044e_120"},{"__ref":"Paragraph:b6b44fd7044e_121"},{"__ref":"Paragraph:b6b44fd7044e_122"},{"__ref":"Paragraph:b6b44fd7044e_123"},{"__ref":"Paragraph:b6b44fd7044e_124"},{"__ref":"Paragraph:b6b44fd7044e_125"},{"__ref":"Paragraph:b6b44fd7044e_126"},{"__ref":"Paragraph:b6b44fd7044e_127"},{"__ref":"Paragraph:b6b44fd7044e_128"},{"__ref":"Paragraph:b6b44fd7044e_129"},{"__ref":"Paragraph:b6b44fd7044e_130"},{"__ref":"Paragraph:b6b44fd7044e_131"},{"__ref":"Paragraph:b6b44fd7044e_132"},{"__ref":"Paragraph:b6b44fd7044e_133"},{"__ref":"Paragraph:b6b44fd7044e_134"},{"__ref":"Paragraph:b6b44fd7044e_135"},{"__ref":"Paragraph:b6b44fd7044e_136"},{"__ref":"Paragraph:b6b44fd7044e_137"},{"__ref":"Paragraph:b6b44fd7044e_138"},{"__ref":"Paragraph:b6b44fd7044e_139"},{"__ref":"Paragraph:b6b44fd7044e_140"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:685a4c0e34a2"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","primaryTopic":null,"topics":[],"isLimitedState":false,"isPublished":true,"allowResponses":true,"responsesLocked":false,"visibility":"PUBLIC","latestPublishedVersion":"b6b44fd7044e","postResponses":{"__typename":"PostResponses","count":2},"responseDistribution":"NOT_DISTRIBUTED","clapCount":179,"title":"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶","isSeries":false,"sequence":null,"uniqueSlug":"building-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","socialTitle":"","socialDek":"","canonicalUrl":"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb","metaDescription":"","latestPublishedAt":1760345007083,"readingTime":20.983962264150943,"previewContent":{"__typename":"PreviewContent","subtitle":"How a 7 million parameter model outperforms 671 billion parameter models on reasoning tasks and why this changes everything"},"previewImage":{"__ref":"ImageMetadata:1*RE5SGAeCzfzpA7dl_PUBpQ.png"},"isShortform":false,"seoMetaTags":{"__typename":"SEOMetaTags","jsonLd":"{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb\",\"@type\":\"SocialMediaPosting\",\"image\":[\"https:\u002F\u002Fmiro.medium.com\u002F\"],\"url\":\"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb\",\"dateCreated\":\"2025-10-12T02:16:50Z\",\"datePublished\":\"2025-10-12T02:16:50Z\",\"dateModified\":\"2025-10-13T08:43:27Z\",\"headline\":\"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶\",\"name\":\"Let‚Äôs Build a Tiny Recursive Model from Scratch with Complete Code: When Tiny Networks Beat Giants‚Ä¶\",\"description\":\"‚Äú‚Äù is published by azhar.\",\"identifier\":\"68d9df9e1fdb\",\"author\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmedium.com\u002F@moazharu\",\"@type\":\"Person\",\"identifier\":\"moazharu\",\"name\":\"azhar\",\"url\":\"https:\u002F\u002Fmedium.com\u002F@moazharu\"},\"creator\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@id\":\"https:\u002F\u002Fmedium.com\u002F@moazharu\",\"@type\":\"Person\",\"identifier\":\"moazharu\",\"name\":\"azhar\",\"url\":\"https:\u002F\u002Fmedium.com\u002F@moazharu\"},\"publisher\":{\"@context\":\"https:\u002F\u002Fschema.org\",\"@type\":\"Organization\",\"@id\":\"https:\u002F\u002Fmedium.com\",\"name\":\"Medium\",\"url\":\"https:\u002F\u002Fmedium.com\",\"logo\":{\"@type\":\"ImageObject\",\"width\":500,\"height\":110,\"url\":\"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:500\u002F7%2AV1_7XP4snlmqrc_0Njontw.png\"}},\"mainEntityOfPage\":\"https:\u002F\u002Fmoazharu.medium.com\u002Fbuilding-tiny-recursive-model-from-scratch-when-tiny-networks-beat-giants-at-their-own-game-68d9df9e1fdb\",\"isAccessibleForFree\":true}"},"seoDescription":"‚Äú‚Äù is published by azhar.","shortformType":"SHORTFORM_TYPE_LINK","firstPublishedAt":1760235410007,"viewerEdge":{"__ref":"PostViewerEdge:postId:68d9df9e1fdb-viewerId:lo_851a71d889ff"},"seoTitle":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:trm"},{"__ref":"Tag:tiny-recursive-model"},{"__ref":"Tag:hrm"},{"__ref":"Tag:hierarchical-reasoning"},{"__ref":"Tag:multihead-attention"}],"isFeaturedInPublishedPublication":false,"isNewsletter":false,"statusForCollection":null,"pendingCollection":null,"detectedLanguage":"en","wordCount":5415}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.0e592952.js"></script><script src="https://cdn-client.medium.com/lite/static/js/5565.7806c3bb.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.f8d3c2c3.js"></script><script id="__LOADABLE_REQUIRED_CHUNKS__" type="application/json">[6183,2951,5052,628,6062,7566,3777,7908,3927,8640,9967,6372,3862,5429,5376,7381,9347,4929,6834,8441,7979,3877,7975,9256,8768,6509,4269,3666,1069,6026,7695,5304,2698,3974,2527,2886,5258]</script>
<script id="__LOADABLE_REQUIRED_CHUNKS___ext" type="application/json">{"namedChunks":["instrumentation","reporting","PostPage.MainContent","PostResponsesContent","responses.editor"]}</script>
<script async="" data-chunk="instrumentation" src="https://cdn-client.medium.com/lite/static/js/instrumentation.434115b9.chunk.js"></script>
<script async="" data-chunk="reporting" src="https://cdn-client.medium.com/lite/static/js/reporting.851fdaca.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/5052.eb638269.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/628.add32a62.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/6062.c3638afc.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7566.14491814.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/3777.af05bea9.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7908.9ea3c3f3.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/3927.2f9f3eed.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/8640.9dfdf08f.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/9967.08537ce5.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/6372.c6e20496.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/3862.a0fe9068.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/5429.931b7269.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/5376.2aa21ddf.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7381.c53435ab.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/9347.a42e3f87.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/4929.2ccdd557.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/6834.6c66e3cc.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/8441.773bce63.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7979.35c5b2af.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/3877.769556c7.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7975.3f8d607c.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/9256.c0f021df.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/8768.9996ec30.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/6509.703cf733.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/4269.6f94ed97.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/3666.122df09d.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/1069.bbe95674.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/6026.904e1f2d.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/7695.47976815.chunk.js"></script>
<script async="" data-chunk="PostPage.MainContent" src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.e250449e.chunk.js"></script>
<script async="" data-chunk="PostResponsesContent" src="https://cdn-client.medium.com/lite/static/js/2698.9eecb474.chunk.js"></script>
<script async="" data-chunk="PostResponsesContent" src="https://cdn-client.medium.com/lite/static/js/3974.82493a33.chunk.js"></script>
<script async="" data-chunk="PostResponsesContent" src="https://cdn-client.medium.com/lite/static/js/2527.ed913434.chunk.js"></script>
<script async="" data-chunk="PostResponsesContent" src="https://cdn-client.medium.com/lite/static/js/PostResponsesContent.e940a3b4.chunk.js"></script>
<script async="" data-chunk="responses.editor" src="https://cdn-client.medium.com/lite/static/js/responses.editor.d61aa7c4.chunk.js"></script><script>window.main();</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'9a1265006b3adcf4',t:'MTc2MzU4MzQ4Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>