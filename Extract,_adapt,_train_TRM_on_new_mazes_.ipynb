{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/qzCgDYtvlTMji78CZXwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/Extract%2C_adapt%2C_train_TRM_on_new_mazes_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpx7wSzP8ZDq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4db92dfc"
      },
      "source": [
        "# Task\n",
        "Extract, clean, and adapt the Transformer-based Reinforcement Learning for Maze-solving (TRM) code from the provided notebook `/content/TRM_Demonstration_30_5x5_mazes3 (1).ipynb` to train it on 100 newly prepared mazes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bede88f0"
      },
      "source": [
        "## Read Notebook Content\n",
        "\n",
        "### Subtask:\n",
        "Read the content of the provided Jupyter notebook file '/content/TRM_Demonstration_30_5x5_mazes3 (1).ipynb' to understand its structure and existing TRM code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868a2ae3"
      },
      "source": [
        "**Reasoning**:\n",
        "To read the content of the Jupyter notebook, I will open the file in read mode and print the first 500 characters to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34fc7348",
        "outputId": "78f7bcd0-0281-47ce-c5ea-5e1e417feb80"
      },
      "source": [
        "with open('/content/TRM_Demonstration_30_5x5_mazes3 (1).ipynb', 'r') as f:\n",
        "    notebook_content = f.read()\n",
        "\n",
        "print(notebook_content[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"nbformat\": 4,\n",
            "  \"nbformat_minor\": 5,\n",
            "  \"metadata\": {\n",
            "    \"kernelspec\": {\n",
            "      \"display_name\": \"Python 3\",\n",
            "      \"language\": \"python\",\n",
            "      \"name\": \"python3\"\n",
            "    },\n",
            "    \"language_info\": {\n",
            "      \"codemirror_mode\": {\n",
            "        \"name\": \"ipython\",\n",
            "        \"version\": 3\n",
            "      },\n",
            "      \"file_extension\": \".py\",\n",
            "      \"mimetype\": \"text/x-python\",\n",
            "      \"name\": \"python\",\n",
            "      \"nbconvert_exporter\": \"python\",\n",
            "      \"pygments_lexer\": \"ipython3\",\n",
            "      \"version\": \"3.10.6\"\n",
            "    },\n",
            "    \"colab\": {\n",
            "      \"pro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdbe2ed7"
      },
      "source": [
        "**Reasoning**:\n",
        "The notebook content has been read as a string. To understand its structure and extract the TRM code, I need to parse the JSON string into a Python dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0834bde8",
        "outputId": "6562cc13-0515-4c29-93f1-cb1cd8cee5cf"
      },
      "source": [
        "import json\n",
        "\n",
        "notebook_data = json.loads(notebook_content)\n",
        "\n",
        "print(f\"Notebook has {len(notebook_data['cells'])} cells.\")\n",
        "# Display the type of the first few cells to get an idea of the structure\n",
        "for i, cell in enumerate(notebook_data['cells'][:5]):\n",
        "    print(f\"Cell {i}: Type = {cell['cell_type']}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook has 30 cells.\n",
            "Cell 0: Type = markdown\n",
            "Cell 1: Type = markdown\n",
            "Cell 2: Type = code\n",
            "Cell 3: Type = markdown\n",
            "Cell 4: Type = code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bb9c954"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the notebook content is parsed into a Python dictionary, I will iterate through the cells to identify and print the content of the first few code cells. This will help in locating the TRM model definition and related code for extraction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbd7b918",
        "outputId": "91a09bce-c859-4c38-ffe4-c7bde78af1ea"
      },
      "source": [
        "trm_code_cells = []\n",
        "print(\"Content of the first 5 code cells:\")\n",
        "for i, cell in enumerate(notebook_data['cells']):\n",
        "    if cell['cell_type'] == 'code':\n",
        "        trm_code_cells.append(cell)\n",
        "        if len(trm_code_cells) <= 5:\n",
        "            print(f\"\\n--- Code Cell {i} ---\")\n",
        "            print(''.join(cell['source']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of the first 5 code cells:\n",
            "\n",
            "--- Code Cell 2 ---\n",
            "!pip install -q torch\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# Set the device to a GPU if available, otherwise use the CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "\n",
            "--- Code Cell 4 ---\n",
            "class RecursiveBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    A single recursive block for the TRM.\n",
            "    \"\"\"\n",
            "    def __init__(self, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.norm_state = nn.LayerNorm(d_model)\n",
            "        self.norm_input = nn.LayerNorm(d_model)\n",
            "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "        self.activation = nn.GELU()\n",
            "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "\n",
            "    def forward(self, x, state):\n",
            "        \"\"\"\n",
            "        Forward pass for the recursive block.\n",
            "        Args:\n",
            "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
            "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
            "        Returns:\n",
            "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
            "        \"\"\"\n",
            "        normalized_state = self.norm_state(state)\n",
            "        normalized_input = self.norm_input(x)\n",
            "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
            "        hidden = self.linear1(combined_input)\n",
            "        hidden = self.activation(hidden)\n",
            "        processed_output = self.linear2(hidden)\n",
            "        new_state = state + processed_output[:, :self.d_model]\n",
            "        output = processed_output[:, self.d_model:]\n",
            "        return output, new_state\n",
            "\n",
            "\n",
            "--- Code Cell 6 ---\n",
            "class TRM(nn.Module):\n",
            "    \"\"\"\n",
            "    The Tiny Recursive Model.\n",
            "    \"\"\"\n",
            "    def __init__(self, vocab_size, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
            "        self.recursive_block = RecursiveBlock(d_model)\n",
            "        self.norm_out = nn.LayerNorm(d_model)\n",
            "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
            "\n",
            "    def forward(self, input_sequence):\n",
            "        \"\"\"\n",
            "        Forward pass for the entire sequence.\n",
            "        Args:\n",
            "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
            "        Returns:\n",
            "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
            "        \"\"\"\n",
            "        batch_size, seq_len = input_sequence.shape\n",
            "        embedded_input = self.embedding(input_sequence)\n",
            "\n",
            "        # Initialize the hidden state on the same device as the input\n",
            "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
            "\n",
            "        outputs = []\n",
            "        for i in range(seq_len):\n",
            "            step_input = embedded_input[:, i, :]\n",
            "            output, state = self.recursive_block(step_input, state)\n",
            "            outputs.append(output)\n",
            "\n",
            "        outputs_tensor = torch.stack(outputs, dim=1)\n",
            "        normalized_outputs = self.norm_out(outputs_tensor)\n",
            "        logits = self.output_linear(normalized_outputs)\n",
            "\n",
            "        return logits\n",
            "\n",
            "\n",
            "--- Code Cell 8 ---\n",
            "VOCAB_SIZE = 20\n",
            "D_MODEL = 32\n",
            "SEQ_LEN = 5\n",
            "BATCH_SIZE = 1\n",
            "\n",
            "# Instantiate the model and move it to the configured device\n",
            "model = TRM(vocab_size=VOCAB_SIZE, d_model=D_MODEL).to(device)\n",
            "print(\"Model Architecture:\")\n",
            "print(model)\n",
            "\n",
            "# Create a dummy input sequence and move it to the device\n",
            "dummy_input = torch.randint(0, VOCAB_SIZE, (BATCH_SIZE, SEQ_LEN)).to(device)\n",
            "print(f\"\\nDummy Input Shape: {dummy_input.shape}\")\n",
            "print(f\"Dummy Input Tensor:\\n{dummy_input}\")\n",
            "\n",
            "# Perform a forward pass\n",
            "output_logits = model(dummy_input)\n",
            "\n",
            "print(f\"\\nOutput Logits Shape: {output_logits.shape}\")\n",
            "print(\"This shape (batch_size, seq_len, vocab_size) is what we expect!\")\n",
            "\n",
            "\n",
            "--- Code Cell 10 ---\n",
            "TRAINING_VOCAB_SIZE = 10\n",
            "TRAINING_D_MODEL = 16\n",
            "\n",
            "# Create a new model instance for training and move to device\n",
            "training_model = TRM(vocab_size=TRAINING_VOCAB_SIZE, d_model=TRAINING_D_MODEL).to(device)\n",
            "optimizer = optim.Adam(training_model.parameters(), lr=0.01)\n",
            "criterion = nn.CrossEntropyLoss()\n",
            "\n",
            "# Data - move to device\n",
            "input_data = torch.tensor([[1, 2, 3, 4]]).to(device)\n",
            "target_data = torch.tensor([[2, 3, 4, 5]]).to(device)\n",
            "\n",
            "print(f\"Input:  {input_data[0].tolist()}\")\n",
            "print(f\"Target: {target_data[0].tolist()}\")\n",
            "\n",
            "# Training Loop\n",
            "epochs = 100\n",
            "for epoch in range(epochs):\n",
            "    optimizer.zero_grad()\n",
            "    logits = training_model(input_data)\n",
            "    loss = criterion(logits.view(-1, TRAINING_VOCAB_SIZE), target_data.view(-1))\n",
            "    loss.backward()\n",
            "    optimizer.step()\n",
            "\n",
            "    if (epoch + 1) % 10 == 0:\n",
            "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
            "\n",
            "# Inference after training\n",
            "print(\"\\n--- Testing after training ---\")\n",
            "with torch.no_grad():\n",
            "    predictions = training_model(input_data)\n",
            "    predicted_ids = torch.argmax(predictions, dim=2)\n",
            "\n",
            "    print(f\"Input:              {input_data[0].tolist()}\")\n",
            "    print(f\"Predicted sequence: {predicted_ids[0].tolist()}\")\n",
            "    print(f\"Target sequence:    {target_data[0].tolist()}\")\n",
            "    print(\"\\nThe model has learned to predict the next number!\")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "203cbc28"
      },
      "source": [
        "**Reasoning**:\n",
        "I have already displayed the first 5 code cells. To comprehensively understand and extract the TRM code, I will now gather the complete source code for the `RecursiveBlock` and `TRM` classes, and any relevant constants or initialization code, from all identified code cells. This will allow for full extraction and later adaptation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3dea656",
        "outputId": "cc3f5609-e46d-45dd-8911-cdbaf2d73b07"
      },
      "source": [
        "trm_architecture_code = []\n",
        "for cell in notebook_data['cells']:\n",
        "    if cell['cell_type'] == 'code':\n",
        "        source_code = ''.join(cell['source'])\n",
        "        # Identify and extract core TRM architecture and related setup\n",
        "        if \"class RecursiveBlock\" in source_code or \\\n",
        "           \"class TRM\" in source_code or \\\n",
        "           \"import torch\" in source_code or \\\n",
        "           \"device = torch.device\" in source_code:\n",
        "            trm_architecture_code.append(source_code)\n",
        "\n",
        "print(\"--- Extracted TRM Architecture Code ---\")\n",
        "print('\\n'.join(trm_architecture_code[:500])) # Print a portion to verify extraction\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Extracted TRM Architecture Code ---\n",
            "!pip install -q torch\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# Set the device to a GPU if available, otherwise use the CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "class RecursiveBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    A single recursive block for the TRM.\n",
            "    \"\"\"\n",
            "    def __init__(self, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.norm_state = nn.LayerNorm(d_model)\n",
            "        self.norm_input = nn.LayerNorm(d_model)\n",
            "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "        self.activation = nn.GELU()\n",
            "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "\n",
            "    def forward(self, x, state):\n",
            "        \"\"\"\n",
            "        Forward pass for the recursive block.\n",
            "        Args:\n",
            "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
            "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
            "        Returns:\n",
            "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
            "        \"\"\"\n",
            "        normalized_state = self.norm_state(state)\n",
            "        normalized_input = self.norm_input(x)\n",
            "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
            "        hidden = self.linear1(combined_input)\n",
            "        hidden = self.activation(hidden)\n",
            "        processed_output = self.linear2(hidden)\n",
            "        new_state = state + processed_output[:, :self.d_model]\n",
            "        output = processed_output[:, self.d_model:]\n",
            "        return output, new_state\n",
            "\n",
            "class TRM(nn.Module):\n",
            "    \"\"\"\n",
            "    The Tiny Recursive Model.\n",
            "    \"\"\"\n",
            "    def __init__(self, vocab_size, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
            "        self.recursive_block = RecursiveBlock(d_model)\n",
            "        self.norm_out = nn.LayerNorm(d_model)\n",
            "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
            "\n",
            "    def forward(self, input_sequence):\n",
            "        \"\"\"\n",
            "        Forward pass for the entire sequence.\n",
            "        Args:\n",
            "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
            "        Returns:\n",
            "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
            "        \"\"\"\n",
            "        batch_size, seq_len = input_sequence.shape\n",
            "        embedded_input = self.embedding(input_sequence)\n",
            "\n",
            "        # Initialize the hidden state on the same device as the input\n",
            "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
            "\n",
            "        outputs = []\n",
            "        for i in range(seq_len):\n",
            "            step_input = embedded_input[:, i, :]\n",
            "            output, state = self.recursive_block(step_input, state)\n",
            "            outputs.append(output)\n",
            "\n",
            "        outputs_tensor = torch.stack(outputs, dim=1)\n",
            "        normalized_outputs = self.norm_out(outputs_tensor)\n",
            "        logits = self.output_linear(normalized_outputs)\n",
            "\n",
            "        return logits\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# --- Maze Data Setup ---\n",
            "\n",
            "# 0: Wall, 1: Path, 2: Start, 3: End\n",
            "MAZE_DATASET = [\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [0, 0, 1, 1, 0], [1, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 1, 0, 0], [1, 1, 1, 1, 1], [1, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (0, 4), (0, 3), (0, 2), (1, 2), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[1, 2, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 2], [1, 1, 0, 1, 3]], \"path\": [(3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 0, 1, 1], [0, 1, 1, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 0], [1, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [2, 2], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [2, 2], [2, 3], [2, 4], [1, 4], [0, 4], [0, 3], [0, 2], [1, 2], [2, 2], [2, 1], [2, 0], [3, 0], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [3, 2], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [3, 2], [4, 2], (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 0], [1, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [2, 2], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [4, 1], [4, 2], [4, 3], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [1, 3], [1, 4], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [4, 1], [4, 2], [4, 3], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], (4, 4)]}\n",
            "  ]\n",
            "\n",
            "UNSEEN_MAZE = {\n",
            "    \"maze\": [\n",
            "        [2, 1, 1, 1, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1],\n",
            "        [1, 1, 1, 0, 3]\n",
            "    ],\n",
            "    \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
            "}\n",
            "\n",
            "# --- Vocabulary and Preprocessing ---\n",
            "WALL, PATH, START, END, SEP = 0, 1, 2, 3, 4\n",
            "PATH_TOKEN_OFFSET = 5\n",
            "MAZE_SIZE = 5\n",
            "MAZE_TOKENS = MAZE_SIZE * MAZE_SIZE\n",
            "\n",
            "def preprocess_maze_data(dataset):\n",
            "    sequences = []\n",
            "    for item in dataset:\n",
            "        maze_flat = [token for row in item[\"maze\"] for token in row]\n",
            "        path_tokens = [PATH_TOKEN_OFFSET + r * MAZE_SIZE + c for r, c in item[\"path\"]]\n",
            "        full_sequence = maze_flat + [SEP] + path_tokens\n",
            "        sequences.append(torch.tensor(full_sequence))\n",
            "    return sequences\n",
            "\n",
            "training_sequences = preprocess_maze_data(MAZE_DATASET)\n",
            "\n",
            "print(f\"Loaded {len(training_sequences)} training mazes.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ab13a3"
      },
      "source": [
        "**Reasoning**:\n",
        "To have the complete TRM architecture and associated setup code in a single executable block for easy transfer and use, I will join the extracted code snippets from `trm_architecture_code` into one string. This final concatenated string represents the full TRM model definition and initial configuration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c757a889",
        "outputId": "eec48922-6032-4a86-908b-f3134b2c000b"
      },
      "source": [
        "full_trm_code = \"\\n\".join(trm_architecture_code)\n",
        "\n",
        "print(\"--- Complete TRM Architecture Code Extracted ---\")\n",
        "print(full_trm_code)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Complete TRM Architecture Code Extracted ---\n",
            "!pip install -q torch\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# Set the device to a GPU if available, otherwise use the CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "class RecursiveBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    A single recursive block for the TRM.\n",
            "    \"\"\"\n",
            "    def __init__(self, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.norm_state = nn.LayerNorm(d_model)\n",
            "        self.norm_input = nn.LayerNorm(d_model)\n",
            "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "        self.activation = nn.GELU()\n",
            "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "\n",
            "    def forward(self, x, state):\n",
            "        \"\"\"\n",
            "        Forward pass for the recursive block.\n",
            "        Args:\n",
            "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
            "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
            "        Returns:\n",
            "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
            "        \"\"\"\n",
            "        normalized_state = self.norm_state(state)\n",
            "        normalized_input = self.norm_input(x)\n",
            "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
            "        hidden = self.linear1(combined_input)\n",
            "        hidden = self.activation(hidden)\n",
            "        processed_output = self.linear2(hidden)\n",
            "        new_state = state + processed_output[:, :self.d_model]\n",
            "        output = processed_output[:, self.d_model:]\n",
            "        return output, new_state\n",
            "\n",
            "class TRM(nn.Module):\n",
            "    \"\"\"\n",
            "    The Tiny Recursive Model.\n",
            "    \"\"\"\n",
            "    def __init__(self, vocab_size, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
            "        self.recursive_block = RecursiveBlock(d_model)\n",
            "        self.norm_out = nn.LayerNorm(d_model)\n",
            "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
            "\n",
            "    def forward(self, input_sequence):\n",
            "        \"\"\"\n",
            "        Forward pass for the entire sequence.\n",
            "        Args:\n",
            "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
            "        Returns:\n",
            "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
            "        \"\"\"\n",
            "        batch_size, seq_len = input_sequence.shape\n",
            "        embedded_input = self.embedding(input_sequence)\n",
            "\n",
            "        # Initialize the hidden state on the same device as the input\n",
            "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
            "\n",
            "        outputs = []\n",
            "        for i in range(seq_len):\n",
            "            step_input = embedded_input[:, i, :]\n",
            "            output, state = self.recursive_block(step_input, state)\n",
            "            outputs.append(output)\n",
            "\n",
            "        outputs_tensor = torch.stack(outputs, dim=1)\n",
            "        normalized_outputs = self.norm_out(outputs_tensor)\n",
            "        logits = self.output_linear(normalized_outputs)\n",
            "\n",
            "        return logits\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# --- Maze Data Setup ---\n",
            "\n",
            "# 0: Wall, 1: Path, 2: Start, 3: End\n",
            "MAZE_DATASET = [\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [0, 0, 1, 1, 0], [1, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 1, 0, 0], [1, 1, 1, 1, 1], [1, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 1, 1, 1, 0], [0, 1, 0, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (2, 3), (2, 4), (1, 4), (0, 4), (0, 3), (0, 2), (1, 2), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (1, 1), (2, 1), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[1, 2, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 2], [1, 1, 0, 1, 3]], \"path\": [(3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 0, 1, 1], [0, 1, 1, 0, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 0], [1, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (2, 2), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (0, 1), (0, 2), (1, 2), (1, 3), (1, 4), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (2, 3), (3, 3), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [(0, 0), (0, 1), (1, 1), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (4, 2), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [(0, 0), (1, 0), (2, 0), (2, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [2, 2], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [2, 2], [2, 3], [2, 4], [1, 4], [0, 4], [0, 3], [0, 2], [1, 2], [2, 2], [2, 1], [2, 0], [3, 0], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [0, 1, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [3, 2], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [1, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 0, 1, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [3, 4], [4, 4]]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [4, 1], [4, 2], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [4, 4]]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [2, 1], [2, 2], [3, 2], [4, 2], (4, 3), (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 0, 1, 1], [1, 1, 1, 1, 0], [1, 0, 1, 0, 1], [1, 1, 1, 1, 1], [0, 1, 0, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 0], [1, 0, 1, 1, 0], [1, 1, 1, 1, 1], [0, 0, 1, 0, 1], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [2, 2], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 1, 1], [1, 1, 0, 1, 0], [1, 1, 1, 1, 1], [0, 1, 0, 1, 0], [1, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [4, 1], [4, 2], [4, 3], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 1], [1, 1, 0, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [0, 1], [0, 2], [1, 2], [1, 3], [1, 4], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 0, 1, 1], [1, 1, 1, 1, 0], [0, 1, 0, 1, 1], [1, 1, 1, 0, 1], [0, 0, 1, 1, 3]], \"path\": [[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [3, 4], (4, 4)]},\n",
            "    {\"maze\": [[2, 0, 1, 0, 1], [1, 1, 1, 1, 1], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0], [0, 1, 1, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [3, 0], [3, 1], [4, 1], [4, 2], [4, 3], (4, 4)]},\n",
            "    {\"maze\": [[2, 1, 1, 0, 1], [1, 0, 1, 1, 0], [1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 0, 0, 1, 3]], \"path\": [[0, 0], [1, 0], [2, 0], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], (4, 4)]}\n",
            "  ]\n",
            "\n",
            "UNSEEN_MAZE = {\n",
            "    \"maze\": [\n",
            "        [2, 1, 1, 1, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1],\n",
            "        [1, 1, 1, 0, 3]\n",
            "    ],\n",
            "    \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
            "}\n",
            "\n",
            "# --- Vocabulary and Preprocessing ---\n",
            "WALL, PATH, START, END, SEP = 0, 1, 2, 3, 4\n",
            "PATH_TOKEN_OFFSET = 5\n",
            "MAZE_SIZE = 5\n",
            "MAZE_TOKENS = MAZE_SIZE * MAZE_SIZE\n",
            "\n",
            "def preprocess_maze_data(dataset):\n",
            "    sequences = []\n",
            "    for item in dataset:\n",
            "        maze_flat = [token for row in item[\"maze\"] for token in row]\n",
            "        path_tokens = [PATH_TOKEN_OFFSET + r * MAZE_SIZE + c for r, c in item[\"path\"]]\n",
            "        full_sequence = maze_flat + [SEP] + path_tokens\n",
            "        sequences.append(torch.tensor(full_sequence))\n",
            "    return sequences\n",
            "\n",
            "training_sequences = preprocess_maze_data(MAZE_DATASET)\n",
            "\n",
            "print(f\"Loaded {len(training_sequences)} training mazes.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d54a69b0"
      },
      "source": [
        "## Analyze and Extract TRM Code\n",
        "\n",
        "### Subtask:\n",
        "Analyze the extracted TRM code string (`full_trm_code`) for redundancies and prepare it for execution and subsequent adaptation. This includes removing shell commands, duplicate imports, and isolating the core model definition from the specific maze data and training logic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5af42e65"
      },
      "source": [
        "**Reasoning**:\n",
        "To analyze and adapt the extracted TRM code, I need to clean it first. This involves removing non-Python shell commands like `!pip install`, eliminating duplicate import statements to avoid redundancy, and separating the core model definitions from specific maze data and example training logic. After cleaning, executing this code will make the `RecursiveBlock` and `TRM` classes and other essential components available for further steps in the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2563b41a",
        "outputId": "84636197-4fb0-4542-dd65-5d15212f1f24"
      },
      "source": [
        "cleaned_trm_code_lines = []\n",
        "seen_imports = set()\n",
        "skip_section = False\n",
        "\n",
        "# Split the code into lines for easier processing\n",
        "code_lines = full_trm_code.split('\\n')\n",
        "\n",
        "for line in code_lines:\n",
        "    # 1. Remove the !pip install command\n",
        "    if line.strip().startswith('!pip install'):\n",
        "        continue\n",
        "\n",
        "    # Identify start and end of training code and maze data sections to skip\n",
        "    if 'TRAINING_VOCAB_SIZE' in line or '# --- Maze Data Setup ---' in line:\n",
        "        skip_section = True\n",
        "\n",
        "    # Skip specific examples or data definitions\n",
        "    if skip_section and (\n",
        "        'MAZE_DATASET' in line or\n",
        "        'UNSEEN_MAZE' in line or\n",
        "        'WALL, PATH, START, END, SEP' in line or\n",
        "        'PATH_TOKEN_OFFSET' in line or\n",
        "        'MAZE_SIZE' in line or\n",
        "        'MAZE_TOKENS' in line or\n",
        "        'def preprocess_maze_data' in line or\n",
        "        'training_sequences' in line or\n",
        "        'print(f\"Loaded {len(training_sequences)} training mazes.\")' in line or\n",
        "        '# Instantiate the model and move it to the configured device' in line or # Example model instantiation\n",
        "        '# Create a dummy input sequence' in line or # Example dummy input\n",
        "        '# Perform a forward pass' in line or # Example forward pass\n",
        "        'print(\"Model Architecture:\")' in line or # Example print\n",
        "        'epochs = 100' in line or # Example training loop\n",
        "        '# Inference after training' in line or\n",
        "        '# Set the device to a GPU if available, otherwise use the CPU' in line # This line is good, but the following print is part of training examples, I will re-add device print later\n",
        "    ):\n",
        "        # Keep skipping until the end of the data/example training logic\n",
        "        # The complex logic in MAZE_DATASET means we need to skip line by line until a logical break.\n",
        "        # This is a bit of a heuristic. Let's make sure we only skip actual data/training lines.\n",
        "        if 'MAZE_DATASET = [' in line:\n",
        "             # Find the end of the MAZE_DATASET list\n",
        "            maze_dataset_start_idx = code_lines.index(line)\n",
        "            maze_dataset_end_idx = maze_dataset_start_idx\n",
        "            open_brackets = 0\n",
        "            for i in range(maze_dataset_start_idx, len(code_lines)):\n",
        "                open_brackets += code_lines[i].count('[')\n",
        "                open_brackets -= code_lines[i].count(']')\n",
        "                if open_brackets == 0 and ']' in code_lines[i]:\n",
        "                    maze_dataset_end_idx = i\n",
        "                    break\n",
        "            # Mark lines in MAZE_DATASET range to be skipped\n",
        "            for i in range(maze_dataset_start_idx, maze_dataset_end_idx + 1):\n",
        "                if code_lines[i] not in cleaned_trm_code_lines: # Ensure not to re-mark if already skipped\n",
        "                    code_lines[i] = '#SKIPPED_DATA_LINE#' # Temporarily mark to skip\n",
        "            skip_section = False # Reset after processing MAZE_DATASET\n",
        "\n",
        "        if 'UNSEEN_MAZE = {' in line:\n",
        "            unseen_maze_start_idx = code_lines.index(line)\n",
        "            unseen_maze_end_idx = unseen_maze_start_idx\n",
        "            open_braces = 0\n",
        "            for i in range(unseen_maze_start_idx, len(code_lines)):\n",
        "                open_braces += code_lines[i].count('{')\n",
        "                open_braces -= code_lines[i].count('}')\n",
        "                if open_braces == 0 and '}' in code_lines[i]:\n",
        "                    unseen_maze_end_idx = i\n",
        "                    break\n",
        "            for i in range(unseen_maze_start_idx, unseen_maze_end_idx + 1):\n",
        "                if code_lines[i] not in cleaned_trm_code_lines:\n",
        "                    code_lines[i] = '#SKIPPED_DATA_LINE#'\n",
        "            skip_section = False\n",
        "\n",
        "        # More robust skip for the initial training loop\n",
        "        if 'TRAINING_VOCAB_SIZE' in line:\n",
        "            # Find the end of this example training loop by looking for the next print statement or end of block\n",
        "            training_loop_start_idx = code_lines.index(line)\n",
        "            training_loop_end_idx = training_loop_start_idx\n",
        "            for i in range(training_loop_start_idx, len(code_lines)):\n",
        "                if 'print(\"\\n--- Testing after training ---\")' in code_lines[i] or 'print(\"The model has learned to predict the next number!\")' in code_lines[i]:\n",
        "                    training_loop_end_idx = i\n",
        "                    break\n",
        "            for i in range(training_loop_start_idx, training_loop_end_idx + 1):\n",
        "                if code_lines[i] not in cleaned_trm_code_lines:\n",
        "                    code_lines[i] = '#SKIPPED_DATA_LINE#'\n",
        "            skip_section = False # Reset after skipping this training block\n",
        "\n",
        "        continue # Skip current line if part of a section to be skipped\n",
        "\n",
        "    # If we are not skipping a section, process the line\n",
        "    if not skip_section:\n",
        "        # 2. Remove duplicate import statements\n",
        "        if line.strip().startswith('import') or line.strip().startswith('from'):\n",
        "            if line.strip() not in seen_imports:\n",
        "                cleaned_trm_code_lines.append(line)\n",
        "                seen_imports.add(line.strip())\n",
        "            continue\n",
        "\n",
        "        # Heuristic to stop skipping if an empty line or class definition follows\n",
        "        if not line.strip() and 'class' in code_lines[code_lines.index(line) + 1 if code_lines.index(line) + 1 < len(code_lines) else code_lines.index(line)].strip():\n",
        "            skip_section = False\n",
        "\n",
        "        # Only append lines that are not part of data/example training and not marked to be skipped\n",
        "        if '#SKIPPED_DATA_LINE#' not in line:\n",
        "            cleaned_trm_code_lines.append(line)\n",
        "\n",
        "# Join the cleaned lines back into a single string\n",
        "cleaned_trm_code = \"\\n\".join(cleaned_trm_code_lines)\n",
        "\n",
        "# Re-insert the device print statement as it's useful for setup\n",
        "if 'device = torch.device' in cleaned_trm_code and 'print(f\"Using device: {device}\")' not in cleaned_trm_code:\n",
        "    # Find the line where device is defined and insert print after it\n",
        "    device_line_idx = -1\n",
        "    for i, line in enumerate(cleaned_trm_code_lines):\n",
        "        if 'device = torch.device' in line:\n",
        "            device_line_idx = i\n",
        "            break\n",
        "    if device_line_idx != -1:\n",
        "        cleaned_trm_code_lines.insert(device_line_idx + 1, 'print(f\"Using device: {device}\")')\n",
        "        cleaned_trm_code = \"\\n\".join(cleaned_trm_code_lines)\n",
        "\n",
        "print(\"--- Cleaned TRM Code for Execution ---\")\n",
        "print(cleaned_trm_code)\n",
        "\n",
        "# 4. Execute the cleaned code\n",
        "exec(cleaned_trm_code)\n",
        "\n",
        "print(\"TRM classes and related setup defined successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cleaned TRM Code for Execution ---\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "\n",
            "# Set the device to a GPU if available, otherwise use the CPU\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "class RecursiveBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    A single recursive block for the TRM.\n",
            "    \"\"\"\n",
            "    def __init__(self, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.norm_state = nn.LayerNorm(d_model)\n",
            "        self.norm_input = nn.LayerNorm(d_model)\n",
            "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "        self.activation = nn.GELU()\n",
            "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "\n",
            "    def forward(self, x, state):\n",
            "        \"\"\"\n",
            "        Forward pass for the recursive block.\n",
            "        Args:\n",
            "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
            "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
            "        Returns:\n",
            "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
            "        \"\"\"\n",
            "        normalized_state = self.norm_state(state)\n",
            "        normalized_input = self.norm_input(x)\n",
            "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
            "        hidden = self.linear1(combined_input)\n",
            "        hidden = self.activation(hidden)\n",
            "        processed_output = self.linear2(hidden)\n",
            "        new_state = state + processed_output[:, :self.d_model]\n",
            "        output = processed_output[:, self.d_model:]\n",
            "        return output, new_state\n",
            "\n",
            "class TRM(nn.Module):\n",
            "    \"\"\"\n",
            "    The Tiny Recursive Model.\n",
            "    \"\"\"\n",
            "    def __init__(self, vocab_size, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
            "        self.recursive_block = RecursiveBlock(d_model)\n",
            "        self.norm_out = nn.LayerNorm(d_model)\n",
            "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
            "\n",
            "    def forward(self, input_sequence):\n",
            "        \"\"\"\n",
            "        Forward pass for the entire sequence.\n",
            "        Args:\n",
            "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
            "        Returns:\n",
            "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
            "        \"\"\"\n",
            "        batch_size, seq_len = input_sequence.shape\n",
            "        embedded_input = self.embedding(input_sequence)\n",
            "\n",
            "        # Initialize the hidden state on the same device as the input\n",
            "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
            "\n",
            "        outputs = []\n",
            "        for i in range(seq_len):\n",
            "            step_input = embedded_input[:, i, :]\n",
            "            output, state = self.recursive_block(step_input, state)\n",
            "            outputs.append(output)\n",
            "\n",
            "        outputs_tensor = torch.stack(outputs, dim=1)\n",
            "        normalized_outputs = self.norm_out(outputs_tensor)\n",
            "        logits = self.output_linear(normalized_outputs)\n",
            "\n",
            "        return logits\n",
            "\n",
            "\n",
            "\n",
            "UNSEEN_MAZE = {\n",
            "    \"maze\": [\n",
            "        [2, 1, 1, 1, 1],\n",
            "        [0, 1, 0, 0, 1],\n",
            "        [1, 1, 1, 0, 1],\n",
            "        [1, 0, 1, 1, 1],\n",
            "        [1, 1, 1, 0, 3]\n",
            "    ],\n",
            "    \"path\": [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n",
            "}\n",
            "\n",
            "# --- Vocabulary and Preprocessing ---\n",
            "WALL, PATH, START, END, SEP = 0, 1, 2, 3, 4\n",
            "PATH_TOKEN_OFFSET = 5\n",
            "MAZE_SIZE = 5\n",
            "MAZE_TOKENS = MAZE_SIZE * MAZE_SIZE\n",
            "\n",
            "def preprocess_maze_data(dataset):\n",
            "    sequences = []\n",
            "    for item in dataset:\n",
            "        maze_flat = [token for row in item[\"maze\"] for token in row]\n",
            "        path_tokens = [PATH_TOKEN_OFFSET + r * MAZE_SIZE + c for r, c in item[\"path\"]]\n",
            "        full_sequence = maze_flat + [SEP] + path_tokens\n",
            "        sequences.append(torch.tensor(full_sequence))\n",
            "    return sequences\n",
            "\n",
            "training_sequences = preprocess_maze_data(MAZE_DATASET)\n",
            "\n",
            "print(f\"Loaded {len(training_sequences)} training mazes.\")\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MAZE_DATASET' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3169014036.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# 4. Execute the cleaned code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_trm_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRM classes and related setup defined successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MAZE_DATASET' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39fc02de"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to clean the code resulted in a `NameError` because parts of the data and training setup were inconsistently removed, leaving a reference to `MAZE_DATASET` which was undefined. To fix this, I will refine the code cleaning logic to explicitly identify and include only the necessary imports, device setup, and the `RecursiveBlock` and `TRM` class definitions, completely excluding all data-specific definitions and example training code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f62348f",
        "outputId": "b3484e91-9cae-448d-b81d-67b9c675f6de"
      },
      "source": [
        "import_device_block_start = 0\n",
        "import_device_block_end = 0\n",
        "recursive_block_start = 0\n",
        "recursive_block_end = 0\n",
        "trm_class_start = 0\n",
        "trm_class_end = 0\n",
        "\n",
        "lines = full_trm_code.split('\\n')\n",
        "\n",
        "# Find relevant sections\n",
        "for i, line in enumerate(lines):\n",
        "    if \"import torch\" in line and import_device_block_start == 0:\n",
        "        import_device_block_start = i\n",
        "    if \"device = torch.device\" in line:\n",
        "        # This should capture the end of the initial imports/device setup block\n",
        "        # We can stop here, as any further imports will be handled by seen_imports\n",
        "        # and the relevant class definitions are picked up by specific start/end points.\n",
        "        import_device_block_end = i\n",
        "    if \"class RecursiveBlock\" in line:\n",
        "        recursive_block_start = i\n",
        "    # Heuristic to find the end of RecursiveBlock class\n",
        "    if recursive_block_start != 0 and recursive_block_end == 0 and \"return output, new_state\" in line:\n",
        "        recursive_block_end = i\n",
        "    if \"class TRM\" in line:\n",
        "        trm_class_start = i\n",
        "    # Heuristic to find the end of TRM class\n",
        "    if trm_class_start != 0 and trm_class_end == 0 and \"return logits\" in line:\n",
        "        trm_class_end = i\n",
        "\n",
        "cleaned_code_parts = []\n",
        "seen_imports = set()\n",
        "\n",
        "# Add imports and device from the initial block\n",
        "for i in range(import_device_block_start, import_device_block_end + 1):\n",
        "    line = lines[i]\n",
        "    stripped_line = line.strip()\n",
        "    if stripped_line.startswith('!pip install'):\n",
        "        continue\n",
        "    if (stripped_line.startswith('import') or stripped_line.startswith('from')):\n",
        "        if stripped_line not in seen_imports:\n",
        "            cleaned_code_parts.append(line)\n",
        "            seen_imports.add(stripped_line)\n",
        "    elif \"device = torch.device\" in line:\n",
        "        cleaned_code_parts.append(line)\n",
        "        # Ensure the device print statement is added right after device definition\n",
        "        cleaned_code_parts.append('print(f\"Using device: {device}\")')\n",
        "\n",
        "# Add RecursiveBlock class\n",
        "if recursive_block_start != 0 and recursive_block_end != 0:\n",
        "    # Add a newline for separation if necessary\n",
        "    if cleaned_code_parts and cleaned_code_parts[-1].strip() != '':\n",
        "        cleaned_code_parts.append('')\n",
        "    for i in range(recursive_block_start, recursive_block_end + 1):\n",
        "        cleaned_code_parts.append(lines[i])\n",
        "\n",
        "# Add TRM class\n",
        "if trm_class_start != 0 and trm_class_end != 0:\n",
        "    # Add a newline for separation if necessary\n",
        "    if cleaned_code_parts and cleaned_code_parts[-1].strip() != '':\n",
        "        cleaned_code_parts.append('')\n",
        "    for i in range(trm_class_start, trm_class_end + 1):\n",
        "        cleaned_code_parts.append(lines[i])\n",
        "\n",
        "final_cleaned_trm_code = \"\\n\".join(cleaned_code_parts)\n",
        "\n",
        "print(\"--- Cleaned TRM Code for Execution ---\")\n",
        "print(final_cleaned_trm_code)\n",
        "exec(final_cleaned_trm_code)\n",
        "print(\"TRM classes and related setup defined successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cleaned TRM Code for Execution ---\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.optim as optim\n",
            "import random\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")\n",
            "\n",
            "class RecursiveBlock(nn.Module):\n",
            "    \"\"\"\n",
            "    A single recursive block for the TRM.\n",
            "    \"\"\"\n",
            "    def __init__(self, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.norm_state = nn.LayerNorm(d_model)\n",
            "        self.norm_input = nn.LayerNorm(d_model)\n",
            "        self.linear1 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "        self.activation = nn.GELU()\n",
            "        self.linear2 = nn.Linear(2 * d_model, 2 * d_model)\n",
            "\n",
            "    def forward(self, x, state):\n",
            "        \"\"\"\n",
            "        Forward pass for the recursive block.\n",
            "        Args:\n",
            "            x (torch.Tensor): Input tensor for the current step. Shape: (batch_size, d_model)\n",
            "            state (torch.Tensor): Hidden state from the previous step. Shape: (batch_size, d_model)\n",
            "        Returns:\n",
            "            Tuple[torch.Tensor, torch.Tensor]: The output and the new state. Both have shape (batch_size, d_model)\n",
            "        \"\"\"\n",
            "        normalized_state = self.norm_state(state)\n",
            "        normalized_input = self.norm_input(x)\n",
            "        combined_input = torch.cat([normalized_state, normalized_input], dim=1)\n",
            "        hidden = self.linear1(combined_input)\n",
            "        hidden = self.activation(hidden)\n",
            "        processed_output = self.linear2(hidden)\n",
            "        new_state = state + processed_output[:, :self.d_model]\n",
            "        output = processed_output[:, self.d_model:]\n",
            "        return output, new_state\n",
            "\n",
            "class TRM(nn.Module):\n",
            "    \"\"\"\n",
            "    The Tiny Recursive Model.\n",
            "    \"\"\"\n",
            "    def __init__(self, vocab_size, d_model):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
            "        self.recursive_block = RecursiveBlock(d_model)\n",
            "        self.norm_out = nn.LayerNorm(d_model)\n",
            "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
            "\n",
            "    def forward(self, input_sequence):\n",
            "        \"\"\"\n",
            "        Forward pass for the entire sequence.\n",
            "        Args:\n",
            "            input_sequence (torch.Tensor): A sequence of token IDs. Shape: (batch_size, seq_len)\n",
            "        Returns:\n",
            "            torch.Tensor: The output logits for each step in the sequence. Shape: (batch_size, seq_len, vocab_size)\n",
            "        \"\"\"\n",
            "        batch_size, seq_len = input_sequence.shape\n",
            "        embedded_input = self.embedding(input_sequence)\n",
            "\n",
            "        # Initialize the hidden state on the same device as the input\n",
            "        state = torch.zeros(batch_size, self.d_model, device=input_sequence.device)\n",
            "\n",
            "        outputs = []\n",
            "        for i in range(seq_len):\n",
            "            step_input = embedded_input[:, i, :]\n",
            "            output, state = self.recursive_block(step_input, state)\n",
            "            outputs.append(output)\n",
            "\n",
            "        outputs_tensor = torch.stack(outputs, dim=1)\n",
            "        normalized_outputs = self.norm_out(outputs_tensor)\n",
            "        logits = self.output_linear(normalized_outputs)\n",
            "\n",
            "        return logits\n",
            "Using device: cpu\n",
            "TRM classes and related setup defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dc97615"
      },
      "source": [
        "## Prepare 100 Mazes\n",
        "\n",
        "### Subtask:\n",
        "Generate 100 5x5 mazes with a solvable path and preprocess them into the format required by the TRM model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d11b3bc"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare for generating new mazes, I need to first extract the maze-related constants (WALL, PATH, START, END, SEP, PATH_TOKEN_OFFSET, MAZE_SIZE, MAZE_TOKENS) and the `preprocess_maze_data` function from the `full_trm_code` string and execute them. This will ensure these essential components are available in the current environment for maze generation and data preprocessing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e006bd",
        "outputId": "8867636e-2436-457f-8e68-c1fece7648b1"
      },
      "source": [
        "import re\n",
        "\n",
        "maze_constants_and_preprocessing_code = []\n",
        "\n",
        "# Regex to capture constants\n",
        "constant_pattern = re.compile(r'^(WALL|PATH|START|END|SEP|PATH_TOKEN_OFFSET|MAZE_SIZE|MAZE_TOKENS) = .*')\n",
        "# Regex to capture the preprocess_maze_data function\n",
        "function_pattern = re.compile(r'^def preprocess_maze_data\\(dataset\\):.*')\n",
        "\n",
        "current_function_block = []\n",
        "in_function = False\n",
        "\n",
        "for line in full_trm_code.split('\\n'):\n",
        "    if constant_pattern.match(line):\n",
        "        maze_constants_and_preprocessing_code.append(line)\n",
        "    elif function_pattern.match(line):\n",
        "        in_function = True\n",
        "        current_function_block.append(line)\n",
        "    elif in_function:\n",
        "        current_function_block.append(line)\n",
        "        if not line.strip() and len(current_function_block) > 1: # End of function block\n",
        "            maze_constants_and_preprocessing_code.extend(current_function_block)\n",
        "            current_function_block = []\n",
        "            in_function = False\n",
        "        elif line.strip() and line[0].isalpha() and not line.strip().startswith('return'): # Heuristic: if a line without indent or a class/def starts, function ended\n",
        "            maze_constants_and_preprocessing_code.extend(current_function_block[:-1]) # Don't include the breaking line\n",
        "            current_function_block = []\n",
        "            in_function = False\n",
        "            # Re-evaluate the breaking line for constants if it matches\n",
        "            if constant_pattern.match(line):\n",
        "                maze_constants_and_preprocessing_code.append(line)\n",
        "\n",
        "# Add any remaining function lines if the file ends within a function block\n",
        "if current_function_block:\n",
        "    maze_constants_and_preprocessing_code.extend(current_function_block)\n",
        "\n",
        "\n",
        "# Ensure the constants are defined before the function that might use them implicitly\n",
        "# Re-order if needed, although simple append should mostly work if constants are defined first in source\n",
        "extracted_code = \"\\n\".join(maze_constants_and_preprocessing_code)\n",
        "\n",
        "print(\"--- Extracted Maze Constants and Preprocessing Function ---\")\n",
        "print(extracted_code)\n",
        "\n",
        "# Execute the extracted code\n",
        "exec(extracted_code)\n",
        "\n",
        "print(\"Maze constants and preprocess_maze_data function defined successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Extracted Maze Constants and Preprocessing Function ---\n",
            "PATH_TOKEN_OFFSET = 5\n",
            "MAZE_SIZE = 5\n",
            "MAZE_TOKENS = MAZE_SIZE * MAZE_SIZE\n",
            "def preprocess_maze_data(dataset):\n",
            "    sequences = []\n",
            "    for item in dataset:\n",
            "        maze_flat = [token for row in item[\"maze\"] for token in row]\n",
            "        path_tokens = [PATH_TOKEN_OFFSET + r * MAZE_SIZE + c for r, c in item[\"path\"]]\n",
            "        full_sequence = maze_flat + [SEP] + path_tokens\n",
            "        sequences.append(torch.tensor(full_sequence))\n",
            "    return sequences\n",
            "\n",
            "Maze constants and preprocess_maze_data function defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afac62ea"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate 100 solvable mazes, I need to define a Python function that uses a maze generation algorithm (like Randomized DFS) to create a maze grid and then finds a solvable path within it using a search algorithm (like BFS). This function will ensure that the generated mazes always have a start at (0,0) and an end at (MAZE_SIZE-1, MAZE_SIZE-1), and return both the maze grid and a valid path.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b45974d"
      },
      "source": [
        "import random\n",
        "from collections import deque\n",
        "\n",
        "def generate_solvable_maze_and_path(size):\n",
        "    maze = [[WALL for _ in range(size)] for _ in range(size)]\n",
        "\n",
        "    # Use Randomized DFS for maze generation\n",
        "    # Stack for DFS\n",
        "    stack = [(0, 0)]\n",
        "    visited = set()\n",
        "\n",
        "    # Mark start and end points for generation logic\n",
        "    start_pos = (0, 0)\n",
        "    end_pos = (size - 1, size - 1)\n",
        "\n",
        "    # Directions for movement (row_offset, col_offset)\n",
        "    directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
        "\n",
        "    path_carved = []\n",
        "\n",
        "    while stack:\n",
        "        current_r, current_c = stack[-1]\n",
        "\n",
        "        if (current_r, current_c) not in visited:\n",
        "            visited.add((current_r, current_c))\n",
        "            maze[current_r][current_c] = PATH\n",
        "            path_carved.append((current_r, current_c))\n",
        "\n",
        "        neighbors = []\n",
        "        for dr, dc in directions:\n",
        "            nr, nc = current_r + dr, current_c + dc\n",
        "            if 0 <= nr < size and 0 <= nc < size and (nr, nc) not in visited:\n",
        "                neighbors.append((nr, nc))\n",
        "\n",
        "        if neighbors:\n",
        "            next_r, next_c = random.choice(neighbors)\n",
        "            stack.append((next_r, next_c))\n",
        "        else:\n",
        "            stack.pop() # Backtrack\n",
        "\n",
        "    # Ensure start and end are marked\n",
        "    maze[start_pos[0]][start_pos[1]] = START\n",
        "    maze[end_pos[0]][end_pos[1]] = END\n",
        "\n",
        "    # Find the shortest path using BFS\n",
        "    queue = deque([(start_pos, [start_pos])])\n",
        "    bfs_visited = set([start_pos])\n",
        "\n",
        "    while queue:\n",
        "        (r, c), current_path = queue.popleft()\n",
        "\n",
        "        if (r, c) == end_pos:\n",
        "            return {\"maze\": maze, \"path\": current_path}\n",
        "\n",
        "        for dr, dc in directions:\n",
        "            nr, nc = r + dr, c + dc\n",
        "\n",
        "            if 0 <= nr < size and 0 <= nc < size and (nr, nc) not in bfs_visited and maze[nr][nc] != WALL:\n",
        "                bfs_visited.add((nr, nc))\n",
        "                queue.append(((nr, nc), current_path + [(nr, nc)]))\n",
        "\n",
        "    # This should ideally not be reached for a solvable maze generated by DFS\n",
        "    return {\"maze\": maze, \"path\": []} # Return an empty path if no path found (shouldn't happen)\n",
        "\n",
        "print(\"Maze generation function 'generate_solvable_maze_and_path' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}