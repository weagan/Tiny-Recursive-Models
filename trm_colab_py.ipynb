{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/trm_colab_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3j4YpJxbuO1"
      },
      "source": [
        "# Less is More: Recursive Reasoning with Tiny Networks (TRM)\n",
        "\n",
        "This notebook implements the Tiny Recursion Model (TRM) from the paper:\n",
        "\"Less is More: Recursive Reasoning with Tiny Networks\"\n",
        "\n",
        "**Key Features:**\n",
        "- 45% accuracy on ARC-AGI-1 with only 7M parameters\n",
        "- 8% accuracy on ARC-AGI-2\n",
        "- Recursive reasoning without massive models\n",
        "\n",
        "**Paper:** https://arxiv.org/abs/2510.04871\n",
        "\n",
        "**Original Code:** Based on Hierarchical Reasoning Model (HRM)\n",
        "\n",
        "**Runtime Requirements:**\n",
        "- ARC-AGI training: ~3 days on 4x H-100 GPUs\n",
        "- Sudoku-Extreme: <36 hours on 1x L40S GPU\n",
        "- Maze-Hard: <24 hours on 4x L40S GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Gd5biGbuO7"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/weagan/Samsung-TRM"
      ],
      "metadata": {
        "id": "wRAfApg5byhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7zRSLe6buO8",
        "outputId": "109237a1-10fd-4e2c-8a35-8c5981bbf6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU and System Info\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EXEFWxMbuO-"
      },
      "outputs": [],
      "source": [
        "# Clone Repository\n",
        "!git clone https://huggingface.co/wtfmahe/Samsung-TRM\n",
        "%cd Samsung-TRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQbVxFpFbuO_"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "# Note: Adjust PyTorch installation based on your CUDA version\n",
        "\n",
        "# Upgrade pip and core tools\n",
        "!pip install --upgrade pip wheel setuptools -q\n",
        "\n",
        "# Install PyTorch (adjust for your CUDA version)\n",
        "# For Colab with CUDA 12.x:\n",
        "!pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121 -q\n",
        "\n",
        "# Install other requirements\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Install adam-atan2 optimizer\n",
        "!pip install --no-cache-dir --no-build-isolation adam-atan2 -q\n",
        "\n",
        "print(\"✓ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctTOsLVJbuPA"
      },
      "outputs": [],
      "source": [
        "# Login to Weights & Biases (Optional)\n",
        "# Skip this cell if you don't want to use W&B\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Option 1: Login interactively\n",
        "wandb.login()\n",
        "\n",
        "# Option 2: Login with API key (uncomment and add your key)\n",
        "# wandb.login(key=\"YOUR_WANDB_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV6xkMv_buPA"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV6wgFC3buPB"
      },
      "outputs": [],
      "source": [
        "# Download ARC-AGI Dataset\n",
        "# You'll need Kaggle API credentials configured\n",
        "\n",
        "# Create kaggle directory\n",
        "!mkdir -p kaggle/combined\n",
        "\n",
        "# Download ARC-AGI dataset\n",
        "# Note: You need to accept competition rules and have kaggle.json configured\n",
        "!kaggle competitions download -c arc-prize-2024\n",
        "!unzip -q arc-prize-2024.zip -d kaggle/combined/\n",
        "\n",
        "print(\"✓ ARC-AGI dataset downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLPwD9M6buPB"
      },
      "outputs": [],
      "source": [
        "# Build ARC-AGI-1 Dataset\n",
        "# This creates augmented versions of the data\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc1concept-aug-1000 \\\n",
        "  --subsets training evaluation concept \\\n",
        "  --test-set-name evaluation\n",
        "\n",
        "print(\"✓ ARC-AGI-1 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tw3t1avJbuPC"
      },
      "outputs": [],
      "source": [
        "# Build ARC-AGI-2 Dataset\n",
        "# Note: Cannot train on both ARC-AGI-1 and ARC-AGI-2 together\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc2concept-aug-1000 \\\n",
        "  --subsets training2 evaluation2 concept \\\n",
        "  --test-set-name evaluation2\n",
        "\n",
        "print(\"✓ ARC-AGI-2 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdrj3kXAbuPC"
      },
      "outputs": [],
      "source": [
        "# Build Sudoku-Extreme Dataset\n",
        "# Generate with 1000 examples and 1000 augmentations\n",
        "\n",
        "!python dataset/build_sudoku_dataset.py \\\n",
        "  --output-dir data/sudoku-extreme-1k-aug-1000 \\\n",
        "  --subsample-size 1000 \\\n",
        "  --num-aug 1000\n",
        "\n",
        "print(\"✓ Sudoku-Extreme dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WHt18ZSbuPD"
      },
      "outputs": [],
      "source": [
        "# Build Maze-Hard Dataset\n",
        "# Generate 1000 examples with 8 augmentations\n",
        "\n",
        "!python dataset/build_maze_dataset.py\n",
        "\n",
        "print(\"✓ Maze-Hard dataset prepared!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDnpn0zObuPD"
      },
      "source": [
        "## Training Experiments\n",
        "\n",
        "### ARC-AGI Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb8wFv9fbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp9rRwYPbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Single GPU - for Colab)\n",
        "# Modified for Colab constraints\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_1gpu\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sjOJIRabuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-2 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc2concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc2concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8kysWsbuPE"
      },
      "source": [
        "### Sudoku-Extreme Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4TfPozabuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (MLP version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_mlp_t_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.mlp_t=True \\\n",
        "  arch.pos_encodings=none \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkFGZc8UbuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (Attention version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_att_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrooQqMlbuPF"
      },
      "source": [
        "### Maze-Hard Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUWrDU0lbuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Maze-Hard\n",
        "# Runtime: <24 hours on 4 L40S GPUs\n",
        "\n",
        "run_name = \"pretrain_att_maze30x30\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/maze-30x30-hard-1k]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro7RuKv1buPF"
      },
      "source": [
        "## Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz3GCdhAbuPG"
      },
      "outputs": [],
      "source": [
        "# Monitor Training Progress\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# List all run directories\n",
        "runs = glob.glob(\"outputs/*/\")\n",
        "print(\"Available training runs:\")\n",
        "for run in sorted(runs):\n",
        "    print(f\"  {run}\")\n",
        "\n",
        "# Check latest checkpoint\n",
        "latest_run = max(runs, key=os.path.getmtime) if runs else None\n",
        "if latest_run:\n",
        "    print(f\"\\nLatest run: {latest_run}\")\n",
        "    checkpoints = glob.glob(os.path.join(latest_run, \"*.pt\"))\n",
        "    print(f\"Checkpoints: {len(checkpoints)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y7_PPCLbuPG"
      },
      "outputs": [],
      "source": [
        "# Load and Evaluate Model\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Specify checkpoint path\n",
        "checkpoint_path = \"outputs/YOUR_RUN_NAME/checkpoint_best.pt\"\n",
        "\n",
        "if Path(checkpoint_path).exists():\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "    print(f\"Best validation accuracy: {checkpoint.get('best_val_acc', 'unknown')}\")\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZPXuK-ObuPG"
      },
      "outputs": [],
      "source": [
        "# Visualize Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_arc_prediction(input_grid, true_output, predicted_output):\n",
        "    \"\"\"Visualize ARC-AGI predictions\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(input_grid, cmap='tab10', interpolation='nearest')\n",
        "    axes[0].set_title('Input')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(true_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[1].set_title('True Output')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(predicted_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[2].set_title('Predicted Output')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (with dummy data)\n",
        "# input_grid = np.random.randint(0, 10, (10, 10))\n",
        "# true_output = np.random.randint(0, 10, (10, 10))\n",
        "# predicted_output = np.random.randint(0, 10, (10, 10))\n",
        "# visualize_arc_prediction(input_grid, true_output, predicted_output)\n",
        "\n",
        "print(\"Visualization functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszXJRwebuPG"
      },
      "source": [
        "## Citation\n",
        "\n",
        "If you use this code, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{jolicoeurmartineau2025morerecursivereasoningtiny,\n",
        "      title={Less is More: Recursive Reasoning with Tiny Networks},\n",
        "      author={Alexia Jolicoeur-Martineau},\n",
        "      year={2025},\n",
        "      eprint={2510.04871},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.LG},\n",
        "      url={https://arxiv.org/abs/2510.04871},\n",
        "}\n",
        "```\n",
        "\n",
        "And the Hierarchical Reasoning Model (HRM):\n",
        "\n",
        "```bibtex\n",
        "@misc{wang2025hierarchicalreasoningmodel,\n",
        "      title={Hierarchical Reasoning Model},\n",
        "      author={Guan Wang and Jin Li and Yuhao Sun and Xing Chen and Changling Liu and Yue Wu and Meng Lu and Sen Song and Yasin Abbasi Yadkori},\n",
        "      year={2025},\n",
        "      eprint={2506.21734},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.AI},\n",
        "      url={https://arxiv.org/abs/2506.21734},\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}