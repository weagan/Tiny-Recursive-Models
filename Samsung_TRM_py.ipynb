{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Tiny-Recursive-Models/blob/main/Samsung_TRM_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3j4YpJxbuO1"
      },
      "source": [
        "# Less is More: Recursive Reasoning with Tiny Networks (TRM)\n",
        "\n",
        "This notebook implements the Tiny Recursion Model (TRM) from the paper:\n",
        "\"Less is More: Recursive Reasoning with Tiny Networks\"\n",
        "\n",
        "**Key Features:**\n",
        "- 45% accuracy on ARC-AGI-1 with only 7M parameters\n",
        "- 8% accuracy on ARC-AGI-2\n",
        "- Recursive reasoning without massive models\n",
        "\n",
        "**Paper:** https://arxiv.org/abs/2510.04871\n",
        "\n",
        "**Original Code:** Based on Hierarchical Reasoning Model (HRM)\n",
        "\n",
        "**Runtime Requirements:**\n",
        "- ARC-AGI training: ~3 days on 4x H-100 GPUs\n",
        "- Sudoku-Extreme: <36 hours on 1x L40S GPU\n",
        "- Maze-Hard: <24 hours on 4x L40S GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Gd5biGbuO7"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7zRSLe6buO8",
        "outputId": "22003256-b4a1-4430-a25e-786bd8cd0a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "Number of GPUs: 1\n",
            "GPU 0: Tesla T4\n",
            "  Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU and System Info\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA version:\", torch.version.cuda)\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EXEFWxMbuO-",
        "outputId": "f06365bb-33f8-42de-8d0c-9b6dcda8ac73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Samsung-TRM'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 58 (delta 16), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (58/58), 722.67 KiB | 2.22 MiB/s, done.\n",
            "/content/Samsung-TRM\n"
          ]
        }
      ],
      "source": [
        "# Clone Repository\n",
        "!git clone https://huggingface.co/wtfmahe/Samsung-TRM\n",
        "%cd Samsung-TRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQbVxFpFbuO_",
        "outputId": "43670ab7-10b6-4031-84ac-43107a149c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for adam-atan2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "✓ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# Install Dependencies\n",
        "# Note: Adjust PyTorch installation based on your CUDA version\n",
        "\n",
        "# Upgrade pip and core tools\n",
        "!pip install --upgrade pip wheel setuptools -q\n",
        "\n",
        "# Install PyTorch (adjust for your CUDA version)\n",
        "# For Colab with CUDA 12.x:\n",
        "!pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121 -q\n",
        "\n",
        "# Install other requirements\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Install adam-atan2 optimizer\n",
        "!pip install --no-cache-dir --no-build-isolation adam-atan2 -q\n",
        "\n",
        "print(\"✓ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctTOsLVJbuPA",
        "outputId": "994f355a-eb28-4be2-a4b6-a7d4f08cc7ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mweagan\u001b[0m (\u001b[33mweagan-abc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "# Option 1: Login interactively\n",
        "#wandb.login()\n",
        "\n",
        "# Option 2: Login with API key from Colab secrets\n",
        "wandb.login(key=userdata.get('W&B_Key'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV6xkMv_buPA"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58a18109",
        "outputId": "8ed470e0-3fef-4e84-8e16-7b3bd67d1d27"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "kaggle_json_content = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Create .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle/\n",
        "\n",
        "# Write the Kaggle API key to kaggle.json\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
        "    f.write(kaggle_json_content)\n",
        "\n",
        "# Set permissions for kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API configured successfully!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AV6wgFC3buPB"
      },
      "outputs": [],
      "source": [
        "# Download ARC-AGI Dataset\n",
        "# You'll need Kaggle API credentials configured\n",
        "\n",
        "# Create kaggle directory\n",
        "!mkdir -p kaggle/combined\n",
        "\n",
        "# Download ARC-AGI dataset\n",
        "# Note: You need to accept competition rules and have kaggle.json configured\n",
        "# !kaggle competitions download -c arc-prize-2024\n",
        "# !unzip -q arc-prize-2024.zip -d kaggle/combined/\n",
        "\n",
        "# print(\"✓ ARC-AGI dataset downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th5ZKiR4mqNB",
        "outputId": "fac9f394-e27e-41fc-ca8a-039775c0d1d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/fchollet/ARC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3xIYWlikPt9",
        "outputId": "9b6a16ee-cd85-462e-bb2b-3ae07133a4e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ARC'...\n",
            "remote: Enumerating objects: 1277, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/284)\u001b[K\rremote: Counting objects:   1% (3/284)\u001b[K\rremote: Counting objects:   2% (6/284)\u001b[K\rremote: Counting objects:   3% (9/284)\u001b[K\rremote: Counting objects:   4% (12/284)\u001b[K\rremote: Counting objects:   5% (15/284)\u001b[K\rremote: Counting objects:   6% (18/284)\u001b[K\rremote: Counting objects:   7% (20/284)\u001b[K\rremote: Counting objects:   8% (23/284)\u001b[K\rremote: Counting objects:   9% (26/284)\u001b[K\rremote: Counting objects:  10% (29/284)\u001b[K\rremote: Counting objects:  11% (32/284)\u001b[K\rremote: Counting objects:  12% (35/284)\u001b[K\rremote: Counting objects:  13% (37/284)\u001b[K\rremote: Counting objects:  14% (40/284)\u001b[K\rremote: Counting objects:  15% (43/284)\u001b[K\rremote: Counting objects:  16% (46/284)\u001b[K\rremote: Counting objects:  17% (49/284)\u001b[K\rremote: Counting objects:  18% (52/284)\u001b[K\rremote: Counting objects:  19% (54/284)\u001b[K\rremote: Counting objects:  20% (57/284)\u001b[K\rremote: Counting objects:  21% (60/284)\u001b[K\rremote: Counting objects:  22% (63/284)\u001b[K\rremote: Counting objects:  23% (66/284)\u001b[K\rremote: Counting objects:  24% (69/284)\u001b[K\rremote: Counting objects:  25% (71/284)\u001b[K\rremote: Counting objects:  26% (74/284)\u001b[K\rremote: Counting objects:  27% (77/284)\u001b[K\rremote: Counting objects:  28% (80/284)\u001b[K\rremote: Counting objects:  29% (83/284)\u001b[K\rremote: Counting objects:  30% (86/284)\u001b[K\rremote: Counting objects:  31% (89/284)\u001b[K\rremote: Counting objects:  32% (91/284)\u001b[K\rremote: Counting objects:  33% (94/284)\u001b[K\rremote: Counting objects:  34% (97/284)\u001b[K\rremote: Counting objects:  35% (100/284)\u001b[K\rremote: Counting objects:  36% (103/284)\u001b[K\rremote: Counting objects:  37% (106/284)\u001b[K\rremote: Counting objects:  38% (108/284)\u001b[K\rremote: Counting objects:  39% (111/284)\u001b[K\rremote: Counting objects:  40% (114/284)\u001b[K\rremote: Counting objects:  41% (117/284)\u001b[K\rremote: Counting objects:  42% (120/284)\u001b[K\rremote: Counting objects:  43% (123/284)\u001b[K\rremote: Counting objects:  44% (125/284)\u001b[K\rremote: Counting objects:  45% (128/284)\u001b[K\rremote: Counting objects:  46% (131/284)\u001b[K\rremote: Counting objects:  47% (134/284)\u001b[K\rremote: Counting objects:  48% (137/284)\u001b[K\rremote: Counting objects:  49% (140/284)\u001b[K\rremote: Counting objects:  50% (142/284)\u001b[K\rremote: Counting objects:  51% (145/284)\u001b[K\rremote: Counting objects:  52% (148/284)\u001b[K\rremote: Counting objects:  53% (151/284)\u001b[K\rremote: Counting objects:  54% (154/284)\u001b[K\rremote: Counting objects:  55% (157/284)\u001b[K\rremote: Counting objects:  56% (160/284)\u001b[K\rremote: Counting objects:  57% (162/284)\u001b[K\rremote: Counting objects:  58% (165/284)\u001b[K\rremote: Counting objects:  59% (168/284)\u001b[K\rremote: Counting objects:  60% (171/284)\u001b[K\rremote: Counting objects:  61% (174/284)\u001b[K\rremote: Counting objects:  62% (177/284)\u001b[K\rremote: Counting objects:  63% (179/284)\u001b[K\rremote: Counting objects:  64% (182/284)\u001b[K\rremote: Counting objects:  65% (185/284)\u001b[K\rremote: Counting objects:  66% (188/284)\u001b[K\rremote: Counting objects:  67% (191/284)\u001b[K\rremote: Counting objects:  68% (194/284)\u001b[K\rremote: Counting objects:  69% (196/284)\u001b[K\rremote: Counting objects:  70% (199/284)\u001b[K\rremote: Counting objects:  71% (202/284)\u001b[K\rremote: Counting objects:  72% (205/284)\u001b[K\rremote: Counting objects:  73% (208/284)\u001b[K\rremote: Counting objects:  74% (211/284)\u001b[K\rremote: Counting objects:  75% (213/284)\u001b[K\rremote: Counting objects:  76% (216/284)\u001b[K\rremote: Counting objects:  77% (219/284)\u001b[K\rremote: Counting objects:  78% (222/284)\u001b[K\rremote: Counting objects:  79% (225/284)\u001b[K\rremote: Counting objects:  80% (228/284)\u001b[K\rremote: Counting objects:  81% (231/284)\u001b[K\rremote: Counting objects:  82% (233/284)\u001b[K\rremote: Counting objects:  83% (236/284)\u001b[K\rremote: Counting objects:  84% (239/284)\u001b[K\rremote: Counting objects:  85% (242/284)\u001b[K\rremote: Counting objects:  86% (245/284)\u001b[K\rremote: Counting objects:  87% (248/284)\u001b[K\rremote: Counting objects:  88% (250/284)\u001b[K\rremote: Counting objects:  89% (253/284)\u001b[K\rremote: Counting objects:  90% (256/284)\u001b[K\rremote: Counting objects:  91% (259/284)\u001b[K\rremote: Counting objects:  92% (262/284)\u001b[K\rremote: Counting objects:  93% (265/284)\u001b[K\rremote: Counting objects:  94% (267/284)\u001b[K\rremote: Counting objects:  95% (270/284)\u001b[K\rremote: Counting objects:  96% (273/284)\u001b[K\rremote: Counting objects:  97% (276/284)\u001b[K\rremote: Counting objects:  98% (279/284)\u001b[K\rremote: Counting objects:  99% (282/284)\u001b[K\rremote: Counting objects: 100% (284/284)\u001b[K\rremote: Counting objects: 100% (284/284), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/109)\u001b[K\rremote: Compressing objects:   1% (2/109)\u001b[K\rremote: Compressing objects:   2% (3/109)\u001b[K\rremote: Compressing objects:   3% (4/109)\u001b[K\rremote: Compressing objects:   4% (5/109)\u001b[K\rremote: Compressing objects:   5% (6/109)\u001b[K\rremote: Compressing objects:   6% (7/109)\u001b[K\rremote: Compressing objects:   7% (8/109)\u001b[K\rremote: Compressing objects:   8% (9/109)\u001b[K\rremote: Compressing objects:   9% (10/109)\u001b[K\rremote: Compressing objects:  10% (11/109)\u001b[K\rremote: Compressing objects:  11% (12/109)\u001b[K\rremote: Compressing objects:  12% (14/109)\u001b[K\rremote: Compressing objects:  13% (15/109)\u001b[K\rremote: Compressing objects:  14% (16/109)\u001b[K\rremote: Compressing objects:  15% (17/109)\u001b[K\rremote: Compressing objects:  16% (18/109)\u001b[K\rremote: Compressing objects:  17% (19/109)\u001b[K\rremote: Compressing objects:  18% (20/109)\u001b[K\rremote: Compressing objects:  19% (21/109)\u001b[K\rremote: Compressing objects:  20% (22/109)\u001b[K\rremote: Compressing objects:  21% (23/109)\u001b[K\rremote: Compressing objects:  22% (24/109)\u001b[K\rremote: Compressing objects:  23% (26/109)\u001b[K\rremote: Compressing objects:  24% (27/109)\u001b[K\rremote: Compressing objects:  25% (28/109)\u001b[K\rremote: Compressing objects:  26% (29/109)\u001b[K\rremote: Compressing objects:  27% (30/109)\u001b[K\rremote: Compressing objects:  28% (31/109)\u001b[K\rremote: Compressing objects:  29% (32/109)\u001b[K\rremote: Compressing objects:  30% (33/109)\u001b[K\rremote: Compressing objects:  31% (34/109)\u001b[K\rremote: Compressing objects:  32% (35/109)\u001b[K\rremote: Compressing objects:  33% (36/109)\u001b[K\rremote: Compressing objects:  34% (38/109)\u001b[K\rremote: Compressing objects:  35% (39/109)\u001b[K\rremote: Compressing objects:  36% (40/109)\u001b[K\rremote: Compressing objects:  37% (41/109)\u001b[K\rremote: Compressing objects:  38% (42/109)\u001b[K\rremote: Compressing objects:  39% (43/109)\u001b[K\rremote: Compressing objects:  40% (44/109)\u001b[K\rremote: Compressing objects:  41% (45/109)\u001b[K\rremote: Compressing objects:  42% (46/109)\u001b[K\rremote: Compressing objects:  43% (47/109)\u001b[K\rremote: Compressing objects:  44% (48/109)\u001b[K\rremote: Compressing objects:  45% (50/109)\u001b[K\rremote: Compressing objects:  46% (51/109)\u001b[K\rremote: Compressing objects:  47% (52/109)\u001b[K\rremote: Compressing objects:  48% (53/109)\u001b[K\rremote: Compressing objects:  49% (54/109)\u001b[K\rremote: Compressing objects:  50% (55/109)\u001b[K\rremote: Compressing objects:  51% (56/109)\u001b[K\rremote: Compressing objects:  52% (57/109)\u001b[K\rremote: Compressing objects:  53% (58/109)\u001b[K\rremote: Compressing objects:  54% (59/109)\u001b[K\rremote: Compressing objects:  55% (60/109)\u001b[K\rremote: Compressing objects:  56% (62/109)\u001b[K\rremote: Compressing objects:  57% (63/109)\u001b[K\rremote: Compressing objects:  58% (64/109)\u001b[K\rremote: Compressing objects:  59% (65/109)\u001b[K\rremote: Compressing objects:  60% (66/109)\u001b[K\rremote: Compressing objects:  61% (67/109)\u001b[K\rremote: Compressing objects:  62% (68/109)\u001b[K\rremote: Compressing objects:  63% (69/109)\u001b[K\rremote: Compressing objects:  64% (70/109)\u001b[K\rremote: Compressing objects:  65% (71/109)\u001b[K\rremote: Compressing objects:  66% (72/109)\u001b[K\rremote: Compressing objects:  67% (74/109)\u001b[K\rremote: Compressing objects:  68% (75/109)\u001b[K\rremote: Compressing objects:  69% (76/109)\u001b[K\rremote: Compressing objects:  70% (77/109)\u001b[K\rremote: Compressing objects:  71% (78/109)\u001b[K\rremote: Compressing objects:  72% (79/109)\u001b[K\rremote: Compressing objects:  73% (80/109)\u001b[K\rremote: Compressing objects:  74% (81/109)\u001b[K\rremote: Compressing objects:  75% (82/109)\u001b[K\rremote: Compressing objects:  76% (83/109)\u001b[K\rremote: Compressing objects:  77% (84/109)\u001b[K\rremote: Compressing objects:  78% (86/109)\u001b[K\rremote: Compressing objects:  79% (87/109)\u001b[K\rremote: Compressing objects:  80% (88/109)\u001b[K\rremote: Compressing objects:  81% (89/109)\u001b[K\rremote: Compressing objects:  82% (90/109)\u001b[K\rremote: Compressing objects:  83% (91/109)\u001b[K\rremote: Compressing objects:  84% (92/109)\u001b[K\rremote: Compressing objects:  85% (93/109)\u001b[K\rremote: Compressing objects:  86% (94/109)\u001b[K\rremote: Compressing objects:  87% (95/109)\u001b[K\rremote: Compressing objects:  88% (96/109)\u001b[K\rremote: Compressing objects:  89% (98/109)\u001b[K\rremote: Compressing objects:  90% (99/109)\u001b[K\rremote: Compressing objects:  91% (100/109)\u001b[K\rremote: Compressing objects:  92% (101/109)\u001b[K\rremote: Compressing objects:  93% (102/109)\u001b[K\rremote: Compressing objects:  94% (103/109)\u001b[K\rremote: Compressing objects:  95% (104/109)\u001b[K\rremote: Compressing objects:  96% (105/109)\u001b[K\rremote: Compressing objects:  97% (106/109)\u001b[K\rremote: Compressing objects:  98% (107/109)\u001b[K\rremote: Compressing objects:  99% (108/109)\u001b[K\rremote: Compressing objects: 100% (109/109)\u001b[K\rremote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "Receiving objects:   0% (1/1277)\rReceiving objects:   1% (13/1277)\rReceiving objects:   2% (26/1277)\rReceiving objects:   3% (39/1277)\rReceiving objects:   4% (52/1277)\rReceiving objects:   5% (64/1277)\rReceiving objects:   6% (77/1277)\rReceiving objects:   7% (90/1277)\rReceiving objects:   8% (103/1277)\rReceiving objects:   9% (115/1277)\rReceiving objects:  10% (128/1277)\rReceiving objects:  11% (141/1277)\rReceiving objects:  12% (154/1277)\rReceiving objects:  13% (167/1277)\rReceiving objects:  14% (179/1277)\rReceiving objects:  15% (192/1277)\rReceiving objects:  16% (205/1277)\rReceiving objects:  17% (218/1277)\rReceiving objects:  18% (230/1277)\rReceiving objects:  19% (243/1277)\rReceiving objects:  20% (256/1277)\rReceiving objects:  21% (269/1277)\rReceiving objects:  22% (281/1277)\rReceiving objects:  23% (294/1277)\rReceiving objects:  24% (307/1277)\rReceiving objects:  25% (320/1277)\rReceiving objects:  26% (333/1277)\rReceiving objects:  27% (345/1277)\rReceiving objects:  28% (358/1277)\rReceiving objects:  29% (371/1277)\rReceiving objects:  30% (384/1277)\rReceiving objects:  31% (396/1277)\rReceiving objects:  32% (409/1277)\rReceiving objects:  33% (422/1277)\rReceiving objects:  34% (435/1277)\rReceiving objects:  35% (447/1277)\rReceiving objects:  36% (460/1277)\rReceiving objects:  37% (473/1277)\rReceiving objects:  38% (486/1277)\rReceiving objects:  39% (499/1277)\rReceiving objects:  40% (511/1277)\rReceiving objects:  41% (524/1277)\rReceiving objects:  42% (537/1277)\rReceiving objects:  43% (550/1277)\rReceiving objects:  44% (562/1277)\rReceiving objects:  45% (575/1277)\rReceiving objects:  46% (588/1277)\rReceiving objects:  47% (601/1277)\rReceiving objects:  48% (613/1277)\rReceiving objects:  49% (626/1277)\rReceiving objects:  50% (639/1277)\rReceiving objects:  51% (652/1277)\rReceiving objects:  52% (665/1277)\rReceiving objects:  53% (677/1277)\rReceiving objects:  54% (690/1277)\rReceiving objects:  55% (703/1277)\rReceiving objects:  56% (716/1277)\rReceiving objects:  57% (728/1277)\rReceiving objects:  58% (741/1277)\rReceiving objects:  59% (754/1277)\rReceiving objects:  60% (767/1277)\rReceiving objects:  61% (779/1277)\rReceiving objects:  62% (792/1277)\rReceiving objects:  63% (805/1277)\rReceiving objects:  64% (818/1277)\rReceiving objects:  65% (831/1277)\rReceiving objects:  66% (843/1277)\rReceiving objects:  67% (856/1277)\rReceiving objects:  68% (869/1277)\rReceiving objects:  69% (882/1277)\rReceiving objects:  70% (894/1277)\rReceiving objects:  71% (907/1277)\rReceiving objects:  72% (920/1277)\rReceiving objects:  73% (933/1277)\rReceiving objects:  74% (945/1277)\rReceiving objects:  75% (958/1277)\rReceiving objects:  76% (971/1277)\rReceiving objects:  77% (984/1277)\rReceiving objects:  78% (997/1277)\rReceiving objects:  79% (1009/1277)\rReceiving objects:  80% (1022/1277)\rReceiving objects:  81% (1035/1277)\rReceiving objects:  82% (1048/1277)\rReceiving objects:  83% (1060/1277)\rremote: Total 1277 (delta 194), reused 175 (delta 175), pack-reused 993 (from 3)\u001b[K\n",
            "Receiving objects:  84% (1073/1277)\rReceiving objects:  85% (1086/1277)\rReceiving objects:  86% (1099/1277)\rReceiving objects:  87% (1111/1277)\rReceiving objects:  88% (1124/1277)\rReceiving objects:  89% (1137/1277)\rReceiving objects:  90% (1150/1277)\rReceiving objects:  91% (1163/1277)\rReceiving objects:  92% (1175/1277)\rReceiving objects:  93% (1188/1277)\rReceiving objects:  94% (1201/1277)\rReceiving objects:  95% (1214/1277)\rReceiving objects:  96% (1226/1277)\rReceiving objects:  97% (1239/1277)\rReceiving objects:  98% (1252/1277)\rReceiving objects:  99% (1265/1277)\rReceiving objects: 100% (1277/1277)\rReceiving objects: 100% (1277/1277), 499.69 KiB | 14.28 MiB/s, done.\n",
            "Resolving deltas:   0% (0/727)\rResolving deltas:   1% (8/727)\rResolving deltas:   2% (15/727)\rResolving deltas:   3% (22/727)\rResolving deltas:   4% (30/727)\rResolving deltas:   5% (37/727)\rResolving deltas:   6% (44/727)\rResolving deltas:   7% (51/727)\rResolving deltas:   8% (59/727)\rResolving deltas:   9% (66/727)\rResolving deltas:  10% (73/727)\rResolving deltas:  11% (80/727)\rResolving deltas:  12% (88/727)\rResolving deltas:  13% (95/727)\rResolving deltas:  14% (102/727)\rResolving deltas:  15% (110/727)\rResolving deltas:  16% (117/727)\rResolving deltas:  17% (124/727)\rResolving deltas:  18% (131/727)\rResolving deltas:  19% (139/727)\rResolving deltas:  20% (146/727)\rResolving deltas:  21% (153/727)\rResolving deltas:  22% (160/727)\rResolving deltas:  23% (168/727)\rResolving deltas:  24% (175/727)\rResolving deltas:  25% (182/727)\rResolving deltas:  26% (190/727)\rResolving deltas:  27% (197/727)\rResolving deltas:  28% (204/727)\rResolving deltas:  29% (211/727)\rResolving deltas:  30% (219/727)\rResolving deltas:  31% (226/727)\rResolving deltas:  32% (233/727)\rResolving deltas:  33% (240/727)\rResolving deltas:  34% (248/727)\rResolving deltas:  35% (255/727)\rResolving deltas:  36% (262/727)\rResolving deltas:  37% (269/727)\rResolving deltas:  38% (277/727)\rResolving deltas:  39% (284/727)\rResolving deltas:  40% (291/727)\rResolving deltas:  41% (299/727)\rResolving deltas:  42% (306/727)\rResolving deltas:  43% (313/727)\rResolving deltas:  44% (320/727)\rResolving deltas:  45% (328/727)\rResolving deltas:  46% (335/727)\rResolving deltas:  47% (342/727)\rResolving deltas:  48% (349/727)\rResolving deltas:  49% (357/727)\rResolving deltas:  50% (364/727)\rResolving deltas:  51% (371/727)\rResolving deltas:  52% (379/727)\rResolving deltas:  53% (386/727)\rResolving deltas:  54% (393/727)\rResolving deltas:  55% (400/727)\rResolving deltas:  56% (408/727)\rResolving deltas:  57% (415/727)\rResolving deltas:  58% (422/727)\rResolving deltas:  59% (429/727)\rResolving deltas:  60% (437/727)\rResolving deltas:  61% (444/727)\rResolving deltas:  62% (451/727)\rResolving deltas:  63% (459/727)\rResolving deltas:  64% (466/727)\rResolving deltas:  65% (473/727)\rResolving deltas:  66% (480/727)\rResolving deltas:  67% (488/727)\rResolving deltas:  68% (495/727)\rResolving deltas:  69% (502/727)\rResolving deltas:  70% (509/727)\rResolving deltas:  71% (517/727)\rResolving deltas:  72% (524/727)\rResolving deltas:  73% (531/727)\rResolving deltas:  74% (538/727)\rResolving deltas:  75% (546/727)\rResolving deltas:  76% (553/727)\rResolving deltas:  77% (560/727)\rResolving deltas:  78% (568/727)\rResolving deltas:  79% (575/727)\rResolving deltas:  80% (582/727)\rResolving deltas:  81% (589/727)\rResolving deltas:  82% (597/727)\rResolving deltas:  83% (604/727)\rResolving deltas:  84% (611/727)\rResolving deltas:  85% (618/727)\rResolving deltas:  86% (626/727)\rResolving deltas:  87% (633/727)\rResolving deltas:  88% (640/727)\rResolving deltas:  89% (648/727)\rResolving deltas:  90% (655/727)\rResolving deltas:  91% (662/727)\rResolving deltas:  92% (669/727)\rResolving deltas:  93% (677/727)\rResolving deltas:  94% (684/727)\rResolving deltas:  95% (691/727)\rResolving deltas:  96% (698/727)\rResolving deltas:  97% (706/727)\rResolving deltas:  98% (713/727)\rResolving deltas:  99% (720/727)\rResolving deltas: 100% (727/727)\rResolving deltas: 100% (727/727), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d namank24/arc-prize-2024-dataset\n",
        "!unzip -q arc-prize-2024-dataset.zip -d kaggle/combined/\n",
        "#!unzip arc-prize-2024-dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xIbYCXRkwWc",
        "outputId": "99c7bf31-12a6-499c-8e07-08a31386856d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/namank24/arc-prize-2024-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading arc-prize-2024-dataset.zip to /content/Samsung-TRM\n",
            "  0% 0.00/150k [00:00<?, ?B/s]\n",
            "100% 150k/150k [00:00<00:00, 508MB/s]\n",
            "replace kaggle/combined/arc-agi_evaluation_challenges.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLPwD9M6buPB",
        "outputId": "2a0ce71c-6ce6-44b8-cece-d0afbc70598b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Puzzle 8be77c9e] augmentation not full, only 72\n",
            "[Puzzle 4258a5f9] augmentation not full, only 576\n",
            "[Puzzle 3618c87e] augmentation not full, only 575\n",
            "[Puzzle 2281f1f4] augmentation not full, only 576\n",
            "[Puzzle 3906de3d] augmentation not full, only 576\n",
            "[Puzzle aedd82e4] augmentation not full, only 576\n",
            "[Puzzle 4612dd53] augmentation not full, only 575\n",
            "[Puzzle 28e73c20] augmentation not full, only 72\n",
            "[Puzzle f15e1fac] augmentation not full, only 576\n",
            "[Puzzle 44d8ac46] augmentation not full, only 576\n",
            "[Puzzle dc433765] augmentation not full, only 575\n",
            "[Puzzle a5313dff] augmentation not full, only 576\n",
            "[Puzzle 3f7978a0] augmentation not full, only 576\n",
            "[Puzzle d4f3cd78] augmentation not full, only 576\n",
            "[Puzzle 760b3cac] augmentation not full, only 576\n",
            "[Puzzle cce03e0d] augmentation not full, only 576\n",
            "[Puzzle ef135b50] augmentation not full, only 576\n",
            "[Puzzle a3df8b1e] augmentation not full, only 72\n",
            "[Puzzle 6855a6e4] augmentation not full, only 576\n",
            "[Puzzle 05f2a901] augmentation not full, only 575\n",
            "[Puzzle ded97339] augmentation not full, only 72\n",
            "[Puzzle dbc1a6ce] augmentation not full, only 575\n",
            "[Puzzle b60334d2] augmentation not full, only 576\n",
            "[Puzzle db3e9e38] augmentation not full, only 576\n",
            "[Puzzle 7447852a] augmentation not full, only 576\n",
            "[Puzzle 80af3007] augmentation not full, only 72\n",
            "[Puzzle 90f3ed37] augmentation not full, only 576\n",
            "[Puzzle ba26e723] augmentation not full, only 576\n",
            "[Puzzle 4938f0c2] augmentation not full, only 576\n",
            "[Puzzle 6d75e8bb] augmentation not full, only 576\n",
            "[Puzzle 4522001f] augmentation not full, only 288\n",
            "[Puzzle ce22a75a] augmentation not full, only 576\n",
            "[Puzzle ff28f65a] augmentation not full, only 576\n",
            "[Puzzle 1fad071e] augmentation not full, only 576\n",
            "[Puzzle d0f5fe59] augmentation not full, only 72\n",
            "[Puzzle 810b9b61] augmentation not full, only 576\n",
            "[Puzzle 67385a82] augmentation not full, only 575\n",
            "[Puzzle d5d6de2d] augmentation not full, only 576\n",
            "[Puzzle 794b24be] augmentation not full, only 576\n",
            "[Puzzle b27ca6d3] augmentation not full, only 576\n",
            "[Puzzle e5062a87] augmentation not full, only 576\n",
            "[Puzzle 017c7c7b] augmentation not full, only 575\n",
            "[Puzzle 1b60fb0c] augmentation not full, only 575\n",
            "[Puzzle ecdecbb3] augmentation not full, only 576\n",
            "[Puzzle d06dbe63] augmentation not full, only 576\n",
            "[Puzzle f8a8fe49] augmentation not full, only 576\n",
            "[Puzzle a48eeaf7] augmentation not full, only 576\n",
            "[Puzzle a1570a43] augmentation not full, only 576\n",
            "[Puzzle 6c434453] augmentation not full, only 576\n",
            "[Puzzle 6f8cd79b] augmentation not full, only 18\n",
            "[Puzzle af902bf9] augmentation not full, only 576\n",
            "[Puzzle 22233c11] augmentation not full, only 576\n",
            "[Puzzle c9e6f938] augmentation not full, only 72\n",
            "[Puzzle d406998b] augmentation not full, only 576\n",
            "[Puzzle 447fd412] augmentation not full, only 576\n",
            "[Puzzle 8efcae92] augmentation not full, only 576\n",
            "[Puzzle 239be575] augmentation not full, only 576\n",
            "[Puzzle e179c5f4] augmentation not full, only 576\n",
            "[Puzzle a79310a0] augmentation not full, only 576\n",
            "[Puzzle e9614598] augmentation not full, only 576\n",
            "[Puzzle 60b61512] augmentation not full, only 576\n",
            "[Puzzle 5c0a986e] augmentation not full, only 576\n",
            "[Puzzle e73095fd] augmentation not full, only 576\n",
            "[Puzzle b527c5c6] augmentation not full, only 576\n",
            "[Puzzle 7df24a62] augmentation not full, only 576\n",
            "[Puzzle 00d62c1b] augmentation not full, only 576\n",
            "[Puzzle 253bf280] augmentation not full, only 576\n",
            "[Puzzle 3aa6fb7a] augmentation not full, only 576\n",
            "[Puzzle 25ff71a9] augmentation not full, only 576\n",
            "[Puzzle a8d7556c] augmentation not full, only 576\n",
            "[Puzzle b0c4d837] augmentation not full, only 576\n",
            "[Puzzle f25fbde4] augmentation not full, only 72\n",
            "[Puzzle ce9e57f2] augmentation not full, only 576\n",
            "[Puzzle d9f24cd1] augmentation not full, only 576\n",
            "[Puzzle bb43febb] augmentation not full, only 576\n",
            "[Puzzle a699fb00] augmentation not full, only 576\n",
            "[Puzzle 5168d44c] augmentation not full, only 576\n",
            "[Puzzle ae4f1146] augmentation not full, only 576\n",
            "[Puzzle 4e469f39] augmentation not full, only 576\n",
            "[Puzzle 8719f442] augmentation not full, only 72\n",
            "[Puzzle 712bf12e] augmentation not full, only 576\n",
            "[Puzzle be03b35f] augmentation not full, only 576\n",
            "[Puzzle 0b17323b] augmentation not full, only 288\n",
            "[Puzzle b9630600] augmentation not full, only 72\n",
            "[Puzzle 817e6c09] augmentation not full, only 576\n",
            "[Puzzle 6f473927] augmentation not full, only 576\n",
            "[Puzzle 2697da3f] augmentation not full, only 72\n",
            "[Puzzle 7e02026e] augmentation not full, only 576\n",
            "[Puzzle ac0c5833] augmentation not full, only 576\n",
            "[Puzzle 73c3b0d8] augmentation not full, only 576\n",
            "[Puzzle 9bebae7a] augmentation not full, only 576\n",
            "[Puzzle 332efdb3] augmentation not full, only 9\n",
            "[Puzzle 9c56f360] augmentation not full, only 575\n",
            "[Puzzle 64a7c07e] augmentation not full, only 72\n",
            "[Puzzle 31adaf00] augmentation not full, only 576\n",
            "[Puzzle bf89d739] augmentation not full, only 575\n",
            "[Puzzle e6de6e8f] augmentation not full, only 576\n",
            "[Puzzle e7639916] augmentation not full, only 576\n",
            "[Puzzle dc2aa30b] augmentation not full, only 576\n",
            "[Puzzle c87289bb] augmentation not full, only 576\n",
            "[Puzzle ce039d91] augmentation not full, only 576\n",
            "[Puzzle baf41dbf] augmentation not full, only 576\n",
            "[Puzzle e1d2900e] augmentation not full, only 576\n",
            "[Puzzle fd4b2b02] augmentation not full, only 576\n",
            "[Puzzle f9a67cb5] augmentation not full, only 576\n",
            "[Puzzle e619ca6e] augmentation not full, only 72\n",
            "[Puzzle 759f3fd3] augmentation not full, only 576\n",
            "[Puzzle da515329] augmentation not full, only 72\n",
            "[Puzzle 0d87d2a6] augmentation not full, only 576\n",
            "[Puzzle 21f83797] augmentation not full, only 576\n",
            "[Puzzle ae58858e] augmentation not full, only 576\n",
            "[Puzzle 54db823b] augmentation not full, only 576\n",
            "[Puzzle 2c0b0aff] augmentation not full, only 576\n",
            "[Puzzle aa300dc3] augmentation not full, only 576\n",
            "[Puzzle 551d5bf1] augmentation not full, only 576\n",
            "[Puzzle 5b526a93] augmentation not full, only 576\n",
            "[Puzzle cb227835] augmentation not full, only 576\n",
            "[Puzzle d304284e] augmentation not full, only 576\n",
            "[Puzzle e0fb7511] augmentation not full, only 576\n",
            "[Puzzle 1c0d0a4b] augmentation not full, only 576\n",
            "[Puzzle e7dd8335] augmentation not full, only 576\n",
            "[Puzzle 20981f0e] augmentation not full, only 576\n",
            "[Puzzle 42a15761] augmentation not full, only 72\n",
            "[Puzzle 60a26a3e] augmentation not full, only 576\n",
            "[Puzzle d37a1ef5] augmentation not full, only 576\n",
            "[Puzzle c1990cce] augmentation not full, only 576\n",
            "[Puzzle 18419cfa] augmentation not full, only 576\n",
            "[Puzzle 8fbca751] augmentation not full, only 575\n",
            "[Puzzle e5c44e8f] augmentation not full, only 576\n",
            "[Puzzle a3f84088] augmentation not full, only 576\n",
            "[Puzzle c97c0139] augmentation not full, only 576\n",
            "[Puzzle 69889d6e] augmentation not full, only 576\n",
            "[Puzzle b1fc8b8e] augmentation not full, only 72\n",
            "[Puzzle 55059096] augmentation not full, only 576\n",
            "[Puzzle 1990f7a8] augmentation not full, only 72\n",
            "[Puzzle 4852f2fa] augmentation not full, only 576\n",
            "[Puzzle 9772c176] augmentation not full, only 576\n",
            "[Puzzle e872b94a] augmentation not full, only 72\n",
            "[Puzzle a934301b] augmentation not full, only 574\n",
            "[Puzzle bd14c3bf] augmentation not full, only 576\n",
            "[Puzzle CleanUp10] augmentation not full, only 72\n",
            "[Puzzle HorizontalVertical5] augmentation not full, only 575\n",
            "[Puzzle ExtendToBoundary6] augmentation not full, only 576\n",
            "[Puzzle InsideOutside3] augmentation not full, only 576\n",
            "[Puzzle CompleteShape5] augmentation not full, only 576\n",
            "[Puzzle Order5] augmentation not full, only 576\n",
            "[Puzzle Order9] augmentation not full, only 36\n",
            "[Puzzle FilledNotFilled4] augmentation not full, only 72\n",
            "[Puzzle ExtendToBoundary5] augmentation not full, only 72\n",
            "[Puzzle Count2] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary1] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary2] augmentation not full, only 72\n",
            "[Puzzle HorizontalVertical6] augmentation not full, only 576\n",
            "[Puzzle Order7] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary10] augmentation not full, only 576\n",
            "[Puzzle Center10] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled10] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary3] augmentation not full, only 72\n",
            "[Puzzle FilledNotFilled9] augmentation not full, only 576\n",
            "[Puzzle Count5] augmentation not full, only 72\n",
            "[Puzzle MoveToBoundary4] augmentation not full, only 72\n",
            "[Puzzle InsideOutside2] augmentation not full, only 576\n",
            "[Puzzle TopBottom2D1] augmentation not full, only 576\n",
            "[Puzzle InsideOutside9] augmentation not full, only 576\n",
            "Total puzzles: 960\n",
            "Total puzzle IDs (including <blank>): 876406\n",
            "^C\n",
            "✓ ARC-AGI-1 dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build ARC-AGI-1 Dataset\n",
        "# This creates augmented versions of the data\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc1concept-aug-1000 \\\n",
        "  --subsets training evaluation concept \\\n",
        "  --test-set-name evaluation\n",
        "\n",
        "print(\"✓ ARC-AGI-1 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw3t1avJbuPC",
        "outputId": "69bddcf0-2898-4524-8217-c984dbd2cee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Puzzle bd14c3bf] augmentation not full, only 574\n",
            "[Puzzle 8dab14c2] augmentation not full, only 575\n",
            "[Puzzle 3aa6fb7a] augmentation not full, only 576\n",
            "[Puzzle e6de6e8f] augmentation not full, only 576\n",
            "[Puzzle 5c0a986e] augmentation not full, only 576\n",
            "[Puzzle 2697da3f] augmentation not full, only 72\n",
            "[Puzzle 3618c87e] augmentation not full, only 576\n",
            "[Puzzle 5168d44c] augmentation not full, only 576\n",
            "[Puzzle 9bebae7a] augmentation not full, only 575\n",
            "[Puzzle 90f3ed37] augmentation not full, only 576\n",
            "[Puzzle 1990f7a8] augmentation not full, only 72\n",
            "[Puzzle 20981f0e] augmentation not full, only 576\n",
            "[Puzzle a934301b] augmentation not full, only 576\n",
            "[Puzzle 18419cfa] augmentation not full, only 576\n",
            "[Puzzle cce03e0d] augmentation not full, only 576\n",
            "[Puzzle 4612dd53] augmentation not full, only 576\n",
            "[Puzzle d37a1ef5] augmentation not full, only 576\n",
            "[Puzzle f9a67cb5] augmentation not full, only 576\n",
            "[Puzzle 4258a5f9] augmentation not full, only 576\n",
            "[Puzzle 0b17323b] augmentation not full, only 288\n",
            "[Puzzle b9630600] augmentation not full, only 72\n",
            "[Puzzle d255d7a7] augmentation not full, only 576\n",
            "[Puzzle ded97339] augmentation not full, only 72\n",
            "[Puzzle 80af3007] augmentation not full, only 72\n",
            "[Puzzle 21f83797] augmentation not full, only 576\n",
            "[Puzzle d06dbe63] augmentation not full, only 576\n",
            "[Puzzle aedd82e4] augmentation not full, only 576\n",
            "[Puzzle 60b61512] augmentation not full, only 576\n",
            "[Puzzle ef135b50] augmentation not full, only 575\n",
            "[Puzzle f15e1fac] augmentation not full, only 576\n",
            "[Puzzle d5d6de2d] augmentation not full, only 576\n",
            "[Puzzle 8efcae92] augmentation not full, only 576\n",
            "[Puzzle aa300dc3] augmentation not full, only 576\n",
            "[Puzzle 44d8ac46] augmentation not full, only 575\n",
            "[Puzzle e5c44e8f] augmentation not full, only 576\n",
            "[Puzzle e73095fd] augmentation not full, only 576\n",
            "[Puzzle 817e6c09] augmentation not full, only 576\n",
            "[Puzzle 00d62c1b] augmentation not full, only 576\n",
            "[Puzzle 3906de3d] augmentation not full, only 576\n",
            "[Puzzle 1c0d0a4b] augmentation not full, only 576\n",
            "[Puzzle fd4b2b02] augmentation not full, only 576\n",
            "[Puzzle e872b94a] augmentation not full, only 72\n",
            "[Puzzle 017c7c7b] augmentation not full, only 576\n",
            "[Puzzle 4852f2fa] augmentation not full, only 576\n",
            "[Puzzle 8be77c9e] augmentation not full, only 72\n",
            "[Puzzle 9c56f360] augmentation not full, only 576\n",
            "[Puzzle cb227835] augmentation not full, only 575\n",
            "[Puzzle 7df24a62] augmentation not full, only 576\n",
            "[Puzzle 758abdf0] augmentation not full, only 576\n",
            "[Puzzle 6f8cd79b] augmentation not full, only 18\n",
            "[Puzzle c9e6f938] augmentation not full, only 72\n",
            "[Puzzle 794b24be] augmentation not full, only 576\n",
            "[Puzzle baf41dbf] augmentation not full, only 576\n",
            "[Puzzle 1b60fb0c] augmentation not full, only 576\n",
            "[Puzzle 28e73c20] augmentation not full, only 72\n",
            "[Puzzle c97c0139] augmentation not full, only 576\n",
            "[Puzzle 5b526a93] augmentation not full, only 576\n",
            "[Puzzle a48eeaf7] augmentation not full, only 576\n",
            "[Puzzle 551d5bf1] augmentation not full, only 576\n",
            "[Puzzle e179c5f4] augmentation not full, only 576\n",
            "[Puzzle 25ff71a9] augmentation not full, only 576\n",
            "[Puzzle 6855a6e4] augmentation not full, only 576\n",
            "[Puzzle db7260a4] augmentation not full, only 576\n",
            "[Puzzle 332efdb3] augmentation not full, only 9\n",
            "[Puzzle 6c434453] augmentation not full, only 576\n",
            "[Puzzle ff28f65a] augmentation not full, only 576\n",
            "[Puzzle b27ca6d3] augmentation not full, only 576\n",
            "[Puzzle 5ad8a7c0] augmentation not full, only 36\n",
            "[Puzzle d406998b] augmentation not full, only 576\n",
            "[Puzzle 73c3b0d8] augmentation not full, only 576\n",
            "[Puzzle 60a26a3e] augmentation not full, only 576\n",
            "[Puzzle 05f2a901] augmentation not full, only 576\n",
            "[Puzzle f8a8fe49] augmentation not full, only 576\n",
            "[Puzzle ac0c5833] augmentation not full, only 576\n",
            "[Puzzle 447fd412] augmentation not full, only 576\n",
            "[Puzzle 22233c11] augmentation not full, only 576\n",
            "[Puzzle e0fb7511] augmentation not full, only 576\n",
            "[Puzzle 31adaf00] augmentation not full, only 576\n",
            "[Puzzle b0c4d837] augmentation not full, only 576\n",
            "[Puzzle c1990cce] augmentation not full, only 576\n",
            "[Puzzle a5313dff] augmentation not full, only 576\n",
            "[Puzzle 4e469f39] augmentation not full, only 576\n",
            "[Puzzle d9f24cd1] augmentation not full, only 576\n",
            "[Puzzle 2281f1f4] augmentation not full, only 576\n",
            "[Puzzle d4f3cd78] augmentation not full, only 576\n",
            "[Puzzle b25e450b] augmentation not full, only 576\n",
            "[Puzzle 760b3cac] augmentation not full, only 576\n",
            "[Puzzle ae4f1146] augmentation not full, only 576\n",
            "[Puzzle 239be575] augmentation not full, only 576\n",
            "[Puzzle a3f84088] augmentation not full, only 576\n",
            "[Puzzle ce039d91] augmentation not full, only 576\n",
            "[Puzzle 8fbca751] augmentation not full, only 576\n",
            "[Puzzle a1570a43] augmentation not full, only 576\n",
            "[Puzzle dc433765] augmentation not full, only 575\n",
            "[Puzzle be03b35f] augmentation not full, only 576\n",
            "[Puzzle 810b9b61] augmentation not full, only 576\n",
            "[Puzzle 3f7978a0] augmentation not full, only 576\n",
            "[Puzzle 7e02026e] augmentation not full, only 576\n",
            "[Puzzle db3e9e38] augmentation not full, only 576\n",
            "[Puzzle dbc1a6ce] augmentation not full, only 575\n",
            "[Puzzle e7639916] augmentation not full, only 576\n",
            "[Puzzle 6f473927] augmentation not full, only 576\n",
            "[Puzzle c61be7dc] augmentation not full, only 576\n",
            "[Puzzle a8d7556c] augmentation not full, only 576\n",
            "[Puzzle e5062a87] augmentation not full, only 576\n",
            "[Puzzle 6d75e8bb] augmentation not full, only 576\n",
            "[Puzzle e7dd8335] augmentation not full, only 576\n",
            "[Puzzle e9614598] augmentation not full, only 576\n",
            "[Puzzle e1d2900e] augmentation not full, only 576\n",
            "[Puzzle 759f3fd3] augmentation not full, only 576\n",
            "[Puzzle ae58858e] augmentation not full, only 576\n",
            "[Puzzle f25fbde4] augmentation not full, only 72\n",
            "[Puzzle d304284e] augmentation not full, only 576\n",
            "[Puzzle 8719f442] augmentation not full, only 72\n",
            "[Puzzle a79310a0] augmentation not full, only 576\n",
            "[Puzzle 97c75046] augmentation not full, only 575\n",
            "[Puzzle ce9e57f2] augmentation not full, only 576\n",
            "[Puzzle 2c0b0aff] augmentation not full, only 576\n",
            "[Puzzle 2faf500b] augmentation not full, only 576\n",
            "[Puzzle 42a15761] augmentation not full, only 72\n",
            "[Puzzle 9772c176] augmentation not full, only 576\n",
            "[Puzzle b1fc8b8e] augmentation not full, only 72\n",
            "[Puzzle 69889d6e] augmentation not full, only 576\n",
            "[Puzzle a699fb00] augmentation not full, only 576\n",
            "[Puzzle d0f5fe59] augmentation not full, only 72\n",
            "[Puzzle 0d87d2a6] augmentation not full, only 576\n",
            "[Puzzle 253bf280] augmentation not full, only 576\n",
            "[Puzzle 84551f4c] augmentation not full, only 576\n",
            "[Puzzle 67385a82] augmentation not full, only 576\n",
            "[Puzzle ce22a75a] augmentation not full, only 576\n",
            "[Puzzle bf89d739] augmentation not full, only 576\n",
            "[Puzzle ba26e723] augmentation not full, only 576\n",
            "[Puzzle 50c07299] augmentation not full, only 288\n",
            "[Puzzle 4522001f] augmentation not full, only 288\n",
            "[Puzzle bb43febb] augmentation not full, only 576\n",
            "[Puzzle b60334d2] augmentation not full, only 576\n",
            "[Puzzle ecdecbb3] augmentation not full, only 576\n",
            "[Puzzle 712bf12e] augmentation not full, only 576\n",
            "[Puzzle e619ca6e] augmentation not full, only 72\n",
            "[Puzzle 55059096] augmentation not full, only 576\n",
            "[Puzzle b527c5c6] augmentation not full, only 576\n",
            "[Puzzle af902bf9] augmentation not full, only 576\n",
            "[Puzzle dc2aa30b] augmentation not full, only 576\n",
            "[Puzzle 54db823b] augmentation not full, only 576\n",
            "[Puzzle c87289bb] augmentation not full, only 576\n",
            "[Puzzle 64a7c07e] augmentation not full, only 72\n",
            "[Puzzle 4938f0c2] augmentation not full, only 576\n",
            "[Puzzle 7447852a] augmentation not full, only 576\n",
            "[Puzzle 1fad071e] augmentation not full, only 576\n",
            "[Puzzle 71e489b6] augmentation not full, only 576\n",
            "[Puzzle da515329] augmentation not full, only 72\n",
            "[Puzzle Count2] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled9] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary2] augmentation not full, only 72\n",
            "[Puzzle Center10] augmentation not full, only 576\n",
            "[Puzzle InsideOutside9] augmentation not full, only 576\n",
            "[Puzzle Order7] augmentation not full, only 576\n",
            "[Puzzle CompleteShape5] augmentation not full, only 576\n",
            "[Puzzle FilledNotFilled10] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary10] augmentation not full, only 575\n",
            "[Puzzle HorizontalVertical5] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary5] augmentation not full, only 72\n",
            "[Puzzle FilledNotFilled4] augmentation not full, only 72\n",
            "[Puzzle MoveToBoundary1] augmentation not full, only 576\n",
            "[Puzzle InsideOutside2] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary4] augmentation not full, only 72\n",
            "[Puzzle TopBottom2D1] augmentation not full, only 576\n",
            "[Puzzle ExtendToBoundary6] augmentation not full, only 576\n",
            "[Puzzle InsideOutside3] augmentation not full, only 576\n",
            "[Puzzle MoveToBoundary3] augmentation not full, only 72\n",
            "[Puzzle Count5] augmentation not full, only 72\n",
            "[Puzzle Order9] augmentation not full, only 36\n",
            "[Puzzle Order5] augmentation not full, only 576\n",
            "[Puzzle HorizontalVertical6] augmentation not full, only 576\n",
            "[Puzzle CleanUp10] augmentation not full, only 72\n",
            "Total puzzles: 1280\n",
            "Total puzzle IDs (including <blank>): 1191730\n",
            "^C\n",
            "✓ ARC-AGI-2 dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build ARC-AGI-2 Dataset\n",
        "# Note: Cannot train on both ARC-AGI-1 and ARC-AGI-2 together\n",
        "\n",
        "!python -m dataset.build_arc_dataset \\\n",
        "  --input-file-prefix kaggle/combined/arc-agi \\\n",
        "  --output-dir data/arc2concept-aug-1000 \\\n",
        "  --subsets training2 evaluation2 concept \\\n",
        "  --test-set-name evaluation2\n",
        "\n",
        "print(\"✓ ARC-AGI-2 dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdrj3kXAbuPC"
      },
      "outputs": [],
      "source": [
        "# Build Sudoku-Extreme Dataset\n",
        "# Generate with 1000 examples and 1000 augmentations\n",
        "\n",
        "!python dataset/build_sudoku_dataset.py \\\n",
        "  --output-dir data/sudoku-extreme-1k-aug-1000 \\\n",
        "  --subsample-size 1000 \\\n",
        "  --num-aug 1000\n",
        "\n",
        "print(\"✓ Sudoku-Extreme dataset prepared!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WHt18ZSbuPD",
        "outputId": "e1b7d62e-c284-4503-af96-b63cb7380e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rtrain.csv: 0.00B [00:00, ?B/s]\rtrain.csv: 1.81MB [00:00, 82.2MB/s]\n",
            "100% 1000/1000 [00:00<00:00, 1404186.14it/s]\n",
            "test.csv: 1.81MB [00:00, 172MB/s]\n",
            "100% 1000/1000 [00:00<00:00, 1505493.18it/s]\n",
            "✓ Maze-Hard dataset prepared!\n"
          ]
        }
      ],
      "source": [
        "# Build Maze-Hard Dataset\n",
        "# Generate 1000 examples with 8 augmentations\n",
        "\n",
        "!python dataset/build_maze_dataset.py\n",
        "\n",
        "print(\"✓ Maze-Hard dataset prepared!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDnpn0zObuPD"
      },
      "source": [
        "## Training Experiments\n",
        "\n",
        "### ARC-AGI Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb8wFv9fbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp9rRwYPbuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-1 (Single GPU - for Colab)\n",
        "# Modified for Colab constraints\n",
        "\n",
        "run_name = \"pretrain_att_arc1concept_1gpu\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc1concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sjOJIRabuPE"
      },
      "outputs": [],
      "source": [
        "# Train on ARC-AGI-2 (Multi-GPU)\n",
        "# Requires 4 H-100 GPUs, runs for ~3 days\n",
        "\n",
        "run_name = \"pretrain_att_arc2concept_4\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/arc2concept-aug-1000]\" \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8kysWsbuPE"
      },
      "source": [
        "### Sudoku-Extreme Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4TfPozabuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (MLP version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_mlp_t_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.mlp_t=True \\\n",
        "  arch.pos_encodings=none \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkFGZc8UbuPF"
      },
      "outputs": [],
      "source": [
        "# Train on Sudoku-Extreme (Attention version)\n",
        "# Runtime: <36 hours on 1 L40S GPU\n",
        "\n",
        "run_name = \"pretrain_att_sudoku\"\n",
        "\n",
        "!python pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=6 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrooQqMlbuPF"
      },
      "source": [
        "### Maze-Hard Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWrDU0lbuPF",
        "outputId": "22a33bec-b573-465b-87f9-4b77e82723d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1120 05:22:02.760000 3473 torch/distributed/run.py:774] \n",
            "W1120 05:22:02.760000 3473 torch/distributed/run.py:774] *****************************************\n",
            "W1120 05:22:02.760000 3473 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "W1120 05:22:02.760000 3473 torch/distributed/run.py:774] *****************************************\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Samsung-TRM/pretrain.py\", line 20, in <module>\n",
            "    from adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/__init__.py\", line 1, in <module>\n",
            "    from .adam_atan2 import AdamATan2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/adam_atan2/adam_atan2.py\", line 4, in <module>\n",
            "    import adam_atan2_backend\n",
            "ModuleNotFoundError: No module named 'adam_atan2_backend'\n",
            "W1120 05:22:21.013000 3473 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3487 closing signal SIGTERM\n",
            "W1120 05:22:21.014000 3473 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3488 closing signal SIGTERM\n",
            "W1120 05:22:21.017000 3473 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3489 closing signal SIGTERM\n",
            "E1120 05:22:21.062000 3473 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 3486) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 901, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py\", line 892, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 143, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py\", line 277, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "pretrain.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2025-11-20_05:22:21\n",
            "  host      : 4e35b16c9f5f\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 3486)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Train on Maze-Hard\n",
        "# Runtime: <24 hours on 4 L40S GPUs\n",
        "\n",
        "run_name = \"pretrain_att_maze30x30\"\n",
        "\n",
        "!torchrun --nproc-per-node 4 \\\n",
        "  --rdzv_backend=c10d \\\n",
        "  --rdzv_endpoint=localhost:0 \\\n",
        "  --nnodes=1 \\\n",
        "  pretrain.py \\\n",
        "  arch=trm \\\n",
        "  data_paths=\"[data/maze-30x30-hard-1k]\" \\\n",
        "  evaluators=\"[]\" \\\n",
        "  epochs=50000 \\\n",
        "  eval_interval=5000 \\\n",
        "  lr=1e-4 \\\n",
        "  puzzle_emb_lr=1e-4 \\\n",
        "  weight_decay=1.0 \\\n",
        "  puzzle_emb_weight_decay=1.0 \\\n",
        "  arch.L_layers=2 \\\n",
        "  arch.H_cycles=3 \\\n",
        "  arch.L_cycles=4 \\\n",
        "  +run_name={run_name} \\\n",
        "  ema=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQbVxFpFbu_",
        "outputId": "7af328d8-38df-46e4-e0be-c412edc50e96"
      },
      "source": [
        "# Install Dependencies\n",
        "# Note: Adjust PyTorch installation based on your CUDA version\n",
        "\n",
        "# Upgrade pip and core tools\n",
        "!pip install --upgrade pip wheel setuptools -q\n",
        "\n",
        "# Install PyTorch (adjust for your CUDA version)\n",
        "# For Colab with CUDA 12.x:\n",
        "!pip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121 -q\n",
        "\n",
        "# Install other requirements\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Install adam-atan2 optimizer\n",
        "# Force pip to build from source to ensure adam_atan2_backend is compiled.\n",
        "!pip install adam-atan2 --force-reinstall --no-binary :all: --verbose\n",
        "\n",
        "print(\"✓ All dependencies installed!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 25.3 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)\n",
            "Collecting adam-atan2\n",
            "  Using cached adam_atan2-0.0.3-py3-none-any.whl\n",
            "Installing collected packages: adam-atan2\n",
            "  Attempting uninstall: adam-atan2\n",
            "    Found existing installation: adam_atan2 0.0.3\n",
            "    Uninstalling adam_atan2-0.0.3:\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2-0.0.3.dist-info/\n",
            "      Removing file or directory /usr/local/lib/python3.12/dist-packages/adam_atan2/\n",
            "      Successfully uninstalled adam_atan2-0.0.3\n",
            "Successfully installed adam-atan2-0.0.3\n",
            "✓ All dependencies installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro7RuKv1buPF"
      },
      "source": [
        "## Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz3GCdhAbuPG"
      },
      "outputs": [],
      "source": [
        "# Monitor Training Progress\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# List all run directories\n",
        "runs = glob.glob(\"outputs/*/\")\n",
        "print(\"Available training runs:\")\n",
        "for run in sorted(runs):\n",
        "    print(f\"  {run}\")\n",
        "\n",
        "# Check latest checkpoint\n",
        "latest_run = max(runs, key=os.path.getmtime) if runs else None\n",
        "if latest_run:\n",
        "    print(f\"\\nLatest run: {latest_run}\")\n",
        "    checkpoints = glob.glob(os.path.join(latest_run, \"*.pt\"))\n",
        "    print(f\"Checkpoints: {len(checkpoints)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y7_PPCLbuPG"
      },
      "outputs": [],
      "source": [
        "# Load and Evaluate Model\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Specify checkpoint path\n",
        "checkpoint_path = \"outputs/YOUR_RUN_NAME/checkpoint_best.pt\"\n",
        "\n",
        "if Path(checkpoint_path).exists():\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
        "    print(f\"Best validation accuracy: {checkpoint.get('best_val_acc', 'unknown')}\")\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {checkpoint_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZPXuK-ObuPG"
      },
      "outputs": [],
      "source": [
        "# Visualize Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_arc_prediction(input_grid, true_output, predicted_output):\n",
        "    \"\"\"Visualize ARC-AGI predictions\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(input_grid, cmap='tab10', interpolation='nearest')\n",
        "    axes[0].set_title('Input')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(true_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[1].set_title('True Output')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(predicted_output, cmap='tab10', interpolation='nearest')\n",
        "    axes[2].set_title('Predicted Output')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage (with dummy data)\n",
        "# input_grid = np.random.randint(0, 10, (10, 10))\n",
        "# true_output = np.random.randint(0, 10, (10, 10))\n",
        "# predicted_output = np.random.randint(0, 10, (10, 10))\n",
        "# visualize_arc_prediction(input_grid, true_output, predicted_output)\n",
        "\n",
        "print(\"Visualization functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszXJRwebuPG"
      },
      "source": [
        "## Citation\n",
        "\n",
        "If you use this code, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{jolicoeurmartineau2025morerecursivereasoningtiny,\n",
        "      title={Less is More: Recursive Reasoning with Tiny Networks},\n",
        "      author={Alexia Jolicoeur-Martineau},\n",
        "      year={2025},\n",
        "      eprint={2510.04871},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.LG},\n",
        "      url={https://arxiv.org/abs/2510.04871},\n",
        "}\n",
        "```\n",
        "\n",
        "And the Hierarchical Reasoning Model (HRM):\n",
        "\n",
        "```bibtex\n",
        "@misc{wang2025hierarchicalreasoningmodel,\n",
        "      title={Hierarchical Reasoning Model},\n",
        "      author={Guan Wang and Jin Li and Yuhao Sun and Xing Chen and Changling Liu and Yue Wu and Meng Lu and Sen Song and Yasin Abbasi Yadkori},\n",
        "      year={2025},\n",
        "      eprint={2506.21734},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.AI},\n",
        "      url={https://arxiv.org/abs/2506.21734},\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}